#LyX 1.3 created this file. For more info see http://www.lyx.org/
\lyxformat 221
\textclass article
\language english
\inputencoding auto
\fontscheme pslatex
\graphics default
\paperfontsize default
\spacing single 
\papersize Default
\paperpackage a4
\use_geometry 0
\use_amsmath 1
\use_natbib 0
\use_numerical_citations 0
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\quotes_times 2
\papercolumns 1
\papersides 1
\paperpagestyle default

\layout Title

The Bernoulli Operator
\layout Author

Linas Vepstas <linas@linas.org>
\layout Date

2 January 2004 (revised 5 January 2005)
\layout Abstract

This paper reviews a raft of related ideas surrounding the Bernoulli operator.
 The Bernoulli operator is the transfer operator or Frobenius-Perron operator
 of the Bernoulli map.
 The Bernoulli map is a simple map of the unit interval onto itself, which
 has the effect of discarding the leading binary digit of the binary expansion
 of a number upon every iteration.
 This map has been well studied in the literature, and much, if not most,
 of what is presented here is well-known.
 
\layout Abstract

If there is anything new here, then perhaps it is a representation of the
 Bernoulli map eigenfunctions in terms of the Takagi curve (or Blancmange
 curve).
 In particular, it is shown that the Hurwitz-zeta function basis for the
 continuous spectrum is just a linear combination of the Takagi curves,
 and vice-versa.
 I find this curious and important somehow: the Blancmange curve has an
 explicitly fractal self-similarity given by the dyadic monoid.
 The dyadic monoid is the monoid that describes the self-similarity of the
 infinite binary tree, and is a subset of the modular group 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
\layout Abstract

This paper is part of a set of chapters that explore the relationship between
 the real numbers, the modular group, and fractals.
\layout Section

The Bernoulli operator
\layout Standard

THIS IS A SET OF WORKING NOTES.
 Its somewhat loosely structured, sometimes messy, and occasionally assumes
 familiarity with the authors other writings and/or a general knowledge
 of dynamical systems.
 The intro hasn't been written yet.
\layout Standard

The general layout is:
\layout Standard

-- Define the Bernoulli operator, demonstrate some of its eigenfunctions
 and eigenvalues.The presentation is a simplified variant of the material
 in 
\begin_inset LatexCommand \cite{Dri99}

\end_inset 

.
 
\layout Standard

-- Present the Hurwitz Zeta eigenfunctions
\layout Standard

-- Present the topological zeta function
\layout Standard

The Bernoulli map and Bernoulli operator appear in many forms and guises
 throughout the theory of dynamical systems.
 In order to give a proper and complete treatment of the subject, the topics
 listed below should be presented/reviewed/understood.
 
\layout Itemize

The Bernoulli process in probability theory is one of the simplest Markov
 processes.
 Understood as a Markov process, it has a number of generalizations.
 
\layout Itemize

Discuss entropy.
\layout Itemize

Discuss symbolic dynamics in two letters.
 Mention one-dimensional tiling, mention Fibonacci tiling.
 Mention Lindenmeyer systems.
 Mention subshifts of finite type.
 Mention how subshifts are solved.
 
\layout Itemize

Discuss connection to the Cantor set.
 viz, all strings in two letters.
\layout Itemize

Discuss free groups, discuss Cayley tree, discuss group presentation, and
 connect it up to this.
\layout Itemize

Discuss ergodicity, the ergodic theorem, and how its related to this.
 Discuss how the Bernoulli map is a 
\begin_inset Quotes eld
\end_inset 

bad
\begin_inset Quotes erd
\end_inset 

 example of ergodicity.
 Hypothesis: are all transfer operators that are triangular (have a polynomial
 basis) equivalent to 
\begin_inset Quotes eld
\end_inset 

bad
\begin_inset Quotes erd
\end_inset 

 ergodic sequences? Or are there good (uniformly converging) ergodic sequences
 that can result from triangular transfer operators?
\layout Itemize

Discuss wavelet transforms, point out their dyadic nature, point out their
 relationship to this mess; point out how wavelet transforms are a good
 tool for working with this kind of dyadic data.
\layout Itemize

While this paper focuses primarily on the polynomial and square-integrable
 eigenfunctions of the Bernoulli operator, there is also a class of non-differen
tiable, non-integrable eigenfunctions that can be precisely defined in terms
 of the shift operator on a one-dimensional lattice model, the Ising model
 of statistical mechanics.
 The Ising model has a natural topology that is distinctly different from
 the topology of the real number line; this alternate topology allows for
 a much, much larger set of eigenfunctions.
 This is discussed in greater detail in 
\begin_inset LatexCommand \cite{Ve-I04}

\end_inset 

.
\layout Standard

Some of the sections, including the section on orthogonality and completeness,
 are awkwardly presented.
 The topic is subtle, the notation is not elegant.
 In a certain sense, this paper illustrates all the wrong ways in which
 to present the notions of completeness with regards to a Hilbert space.
 The notions of what is fractal, and what is differentiable, and what is
 an operator, and what is an eigenvalue, is muddied as a result.
 The journey, however faulty, is still educational, though.
 To do: Riesz representation thm 
\layout Section

The Frobenius-Perron Operator of the Bernoulli Map
\layout Standard

The Bernoulli map is an exactly solvable example of deterministic chaos.
 A good presentation of this map, its associated transfer operator and its
 solution in terms of polynomial eigenfunctions is given in 
\begin_inset LatexCommand \cite{Dri99}

\end_inset 

.
 The first section here recaps those results using a much simplified development
 and simpler tools.
 The simpler tools allow several extensions, explored in later sections.
 
\layout Standard

The Bernoulli map is given by 
\begin_inset Formula \begin{equation}
b(x)=2x-\left\lfloor 2x\right\rfloor \label{eq:}\end{equation}

\end_inset 

 and can be thought of as popping the leading digit off of the binary expansion
 of 
\begin_inset Formula $x.$
\end_inset 

 This map has a positive Lyapunov exponent and is highly chaotic, as, in
 a certain sense, one can say that the digits of the binary expansion of
 some 'arbitrary' number are unpredictable, and that the orbits of two close-by
 numbers will eventually become 'uncorellated' (after suitably defining
 what we mean by 'arbitrary' and 'unpredictable').
 
\layout Standard

The Frobenius-Perron operator or transfer operator of the Bernoulli map
 is given by
\begin_inset Formula \begin{equation}
\left[U_{B}f\right](x)=\frac{1}{2}\left[f\left(\frac{x}{2}\right)+f\left(\frac{x+1}{2}\right)\right]\label{eq:Bernoulli operator}\end{equation}

\end_inset 

 A general definition of the transfer operator is given in 
\begin_inset LatexCommand \cite{Ve-Tr04}

\end_inset 

, which also develops the general notation used in the following presentation.
 This reference should be consulted if the notation below becomes confusing.
\layout Subsection

The Polynomial Representation
\layout Standard

The operator 
\begin_inset Formula $U_{B}$
\end_inset 

 has a representation in which it acts on the Hilbert space of polynomials.
 That is, one may contemplate the structure of 
\begin_inset Formula $U_{B}$
\end_inset 

 when the function 
\begin_inset Formula $f$
\end_inset 

 in equation 
\begin_inset LatexCommand \ref{eq:Bernoulli operator}

\end_inset 

 is a polynomial.
 In what follows, the bra-ket notation from quantum mechanics is used.
 The kets 
\begin_inset Formula $\left|n\right\rangle $
\end_inset 

 refer to the monomial 
\begin_inset Formula $x^{n}$
\end_inset 

, while the bras 
\begin_inset Formula $\left\langle m\right|$
\end_inset 

refer to the Riesz duals of the monomials.
 These duals are in fact derivatives of the Dirac delta function.
 A presentation of the notation used here, including the general method
 by which one may obtain the matrix elements of the transfer operator in
 the polynomial basis, is detailed in 
\begin_inset LatexCommand \cite{Ve-Tr04}

\end_inset 

, which should be reviewed if confusion arises below.
\layout Standard

The matrix elements of the Bernoulli operator in the monomial basis are
 given by
\layout Standard


\begin_inset Formula \begin{equation}
\left[U_{B}\right]_{mk}\equiv U_{mk}\equiv\left\langle m\right|U\left|k\right\rangle =\frac{\delta_{mk}}{2^{m}}+\left(\begin{array}{c}
k\\
m\end{array}\right)\frac{\Theta_{mk}}{2^{k+1}}\label{eq:}\end{equation}

\end_inset 

 where 
\begin_inset Formula $\left(\begin{array}{c}
m\\
k\end{array}\right)$
\end_inset 

 is the binomial coefficient, and 
\begin_inset Formula \begin{equation}
\Theta_{mk}=\left\{ \begin{array}{c}
0\;\textrm{ if }\; k\leq m\\
1\;\textrm{ if }\; k>m\end{array}\right.\label{eq:}\end{equation}

\end_inset 

 is a traceless, pure upper-triangular matrix.
 Thus, for the polynomial eigenstates, we can promptly read the eigenvalues
 off the diagonal; these eigenvalues are 
\begin_inset Formula $\lambda_{n}=2^{-n}$
\end_inset 

.
 Because the matrix is upper-triangular, it is easily solvable for both
 the left and right eigenvectors, which agree perfectly with those given
 by Driebe
\begin_inset LatexCommand \cite{Dri99}

\end_inset 

.
 Visually, the upper-left of this matrix looks like 
\begin_inset Formula \begin{equation}
U_{mk}=\left[\begin{array}{cccccc}
1 & \frac{1}{4} & \frac{1}{8} & \frac{1}{16} & \frac{1}{32} & ...\\
0 & \frac{1}{2} & \frac{1}{4} & \frac{3}{16} & \frac{1}{8}\\
0 & 0 & \frac{1}{4} & \frac{3}{16} & \frac{3}{16}\\
0 & 0 & 0 & \frac{1}{8} & \frac{1}{8}\\
0 & 0 & 0 & 0 & \frac{1}{16}\\
... &  &  &  &  & ...\end{array}\right]\label{eq:}\end{equation}

\end_inset 


\layout Standard

The right eigenvectors are denoted by 
\begin_inset Formula $\left|B_{n}\right\rangle $
\end_inset 

 and have the vector components 
\begin_inset Formula \begin{equation}
\left\langle k\left|B_{n}\right.\right\rangle =\left(\begin{array}{c}
n\\
k\end{array}\right)\left(1-\Theta_{n,k}\right)B_{n-k}=\left\{ \begin{array}{ccc}
\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k} & \;\textrm{ for }\; & k\leq n\\
0 & \;\textrm{ for }\; & k>n\end{array}\right.\label{eq:}\end{equation}

\end_inset 

 where 
\begin_inset Formula $B_{k}$
\end_inset 

 are the Bernoulli numbers.
 We can verify this by multiplying the eigenvector into the matrix: 
\begin_inset Formula \begin{eqnarray}
\sum_{k=0}^{\infty}\left\langle m\right|U\left|k\right\rangle \left\langle k\left|B_{n}\right.\right\rangle  & = & \sum_{k=m}^{n}\left[\frac{\delta_{mk}}{2^{m}}+\left(\begin{array}{c}
k\\
m\end{array}\right)\frac{\Theta_{mk}}{2^{k+1}}\right]\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k}\nonumber \\
 & = & \frac{1}{2^{m}}\left(\begin{array}{c}
n\\
m\end{array}\right)B_{n-m}+...non-trivial-taylor-expn\nonumber \\
 & = & \lambda_{n}\left\langle m\left|B_{n}\right.\right\rangle \label{eq:}\end{eqnarray}

\end_inset 

 In coordinate space, the right eigenvectors are the Bernoulli polynomials.
\layout Standard


\begin_inset Formula \begin{equation}
\sum_{k=0}^{\infty}\left\langle x|k\right\rangle \left\langle k\left|B_{n}\right.\right\rangle =\sum_{k=0}^{n}\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k}x^{k}=B_{n}(x)\label{eq:}\end{equation}

\end_inset 

 which we can verify explicitly by substituting into the function-operator
 form of the map:
\begin_inset Formula \begin{eqnarray}
\left[U_{B}B_{n}\right](x) & = & \frac{1}{2}\left[B_{n}\left(\frac{x}{2}\right)+B_{n}\left(\frac{x+1}{2}\right)\right]\nonumber \\
 & = & \lambda_{n}B_{n}(x)\label{eq:}\end{eqnarray}

\end_inset 

 The last identity follows from the 
\begin_inset Quotes eld
\end_inset 

multiplication formula
\begin_inset Quotes erd
\end_inset 

 for Bernoulli polynomials.
\layout Standard

The left eigenvectors are denoted by 
\begin_inset Formula $\left\langle \tilde{B}_{n}\right|$
\end_inset 

and, for 
\begin_inset Formula $n>0$
\end_inset 

, have the components 
\begin_inset Formula \begin{equation}
\left\langle \left.\tilde{B}_{n}\right|k\right\rangle =\left(\begin{array}{c}
k\\
n-1\end{array}\right)\frac{1}{n}\left(\delta_{nk}+\Theta_{nk}\right)\label{eq:}\end{equation}

\end_inset 

 The zeroth left eigenvector is a special-case; it has components 
\begin_inset Formula $\left\langle \left.\tilde{B}_{0}\right|k\right\rangle =1/(k+1)$
\end_inset 

.
 The left eigenvectors can also be written out in coordinate space: 
\begin_inset Formula \begin{eqnarray}
\left\langle \tilde{B}_{n}|x\right\rangle  & = & \sum_{k=0}^{\infty}\left\langle \left.\tilde{B}_{n}\right|k\right\rangle \left\langle k|x\right\rangle \nonumber \\
 & = & \sum_{k=0}^{\infty}\left\langle \left.\tilde{B}_{n}\right|k\right\rangle (-)^{k}\frac{\delta^{(k)}(x)}{k!}\nonumber \\
 & = & \frac{1}{n}\sum_{k=n}^{\infty}\left(\begin{array}{c}
k\\
n-1\end{array}\right)(-)^{k}\frac{\delta^{(k)}(x)}{k!}\nonumber \\
 & = & \frac{(-)^{n+1}}{n!}\left[\delta^{(n-1)}(1-x)-\delta^{(n-1)}(x)\right]\label{eq:left bernoulli}\end{eqnarray}

\end_inset 

 for the 
\begin_inset Formula $n>0$
\end_inset 

case.
 The 
\begin_inset Formula $n=0$
\end_inset 

 left eigenvector is best understood by integrating it over some arbitrary
 function 
\begin_inset Formula $f(x)$
\end_inset 

: 
\begin_inset Formula \begin{eqnarray}
\int_{0}^{1}dx\,\left\langle \left.\tilde{B}_{0}\right|x\right\rangle f(x) & = & \int_{0}^{1}dx\, f(x)\sum_{k=0}^{\infty}(-)^{k}\frac{\delta^{(k)}(x)}{(k+1)!}\nonumber \\
 & = & \sum_{k=0}^{\infty}\frac{f^{(k)}(0)}{(k+1)!}\nonumber \\
 & = & \sum_{k=0}^{\infty}\frac{f^{(k)}(0)}{k!}\int_{0}^{1}x^{k}dx\nonumber \\
 & = & \int_{0}^{1}f(x)dx\nonumber \\
 & = & \left\langle \left.\tilde{B}_{0}\right|f\right\rangle \label{eq:}\end{eqnarray}

\end_inset 

 Its instructive to look at the other left eigenvectors acting on some function
 
\begin_inset Formula $f(x)$
\end_inset 

; these can be written as 
\begin_inset Formula \begin{equation}
\left\langle \left.\tilde{B}_{n}\right|f\right\rangle =\frac{1}{n!}\left[f^{(n-1)}(1)-f^{(n-1)}(0)\right]\label{eq:}\end{equation}

\end_inset 

Note that the left eigenvectors are adjoint to the Bernoulli polynomials.
 Thus, the identity operator 
\begin_inset Formula $\mathbb{I}_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|$
\end_inset 

 turns out to be the Euler-MacLaurin summation formula in disguise, which
 we can see more easily by writing 
\begin_inset Formula \begin{eqnarray}
f(x) & = & \left\langle x|f\right\rangle \nonumber \\
 & = & \sum_{m=0}^{M}B_{m}(x)\left\langle \left.\tilde{B}_{m}\right|f\right\rangle -\frac{1}{(M+1)!}\int_{0}^{1}dy\, B_{M+1}(x-y)\; f^{(M)}(y)\label{eq:}\end{eqnarray}

\end_inset 

 Its not to hard to explicitly validate completeness: one finds that 
\begin_inset Formula \begin{equation}
\left\langle j\left|\mathbb{I}_{B}\right|k\right\rangle =\left\langle j\right|\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|\left|k\right\rangle =\delta_{jk}\label{eq:}\end{equation}

\end_inset 

 Naively, the Euler-MacLaurin formula, one is tempted to deduce orthogonality
 over coordinate space.
 That is, from 
\begin_inset Formula \begin{equation}
\sum_{n=0}^{\infty}\left\langle x\left|B_{n}\right.\right\rangle \left\langle \left.\tilde{B}_{n}\right|f\right\rangle =f(x)\label{eq:}\end{equation}

\end_inset 

 one wants to deduce that 
\begin_inset Formula \begin{equation}
\sum_{n=0}^{\infty}\left\langle x\left|B_{n}\right.\right\rangle \left\langle \left.\tilde{B}_{n}\right|y\right\rangle =\delta(x-y)\label{eq: Bernoulli-faulty}\end{equation}

\end_inset 

However, this equation is 
\begin_inset Quotes eld
\end_inset 

wrong
\begin_inset Quotes erd
\end_inset 

 in a certain sense, as discussed in the next section.
 The operator 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 is in fact a projection operator; it has a large kernel.
 
\layout Standard

Thus, in the polynomial representation, the Frobenius-Perron operator of
 the Bernoulli map is 
\begin_inset Formula \begin{equation}
U_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \lambda_{n}\left\langle \tilde{B}_{n}\right|\label{eq:}\end{equation}

\end_inset 

 We can make use of this diagonal form to easily compute formal expressions
 involving 
\begin_inset Formula $U_{B}$
\end_inset 

.
 Thus, for a function 
\begin_inset Formula $f(x)$
\end_inset 

 that is expressible as a polynomial series in 
\begin_inset Formula $x$
\end_inset 

, we can write the operator 
\begin_inset Formula \begin{equation}
f\left(U_{B}\right)=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle f\left(\lambda_{n}\right)\left\langle \tilde{B}_{n}\right|\label{eq:}\end{equation}

\end_inset 

 whose matrix elements we can explicitly demonstrate in the monomial basis:
 
\begin_inset Formula \begin{equation}
\left\langle j\left|f\left(U_{B}\right)\right|k\right\rangle =\sum_{j\leq n\leq k}\left(\begin{array}{c}
n\\
j\end{array}\right)\left(\begin{array}{c}
k\\
n-1\end{array}\right)\frac{B_{n-j}}{n}f\left(2^{-n}\right)\label{eq:}\end{equation}

\end_inset 

 This allows us to write, for example, 
\begin_inset Formula $U_{B}=\exp(-H_{B})$
\end_inset 

 so that 
\begin_inset Formula $H_{B}=-\log U_{B}$
\end_inset 

 has matrix elements 
\begin_inset Formula \begin{equation}
\left\langle j\left|H_{B}\right|k\right\rangle =\frac{\log(2)}{k+1}\left(\begin{array}{c}
k+1\\
j\end{array}\right)\sum_{m=0}^{k-j}\left(\begin{array}{c}
k-j+1\\
m\end{array}\right)(j+m)\, B_{m}\label{eq:}\end{equation}

\end_inset 

 
\layout Subsection

Completeness and Orthogonality
\layout Standard

The notions of completeness and orthogonality are somewhat cavalierly treated
 above.
 We attempt to remedy this here.
 The operator 
\begin_inset Formula $\mathbb{I}_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|$
\end_inset 

, although appearing to embody a certain notion of 
\begin_inset Quotes eld
\end_inset 

completeness
\begin_inset Quotes erd
\end_inset 

, is in fact a projection operator when considered on a larger set of states.
 In fact, it has a large kernel, consisting of all functions odd about 
\begin_inset Formula $x=1/2$
\end_inset 

, that is, all functions can be written as 
\begin_inset Formula \begin{equation}
f(x)=\sum_{k=1}^{\infty}a_{k}\sin(2\pi kx)\label{eq:}\end{equation}

\end_inset 

 This is easily seen by noting that 
\layout Standard


\begin_inset Formula \begin{eqnarray}
\int_{0}^{1}dx\,\tilde{B}_{n}(x)\,\sin(2\pi kx) & = & \frac{1}{n!}\left[\left.\frac{d^{n-1}\sin2\pi kx}{dx^{n-1}}\right|_{x=1}-\left.\frac{d^{n-1}\sin2\pi kx}{dx^{n-1}}\right|_{x=0}\right]\label{eq:}\\
 & = & 0\nonumber \end{eqnarray}

\end_inset 

 where we've written 
\begin_inset Formula $\tilde{B}_{n}(x)$
\end_inset 

 for 
\begin_inset Formula $\left\langle \tilde{B}_{n}|x\right\rangle $
\end_inset 

.
 Perhaps this lack of completeness is due to the form of the left eigenstates
 given in equation 
\begin_inset LatexCommand \ref{eq:left bernoulli}

\end_inset 

.
 So we make a guess that perhaps a more truly complete set of states can
 be found by considering 
\begin_inset Formula \begin{equation}
\tilde{S}_{n}(x)=\frac{(-)^{n+1}}{n!}\left[\delta^{(n-1)}(1-x)+\delta^{(n-1)}(x)\right]\label{eq:}\end{equation}

\end_inset 

 so that sums and differences of the duals 
\begin_inset Formula $\tilde{B}_{m}(x)$
\end_inset 

 and 
\begin_inset Formula $\tilde{S}_{n}(x)$
\end_inset 

 can be used to regain the duals to the monomials 
\begin_inset Formula $\left\langle n|y\right\rangle =(-)^{n}\delta^{(n)}(y)/n!$
\end_inset 

.
 
\layout Description

Theorem: The duals to 
\begin_inset Formula $\tilde{S}_{n}(x)$
\end_inset 

 are given by 
\begin_inset Formula $S_{n}(x)=nE_{n}(x)/2$
\end_inset 

 where the 
\begin_inset Formula $E_{n}(x)$
\end_inset 

 are the Euler polynomials.
 
\layout Description

Proof: Consider the generating function for the Euler polynomials 
\begin_inset Formula \begin{equation}
G_{E}(x,t)=\frac{2e^{xt}}{1+e^{t}}=\sum_{n=0}^{\infty}E_{n}(x)\frac{t^{n}}{n!}\label{eq:}\end{equation}

\end_inset 

 Then one has, by taking the left hand side, 
\begin_inset Formula \begin{equation}
\int_{0}^{1}\tilde{S}_{n}(x)\,\frac{2e^{xt}}{1+e^{t}}\, dx=\frac{2}{n}\frac{t^{n-1}}{(n-1)!}\label{eq:}\end{equation}

\end_inset 

 and, performing the same operation on the right hand side, 
\begin_inset Formula \begin{equation}
\int_{0}^{1}\tilde{S}_{n}(x)\sum_{k=0}^{\infty}E_{k}(x)\frac{t^{k}}{k!}\; dx=\sum_{k=0}^{\infty}\frac{t^{k}}{k!}\int_{0}^{1}\tilde{S}_{n}(x)\, E_{k}(x)\, dx\label{eq:}\end{equation}

\end_inset 

 Then, equating the two sides, one has demonstrated orthogonality of the
 dual states: 
\begin_inset Formula \begin{equation}
\int_{0}^{1}\tilde{S}_{n}(x)\, E_{k}(x)\, dx=\frac{2\delta_{k,n-1}}{n}\label{eq:}\end{equation}

\end_inset 

 QED.
\layout Standard

From this orthogonality relationship follows a certain restricted completeness
 statement in coordinate space.
 That is, if one decomposes a function 
\begin_inset Formula $f(y)=\sum_{k=1}^{\infty}a_{k}S_{k}(y)$
\end_inset 

 then one easily finds 
\begin_inset Formula \begin{equation}
\int_{0}^{1}\sum_{n=1}^{\infty}S_{n}(x)\tilde{S}_{n}(y)\, f(y)\, dy=f(x)\label{eq:}\end{equation}

\end_inset 

 from which one wants to conclude, incorrectly, that 
\begin_inset Formula \begin{equation}
\sum_{n=1}^{\infty}S_{n}(x)\tilde{S}_{n}(y)=\delta(x-y)\label{eq:}\end{equation}

\end_inset 

 using the same faulty logic as in equation 
\begin_inset LatexCommand \ref{eq: Bernoulli-faulty}

\end_inset 

.
 The fault is the assumption that 
\begin_inset Formula $f(y)$
\end_inset 

 can be decomposed in the fashion given.
 In fact, the operator 
\begin_inset Formula $\mathbb{I}_{S}=\sum_{n=0}^{\infty}\left|S_{n}\right\rangle \left\langle \tilde{S}_{n}\right|$
\end_inset 

 has a large kernel: this time, all functions that are even about 
\begin_inset Formula $x=1/2$
\end_inset 

 are in the kernel.
 One might hope that one can remedy the above situation by taking the sum
 
\begin_inset Formula $\mathbb{I}_{C}=\mathbb{I}_{B}+\mathbb{I}_{S}$
\end_inset 

 with one operator projecting out the even functions, and the other the
 odd functions, but, between the two of them, making a whole.
 However, one immediately runs into a problem with the basis functions.
 The 
\begin_inset Formula $\tilde{S}_{n}(x)$
\end_inset 

 are not orthogonal to the 
\begin_inset Formula $B_{n}(x)$
\end_inset 

, and vice-versa.
 This is easily seen by considering the the generating function for the
 Bernoulli polynomials: 
\begin_inset Formula \begin{equation}
G_{B}(x,t)=\frac{te^{xt}}{e^{t}-1}=\sum_{n=0}^{\infty}B_{n}(x)\frac{t^{n}}{n!}\label{eq:}\end{equation}

\end_inset 

Integrating, one gets 
\begin_inset Formula \begin{equation}
\int_{0}^{1}\tilde{S}_{n}(x)G_{B}(x,t)\, dx=\frac{t^{n}}{n!}\frac{e^{t}+1}{e^{t}-1}=\sum_{k=0}^{\infty}\frac{t^{k}}{k!}\int_{0}^{1}\tilde{S}_{n}(x)\, B_{k}(x)\, dx\label{eq:}\end{equation}

\end_inset 

 from which one deduces that 
\begin_inset Formula $\int_{0}^{1}\tilde{S}_{n}(x)\, B_{k}(x)\, dx=0$
\end_inset 

 only for 
\begin_inset Formula $k<n-1$
\end_inset 

, and similarly for 
\begin_inset Formula $\int_{0}^{1}\tilde{B}_{n}(x)\, S_{k}(x)\, dx$
\end_inset 

.
\layout Subsection

Basis Confusion Redux
\layout Standard

The nature and meaning of 
\begin_inset Quotes eld
\end_inset 

vector space basis
\begin_inset Quotes erd
\end_inset 

 is perhaps a bit confusing in Hilbert Space.
 It is hard to discuss the notion of what an operator 
\begin_inset Quotes eld
\end_inset 

is
\begin_inset Quotes erd
\end_inset 

 without also discussing the basis at the same time.
 Removing this confusion takes mathematical techniques beyond the scope
 of this paper.
 In this section, we'll merely review some of the sources of confusion,
 and some of the notational devices that help minimize it.
 One begins by asking, 
\begin_inset Quotes eld
\end_inset 

what is the operator 
\begin_inset Formula $U_{B}$
\end_inset 

, really
\begin_inset Quotes erd
\end_inset 

? It was seen above that the monomials form a complete set of basis states
 that can be used to represent analytic functions.
 The operator 
\begin_inset Formula $\mathbb{I}_{M}=\sum_{n=0}^{\infty}\left|n\right\rangle \left\langle n\right|$
\end_inset 

 can be called the identity operator over the space of real analytic functions;
 it has no kernel in that space.
 Here, the subscript 
\begin_inset Formula $M$
\end_inset 

 is used to remind us that the identity operator is built from the monomial
 states.
 Thus, one may write 
\begin_inset Formula $U_{B}=\mathbb{I}_{M}U_{B}\mathbb{I}_{M}$
\end_inset 

 which expands to 
\begin_inset Formula \begin{equation}
U_{B}=\sum_{m=0}^{\infty}\sum_{n=0}^{\infty}\left|m\right\rangle \left\langle m\left|U_{B}\right|n\right\rangle \left\langle n\right|\label{eq:}\end{equation}

\end_inset 

 As seen above, the matrix elements 
\begin_inset Formula $U_{mn}\equiv\left\langle m\left|U\right|n\right\rangle $
\end_inset 

 are upper-triangular, and so one wants to say that the operator 
\begin_inset Formula $U_{B}$
\end_inset 

 is clearly not Hermitian.
 And yet, one may use the same trick to write 
\begin_inset Formula $U_{B}=\mathbb{I}_{B}U_{B}\mathbb{I}_{B}$
\end_inset 

 to get matrix elements that are clearly non-zero only on the diagonal:
 
\begin_inset Formula $\left\langle B_{m}\left|U_{B}\right|\tilde{B}_{n}\right\rangle =\delta_{mn}\lambda_{n}$
\end_inset 

.
 Matrixes that are diagonal and have only real entries on the diagonal are
 clearly Hermitian, so this implies that 
\begin_inset Formula $U_{B}$
\end_inset 

 is Hermitian.
 So which is it? Is it Hermitian or not? Some of the confusion is due to
 the fact that the use of the operator notation carries hidden with it an
 implied choice of basis, and, so in the above, we have made an inadvertent
 change of basis, which is 
\begin_inset Quotes eld
\end_inset 

invisible
\begin_inset Quotes erd
\end_inset 

 when things such as 
\begin_inset Formula $U_{B}=\mathbb{I}_{M}U_{B}\mathbb{I}_{M}$
\end_inset 

 are written.
 Much of the confusion is due to the fact that in a Hilbert space, the concept
 of orthonormality violates the notions one gets from working with finite-dimens
ional basis.
 Lets show this change of basis explicitly.
 We write 
\begin_inset Formula \begin{eqnarray}
U_{diagonal} & = & \sum_{j,k=0}^{\infty}\left|B_{j}\right\rangle \delta_{jk}\lambda_{k}\left\langle \tilde{B}_{k}\right|\nonumber \\
 & = & \sum_{j,k,m,n=0}^{\infty}\left|B_{j}\right\rangle \left\langle \left.\tilde{B}_{j}\right|m\right\rangle \left\langle m\left|U_{monomial}\right|n\right\rangle \left\langle n\left|B_{k}\right.\right\rangle \left\langle \tilde{B}_{k}\right|\nonumber \\
 & = & \tilde{B}\, U_{monomial}\, B\label{eq:}\end{eqnarray}

\end_inset 

 where the operators 
\begin_inset Formula $\tilde{B}$
\end_inset 

 and 
\begin_inset Formula $B$
\end_inset 

 show the change of basis: 
\begin_inset Formula \begin{equation}
\tilde{B}=\sum_{j,m=0}^{\infty}\left|B_{j}\right\rangle \left\langle \left.\tilde{B}_{j}\right|m\right\rangle \left\langle m\right|\label{eq:}\end{equation}

\end_inset 

 and 
\begin_inset Formula \begin{equation}
B=\sum_{k,n=0}^{\infty}\left|n\right\rangle \left\langle n\left|B_{k}\right.\right\rangle \left\langle \tilde{B}_{k}\right|\label{eq:}\end{equation}

\end_inset 

 It is not hard to work out that 
\begin_inset Formula $\tilde{B}B=\mathbb{I}_{B}$
\end_inset 

 and that 
\begin_inset Formula $B\tilde{B}=\mathbb{I}_{M}$
\end_inset 

 so that, in a certain sense 
\begin_inset Formula $\tilde{B}$
\end_inset 

 is both a left- and right-inverse of 
\begin_inset Formula $B$
\end_inset 

.
 However, 
\begin_inset Formula $B$
\end_inset 

 is not orthogonal in the traditional sense: we had demonstrated the matrix
 elements up above, and one clearly has 
\begin_inset Formula $\left\langle n|B_{k}\right\rangle \neq\left\langle \tilde{B}_{n}|k\right\rangle $
\end_inset 

.
 What makes this seem so strange is that both the monomial basis states
 
\begin_inset Formula $\left|n\right\rangle $
\end_inset 

 and the Bernoulli polynomial basis states 
\begin_inset Formula $\left|B_{j}\right\rangle $
\end_inset 

 are both complete and orthogonal.
 From experience working with finite-dimensional matrices, one is accustomed
 to believe that any change of basis between a set of ortho-normal basis
 states is given by a similarity matrix with is orthogonal.
 It is seen here that for infinite-dimensional spaces, that this is not
 the case.
 
\layout Standard

XXX I'm still troubled by this.
 Its not completely clear that the space spanned by the monomial basis is
 really identical to the space spanned by the Bernoulli polynomial basis.
 There is some conceptual monkey business that is not adequately explained
 here.
 Either set of basis functions seems to be in a certain sense 
\begin_inset Quotes eld
\end_inset 

complete
\begin_inset Quotes erd
\end_inset 

, but we haven't truly proven the following: Thm: Consider a larger space
 of functions, for example, the space of square integrable functions.
 Then consider 
\begin_inset Formula $\mathbb{I}_{M}$
\end_inset 

 and 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 as projection operators on this space.
 Then is the image of 
\begin_inset Formula $\mathbb{I}_{M}$
\end_inset 

 equal to image of 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 when embedded in this larger space?
\layout Subsection

The Fourier Representation 
\layout Standard

The Koopman operator of the Bernoulli Map has the property of taking a function
 and making two copies of it.
 That is, 
\begin_inset Formula \begin{eqnarray}
\left[K_{B}f\right](y) & = & \int_{0}^{1}\delta\left(x-b(y)\right)f(x)\, dx\nonumber \\
 & = & f(b(y))\nonumber \\
 & = & f(2y)\theta(1-2y)+f(2y-1)\theta(2y-1)\label{eq:}\end{eqnarray}

\end_inset 

 where 
\begin_inset Formula $\theta(x)$
\end_inset 

 is the step function, identically zero for 
\begin_inset Formula $x<0$
\end_inset 

 and identically one for 
\begin_inset Formula $x>0$
\end_inset 

.
 The Koopman operator for the Bernoulli map is not faithfully representable
 in the polynomial basis; this can be seen in two ways.
 First, it introduces a discontinuity at 
\begin_inset Formula $x=1/2$
\end_inset 

 which the polynomials cannot move beyond; the radius of the circle of converge
 is limited by this singularity.
 Secondly, it takes a function and more-or-less makes it periodic; again,
 the polynomials cannot cope directly with this.
 Thus, one is motivated to explore the Fourier representation, if only to
 express the Koopman operator.
 
\layout Standard

It is easy to find an explicit form for this operator in the Fourier basis.
 Writing 
\begin_inset Formula \begin{equation}
f(x)=\sum_{n}a_{n}\cos2\pi nx\;+b_{n}\sin2\pi nx\label{eq:}\end{equation}

\end_inset 

 then 
\begin_inset Formula \begin{equation}
\left[K_{B}f\right](x)=\sum_{n}a_{n}\cos4\pi nx\;+b_{n}\sin4\pi nx\label{eq:}\end{equation}

\end_inset 

 or, in Dirac notation, 
\begin_inset Formula $\left\langle em\left|K_{B}\right|en\right\rangle =\delta_{2m,n}$
\end_inset 

.
 This is a very singular operator in this basis.
 Visually, it has the distinctive appearance of 
\begin_inset Formula \begin{equation}
K_{B}=\left[\begin{array}{cccccc}
1 & 0 & 0 & 0 & 0 & ...\\
0 & 0 & 0 & 0 & ...\\
0 & 1 & 0 & 0\\
0 & 0 & 0 & 0\\
0 & 0 & 1 & 0 & ...\\
...\end{array}\right]\label{eq:}\end{equation}

\end_inset 

 where every other row consists of zeros.
 In this same basis, 
\begin_inset Formula $U_{B}$
\end_inset 

is equally remarkable: it is literally the transpose: that is 
\begin_inset Formula $K_{B}=U_{B}^{T}$
\end_inset 

 in this basis, and so 
\begin_inset Formula \begin{equation}
U_{B}=\left[\begin{array}{cccccc}
1 & 0 & 0 & 0 & 0 & ...\\
0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & ...\\
...\end{array}\right]\label{eq:}\end{equation}

\end_inset 

 In this representation, it is easily seen that 
\begin_inset Formula $U_{B}K_{B}=1$
\end_inset 

 but 
\begin_inset Formula $K_{B}U_{B}\neq1$
\end_inset 

, just as in the coordinate-space representation.
 It is very instructive to verify that the Bernoulli polynomials are still
 eigenfunctions in this representation.
 For 
\begin_inset Formula $n\neq0$
\end_inset 

, one has 
\begin_inset Formula \begin{equation}
\int_{0}^{1}B_{1}(x)\,\sin(2\pi nx)\, dx=\frac{-1}{\pi n}\label{eq:}\end{equation}

\end_inset 

 and it is straightforward to visually verify that 
\begin_inset Formula $U_{B}B_{1}=\frac{1}{2}B_{1}$
\end_inset 

.
 By working with the generator for the Bernoulli polynomials, 
\begin_inset Formula \begin{equation}
\frac{te^{xt}}{e^{t}-1}=\sum_{n=0}^{\infty}B_{n}(x)\,\frac{t^{n}}{n!}\label{eq:}\end{equation}

\end_inset 

 one can immediately find, for 
\begin_inset Formula $m\neq0$
\end_inset 

, the Fourier components 
\begin_inset Formula \begin{equation}
\int_{0}^{1}B_{n}(x)\,\cos(2\pi mx)\, dx=\left\{ \begin{array}{cc}
0 & \;\textrm{ for n odd }\\
\left(-\right)^{1+n/2}n!/\left(2\pi m\right)^{n} & \;\textrm{ for n even }\end{array}\right.\label{eq:}\end{equation}

\end_inset 

 and 
\begin_inset Formula \begin{equation}
\int_{0}^{1}B_{n}(x)\,\sin(2\pi mx)\, dx=\left\{ \begin{array}{cc}
0 & \;\textrm{ for n even }\\
\left(-\right)^{(n+1)/2}n!/\left(2\pi m\right)^{n} & \;\textrm{ for n odd }\end{array}\right.\label{eq:}\end{equation}

\end_inset 

 Applying the Fourier-representation 
\begin_inset Formula $U_{B}$
\end_inset 

 to these to these vector components makes it immediately clear how the
 eigenvalue of 
\begin_inset Formula $1/2^{n}$
\end_inset 

 is associated with the eigenvector 
\begin_inset Formula $B_{n}$
\end_inset 

.
 
\layout Subsection

The Hurwitz Zeta Eigenfunctions
\layout Standard

The Fourier representation also makes it clear that any vector with vector
 components 
\begin_inset Formula $a_{n}=1/n^{s}$
\end_inset 

 will be an eigenvector of 
\begin_inset Formula $U_{B}$
\end_inset 

 associated with the eigenvalue 
\begin_inset Formula $\lambda=1/2^{s}$
\end_inset 

.
 In coordinate space, one may write these eigenfunctions as 
\begin_inset Formula \begin{equation}
\beta(x;s)=2\Gamma(s+1)\sum_{n=1}^{\infty}\frac{\exp(2\pi inx)}{\left(2\pi n\right)^{s}}\label{eq:}\end{equation}

\end_inset 

 which transform as 
\begin_inset Formula $U_{B}\beta(x;s)=2^{-s}\beta(x;s)$
\end_inset 

.
 Given the nature of summation, this series is strictly convergent for any
 complex-valued 
\begin_inset Formula $s$
\end_inset 

 with 
\begin_inset Formula $\Re s>1$
\end_inset 

.
 This series recreates the Bernoulli polynomials for integer values of 
\begin_inset Formula $n$
\end_inset 

, so for example, 
\begin_inset Formula $\Re\beta(x;2)=B_{2}(x)$
\end_inset 

 and 
\begin_inset Formula $\Im\beta(x;3)=B_{3}(x)$
\end_inset 

 and generally 
\begin_inset Formula $\Re\left[\left(-i\right)^{n}\beta(x;n)\right]=-B_{n}(x)$
\end_inset 

.
 Equivalently, the Fourier series for the Bernoulli Polynomials can be written
 as 
\begin_inset Formula \begin{eqnarray}
B_{n}(x) & = & -\Gamma(n+1)\sum_{k=1}^{\infty}\frac{\exp(2\pi ikx)+\exp(2\pi ik(1-x))}{\left(2\pi ik\right)^{n}}\label{eq:}\\
 & = & \frac{-(-i)^{n}}{2}\left(\beta(x;n)+\beta(1-x;n)\right)\nonumber \end{eqnarray}

\end_inset 

See, for example 
\begin_inset LatexCommand \cite[Thm. 12.19]{Apo76}

\end_inset 

.
 It turns out that these eigenfunctions are essentially a form of the Hurwitz
 Zeta function 
\begin_inset Formula \begin{equation}
\zeta(s,x)=\sum_{n=0}^{\infty}\frac{1}{\left(n+x\right)^{s}}\label{eq:}\end{equation}

\end_inset 

 and that, in fact, the Hurwitz Zeta itself is an eigenfunction, with eigenvalue
 
\begin_inset Formula $2^{s-1}$
\end_inset 

.
 One may confirm this by following a very old-fashioned recipe for obtaining
 the functional relation for a zeta-like sum.
 Start by expressing the gamma function as 
\begin_inset Formula \begin{equation}
\int_{0}^{\infty}dy\, e^{-2\pi ny}y^{s-1}=\frac{\Gamma(s)}{(2\pi n)^{s}}\label{eq:}\end{equation}

\end_inset 

 Substituting into the expression for 
\begin_inset Formula $\beta$
\end_inset 

 and performing the sum, one may write 
\begin_inset Formula \begin{equation}
\beta(x;s)=2s\int_{0}^{\infty}dy\,\frac{y^{s-1}}{\exp\left(-2\pi i(x+iy)\right)-1}\label{eq:}\end{equation}

\end_inset 

 Then, following a traditional trick 
\begin_inset LatexCommand \cite[pp 13 ff]{Edw74}

\end_inset 

, re-write this as a contour integral 
\begin_inset Formula \begin{equation}
\beta(x;s)=\frac{-is}{\sin\pi s}\oint\frac{(-y)^{s}}{\exp\left(-2\pi i(x+iy)\right)-1}\;\frac{dy}{y}\label{eq:}\end{equation}

\end_inset 

 where the contour is taken to extend from 
\begin_inset Formula $+\infty+i\epsilon$
\end_inset 

, running just above the positive real axis, to the origin, circling the
 origin in a clockwise fashion, and returning to 
\begin_inset Formula $+\infty-i\epsilon$
\end_inset 

 just under the real axis.
 The contour essentially encloses the cut of the logarithm in the expression
 
\begin_inset Formula $(-y)^{s}=\exp s\,\log(-y)$
\end_inset 

.
 The old fashioned recipe calls for closing the contour at infinity (in
 a counter-clockwise direction) and then taking the dubious step of asserting
 Cauchy's Theorem to equate the integral around the cut to the sum of the
 poles, where we note that we have a pole whenever 
\begin_inset Formula $x+iy=n$
\end_inset 

 for some integer 
\begin_inset Formula $n$
\end_inset 

.
 By doing this we get the formal summation 
\begin_inset Formula \begin{equation}
\frac{i\sin\pi s}{s}\beta(x;s)=\exp\left(\frac{i\pi s}{2}\right)\sum_{n=-\infty}^{\infty}(n-x)^{s-1}\label{eq:}\end{equation}

\end_inset 

 This is a 
\begin_inset Quotes eld
\end_inset 

formal sum
\begin_inset Quotes erd
\end_inset 

, since the preceding steps required taking 
\begin_inset Formula $\Re s>1$
\end_inset 

 whereas now one needs to take 
\begin_inset Formula $\Re s<0$
\end_inset 

.
 This is a bit of jiggery-pokery that is common for this type of presentation;
 a different set of tools is required to do better.
 So we proceed, ignoring these difficulties.
 Re-write this sum as 
\begin_inset Formula \begin{equation}
\frac{i\sin\pi s}{s}\beta(x;s)=\exp\left(\frac{i\pi s}{2}\right)\left[\sum_{n=0}^{\infty}(n+(1-x))^{s-1}+e^{-i\pi(s-1)}\sum_{n=0}^{\infty}(n+x)^{s-1}\right]\label{eq:}\end{equation}

\end_inset 

 where we were mindful to rotate counter-clockwise for 
\begin_inset Formula $n<0$
\end_inset 

 when replacing 
\begin_inset Formula $(-)^{n}$
\end_inset 

 by 
\begin_inset Formula $e^{-i\pi n}$
\end_inset 

 instead of the sloppy and incorrect 
\begin_inset Formula $e^{i\pi n}$
\end_inset 

.
 Recognizing the sums as the Hurwitz Zeta, this then gives the desired result:
 
\begin_inset Formula \begin{equation}
\beta(x;s)=\frac{is}{\sin\pi s}\left[e^{-i\pi s/2}\zeta(1-s,x)-e^{i\pi s/2}\zeta(1-s,1-x)\right]\label{eq:}\end{equation}

\end_inset 

 It is straightforward to invert this and solve for 
\begin_inset Formula $\zeta$
\end_inset 

; one gets 
\begin_inset Formula \begin{equation}
\zeta(1-s,x)=\frac{1}{2s}\left[e^{-i\pi s/2}\beta(x;s)+e^{i\pi s/2}\beta(1-x;s)\right]\label{eq:}\end{equation}

\end_inset 

 thus proving the assertion that the Hurwitz Zeta is an eigenfunction of
 the Bernoulli Operator, with eigenvalue 
\begin_inset Formula $2^{s-1}$
\end_inset 

.
 To verify the correctness of the above steps, expand the exponentials in
 terms of their real and imaginary parts, to find that 
\layout Standard


\begin_inset Formula \begin{equation}
\zeta(z,x)=\frac{2\Gamma(1-z)}{\left(2\pi\right)^{1-z}}\left[\sin\left(\frac{\pi z}{2}\right)\sum_{n=1}^{\infty}\frac{\cos(2\pi nx)}{n^{1-z}}+\cos\left(\frac{\pi z}{2}\right)\sum_{n=1}^{\infty}\frac{\sin(2\pi nx)}{n^{1-z}}\right]\label{eq:}\end{equation}

\end_inset 

 which agrees with standard textbook presentations of the Hurwitz Zeta;
 see for example 
\begin_inset LatexCommand \cite[Thm 12.6]{Apo76}

\end_inset 

.
\layout Subsection

Visualizing the Hurwitz Zeta Eigenfunctions
\layout Standard

Perhaps one surprising aspect of this result is that the Hurwitz Zeta eigenfunct
ions appear to be smooth, since one is conditioned to expect that the only
 continuous-spectrum eigenfunctions of a Frobenius-Perron operator are fractal.
 Thus, it is worthwhile to take a few minutes to get acquainted with the
 shape and nature of the zeta.
 This section shows a number of graphs, and discusses the analytic structure
 of the eigenvectors.
 We'll see that the eigenfunctions are 
\begin_inset Formula $C^{\infty}$
\end_inset 

 in 
\begin_inset Formula $x$
\end_inset 

 for almost all 
\begin_inset Formula $x$
\end_inset 

: everywhere except at the endpoints 
\begin_inset Formula $x=0,1$
\end_inset 

.
 Thus, these are not 
\begin_inset Quotes eld
\end_inset 

physical
\begin_inset Quotes erd
\end_inset 

 eigenstates, if 
\begin_inset Formula $C^{\infty}$
\end_inset 

 for all 
\begin_inset Formula $x$
\end_inset 

 is placed as a demand for being 
\begin_inset Quotes eld
\end_inset 

physical
\begin_inset Quotes erd
\end_inset 

.
 We also find that there are eigenfunctions that have eigenvalues greater
 than one; these, while quite smooth and differentiable, are not square-integrab
le: they are divergent at 
\begin_inset Formula $x=0,1$
\end_inset 

.
 However, in all other respects, the eigenfunctions are analytically well-behave
d, even if a bit 
\begin_inset Quotes eld
\end_inset 

lumpy
\begin_inset Quotes erd
\end_inset 

 and uneven.
 
\layout Standard

There is a countably infinite degeneracy of eigenfunctions for a give eigenvalue.
 We can see this by writing 
\begin_inset Formula $s=\sigma+i\tau$
\end_inset 

 in terms of its real and imaginary components.
 Then the eigenvalue is 
\begin_inset Formula $\lambda=2^{-s}=2^{-\sigma}\exp(-i\tau\ln2)$
\end_inset 

 and it belongs to a family of eigenvectors with 
\begin_inset Formula $\tau'=\tau+2\pi n/\ln2$
\end_inset 

 for 
\begin_inset Formula $n\in\mathbb{Z}$
\end_inset 

.
 The next five figures show some of these, graphed in various ways.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Real Part of Symmetric Beta
\layout Standard


\begin_inset Graphics
	filename zeta-2.2345-04.png
	width 100text%

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\Re\left[\beta(x;s)+\beta(-x;s)\right]/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that 
\begin_inset Formula $\left|\Gamma(1+s)\right|$
\end_inset 

gets very small as n gets large, and so the normalization brings them to
 visually comparable values.
 Other real values of 
\begin_inset Formula $\sigma$
\end_inset 

 can be understood by recalling that 
\begin_inset Formula $\beta$
\end_inset 

 essentially interpolates between Bernoulli polynomials at integer values
 of 
\begin_inset Formula $\sigma$
\end_inset 

.
 In short, they'll all look more or less like this.
 
\layout Standard

XXX redo this graph to show 
\begin_inset Formula $\Re\left[\beta(x;s)+\beta(1-x;s)\right]/2\left|\Gamma(1+s)\right|$
\end_inset 

 instead XXX
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Magnitude of Symmetric Beta
\layout Standard


\begin_inset Graphics
	filename zeta-abs-2.2345-04.png
	width 100text%

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\left|\beta(x;s)+\beta(-x;s)\right|/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that 
\begin_inset Formula $\left|\Gamma(1+s)\right|$
\end_inset 

gets very small as n gets large, and so the normalization brings them to
 visually comparable values.
 
\layout Standard

XXX redo this graph to show 
\begin_inset Formula $\left|\beta(x;s)+\beta(1-x;s)\right|/2\left|\Gamma(1+s)\right|$
\end_inset 

 instead XXX
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Real part of Beta
\layout Standard


\begin_inset Graphics
	filename zeta-exp-2.2345-04.png
	width 100text%

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\Re\beta(x;s)/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Although these curves clearly look very lumpy, they are 
\begin_inset Formula $C^{\infty}$
\end_inset 

 for all 
\begin_inset Formula $x\in(0,1)$
\end_inset 

 but not at the endpoints 
\begin_inset Formula $x=0,1$
\end_inset 

.
 At the endpoints, the derivative becomes divergent after just a few derivatives
, where the curves are behaving essentially as 
\begin_inset Formula $x^{s-1}$
\end_inset 

 and 
\begin_inset Formula $(1-x)^{s-1}$
\end_inset 

.
 It is impossible to see this pending divergence in the graphs above, because,
 to the naked eye, a graph of, for example, 
\begin_inset Formula $x^{1.5}$
\end_inset 

 is nearly indistinguishable from a graph of 
\begin_inset Formula $x^{2}$
\end_inset 

.
 
\layout Standard

Although these curves appear to be sine-wave-like, it is perhaps more correct
 to think of them as being Bernoulli-polynomial-like.
 That is, to better understand what eigenvectors near some arbitrary value
 of 
\begin_inset Formula $s$
\end_inset 

 look like, its useful to think of what the polynomial 
\begin_inset Formula $B_{\left\lfloor \Re s\right\rfloor }(x)$
\end_inset 

 looks like.
 Recall, however, that, of course, 
\begin_inset Formula $B_{k}(x)$
\end_inset 

 for 
\begin_inset Formula $k\geq3$
\end_inset 

 is very sine-wave like! Note also that the first curve shown above, for
 
\begin_inset Formula $n=0$
\end_inset 

, generally resembles 
\begin_inset Formula $B_{2}(x)$
\end_inset 

 which is a parabola.
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Magnitude of Beta 
\layout Standard


\begin_inset Graphics
	filename zeta-emag-2.2345-04.png
	width 100text%

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\left|\beta(x;s)\right|/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that curiously, these functions seem to be smoother for larger x and
 seem to have vanishing ripples as x approaches zero.
 Curiously, the ripples seem to have a period of oscillation of approximately
 
\begin_inset Formula $nx$
\end_inset 

 in the interval 
\begin_inset Formula $x\in\left[1/2,1\right]$
\end_inset 

, and then repeating again between 1, 1/2, 1/4, 1/8, ...
 We'll gain some insight into these ripples in a later section, where we
 will analyze a sawtooth map having the same oscillatory behavior, for which
 the Hurwitz Zeta also plays a role as an eigenvector.
 That is, there is a certain sense in which the above curves are self-similar,
 with the curve in the interval 
\begin_inset Formula $x\in\left[2^{-k-1},2^{-k}\right]$
\end_inset 

 reprises the curve in the interval 
\begin_inset Formula $x\in\left[1/2,1\right]$
\end_inset 


\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Argument of Beta
\layout Standard


\begin_inset Graphics
	filename zeta-arg-2.2345-04.png
	width 100text%

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\arg\beta(x;s)/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 
\end_inset 

 
\layout Standard

There are eigenfunctions with eigenvalues greater than one, essentially
 because the Hurwitz Zeta can be analytically continued to everywhere on
 the complex plane except for a simple pole at 
\begin_inset Formula $z=1$
\end_inset 

.
 Examining these eigenfunctions, one quickly discovers that these are not
 square-integrable: they have singularities located at 
\begin_inset Formula $x=0,1$
\end_inset 

.
 That is, for for 
\begin_inset Formula $\Re z>0$
\end_inset 

, the Hurwitz Zeta 
\begin_inset Formula $\zeta(z,x)$
\end_inset 

 has a clear singularity 
\begin_inset Formula $x^{-z}$
\end_inset 

 at 
\begin_inset Formula $x=0$
\end_inset 

.
 We remove this explicitly, and write 
\begin_inset Formula \begin{eqnarray}
\frac{\sin\pi s}{is}\beta(x;s) & = & \frac{e^{-i\pi s/2}}{x^{1-s}}-\frac{e^{i\pi s/2}}{(1-x)^{1-s}}+\nonumber \\
 &  & e^{-i\pi s/2}\left(\zeta(1-s,x)-x^{s-1}\right)-e^{i\pi s/2}\left(\zeta(1-s,1-x)-(1-x)^{s-1}\right)\label{eq:}\end{eqnarray}

\end_inset 

 The first part of the equation above encapsulates the singularities at
 
\begin_inset Formula $x=0,1$
\end_inset 

 that occur when working with eigenvalues 
\begin_inset Formula $\left|\lambda\right|=\left|2^{-s}\right|>1$
\end_inset 

, that is, with 
\begin_inset Formula $\Re s<0$
\end_inset 

.
 The remaining term is well-behaved and is shown in figure xx
\begin_inset LatexCommand \ref{cap:The-non-singular-part}

\end_inset 

xx.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption


\begin_inset LatexCommand \label{cap:The-non-singular-part}

\end_inset 

The Non-Singular Part of the Divergent Eigenfunctions
\layout Standard


\begin_inset Graphics
	filename zeta-diverge.png
	width 100text%

\end_inset 


\layout Standard

This figure shows 
\begin_inset Formula \[
\eta_{even}(x;\sigma)=\frac{\cos\pi\sigma/2}{\sigma}\left[\beta(x;\sigma)+\beta(1-x;\sigma)\right]-x^{\sigma-1}-(1-x)^{\sigma-1}\]

\end_inset 

 and 
\begin_inset Formula \[
\eta_{odd}(x;\sigma)=\frac{\sin\pi\sigma/2}{\sigma}\left[\beta(x;\sigma)-\beta(1-x;\sigma)\right]-x^{\sigma-1}+(1-x)^{\sigma-1}\]

\end_inset 

 for a value of 
\begin_inset Formula $\sigma=-3.3$
\end_inset 

, corresponding to an eigenvalue of 
\begin_inset Formula $9.85=2^{3.3}$
\end_inset 

.
 Except for the singularity, we see that the finite part of these eigenfunctions
 is very well behaved.
 
\end_inset 

 
\layout Standard

Note that when 
\begin_inset Formula $\left|\lambda\right|=\left|2^{-s}\right|<1/2$
\end_inset 

, that is, when 
\begin_inset Formula $\Re s>1$
\end_inset 

, there is no singularity, and 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 is finite on the entire interval 
\begin_inset Formula $x\in[0,1]$
\end_inset 

 including the endpoints.
 For 
\begin_inset Formula $1/2<\Re s\leq1$
\end_inset 

 there is a bit of funny-business at the endpoints, that is, there is a
 weak divergence there, but the function overall remains square-integrable.
 Things break loose after that, with the exception of 
\begin_inset Formula $s=0$
\end_inset 

, where we have 
\begin_inset Formula $\beta(x;0)=-1$
\end_inset 

, a constant independent of 
\begin_inset Formula $x$
\end_inset 

.
 This essentially follows from the nature of differentiation on the Bernoulli
 polynomials, which we'll see below.
 Note, however, that for 
\begin_inset Formula $s$
\end_inset 

 near zero, the function 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 has severe ringing artifacts in 
\begin_inset Formula $x$
\end_inset 

, suffering from a variation of Gibbs Phenomenon.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Ringing
\layout Standard


\begin_inset Graphics
	filename zeta-gibbs.png
	width 100text%

\end_inset 


\layout Standard

This figure shows ringing/Gibbs phenomenon as 
\begin_inset Formula $s$
\end_inset 

 approaches zero.
 In the limit of 
\begin_inset Formula $s=0$
\end_inset 

, we expect the real part of 
\begin_inset Formula $\beta$
\end_inset 

 to approach the trivial eigenfunction 
\begin_inset Formula $\lim_{s\rightarrow0^{+}}\Re\beta(x;s)=-B_{0}(x)=-1$
\end_inset 

.
 As this graph shows, the function is indeed trying very desperately to
 get flat, with not much success.
 The ringing occurs only at 
\begin_inset Formula $s=0$
\end_inset 

; there is no problem with convergence near larger integers, where 
\begin_inset Formula $\lim_{s\rightarrow n}\Re(-i)^{s}\beta(x;s)=-B_{n}(x)$
\end_inset 

 converges very smoothly and cleanly.
\end_inset 


\layout Standard

We conclude by noting that 
\begin_inset Formula $\beta$
\end_inset 

 is 
\begin_inset Formula $C^{\infty}$
\end_inset 

 for 
\begin_inset Formula $x\in(0,1)$
\end_inset 

 but not at the endpoints 
\begin_inset Formula $x=0,1$
\end_inset 

.
 This can be easily seen by writing the derivative 
\begin_inset Formula \begin{equation}
\frac{d}{dx}\beta(x;s)=2\pi i\beta(x;s-1)\label{eq:}\end{equation}

\end_inset 

 and so even if we start with 
\begin_inset Formula $\Re s>1$
\end_inset 

, each derivative carries us one step closer into the danger zone.
 
\layout Subsection

The Kernel
\layout Standard

What is the kernel of 
\begin_inset Formula $U_{B}$
\end_inset 

? It is the set of functions that have only odd Fourier terms.
 
\layout Standard

That is, for any integer 
\begin_inset Formula $k\in\mathbb{Z}$
\end_inset 

 we have 
\begin_inset Formula $U_{B}\cos2\pi(2k+1)x=0$
\end_inset 

 and so we write 
\begin_inset Formula $\cos2\pi(2k+1)x\in K\left[U_{B}\right]$
\end_inset 

 and likewise 
\begin_inset Formula $\sin2\pi(2k+1)x\in K\left[U_{B}\right]$
\end_inset 

.
 
\layout Standard

This implies that 'half' of all square-integrable functions are in the kernel.
 This is a huge space.
 The quotient space of the implied isomorphism thus has the Bernoulli polynomial
s as the representative elements.
 This is I think the correct way to relate coordinate space to the Hilbert
 space, is by means of the quotient space generated by the kernel of the
 time-evolution operator.
 
\layout Subsection

The Continuous Fractal Spectrum
\layout Standard

An alternate set of eigenvectors with a continuous spectrum are given by
 
\begin_inset Formula \begin{equation}
\phi_{z,k}(x)=\sum_{n=0}^{\infty}z^{n}\exp\left(2\pi i\;2^{n}\left(2k+1\right)x\right)\label{eq:}\end{equation}

\end_inset 

 and have eigenvalue 
\begin_inset Formula $z$
\end_inset 

: that is 
\begin_inset Formula $[U_{B}\phi_{z,k}](x)=z\phi_{z,k}(x)$
\end_inset 

.
 Again, for a given fixed eigenvalue, they have a countably infinite degeneracy,
 labelled by the parameter 
\begin_inset Formula $k\in\mathbb{Z}$
\end_inset 

.
 These eigenfunctions are fractal, as can be readily seen from the graph[xxx
 need figure].
 Since they are a generalization of the Takagi-Landsberg Curve, they have
 an 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

 symmetry, as discussed in an earlier chapter.
 As is typical for Takagi-type curves, these eigenfunctions are differentiable
 a finite number of times before they become differentiable nowhere.
 For example, for 
\begin_inset Formula $1/2<\left|z\right|<1$
\end_inset 

, these are continuous with respect to 
\begin_inset Formula $x$
\end_inset 

 but nowhere differentiable.
 For 
\begin_inset Formula $1/2^{m+1}<\left|z\right|<1/2^{m}$
\end_inset 

, these are everywhere 
\begin_inset Formula $m$
\end_inset 

 times differentiable with respect to 
\begin_inset Formula $x$
\end_inset 

, but nowhere 
\begin_inset Formula $m+1$
\end_inset 

 times differentiable.
 
\layout Standard

We can express these in terms of the Hurwitz Zeta eigenfunctions by considering
 the sum 
\begin_inset Formula \begin{eqnarray}
\sum_{k=0}^{\infty}z^{\ln_{2}(2k+1)}\phi_{z,k}(x) & = & \sum_{n=1}^{\infty}z^{\ln_{2}n}\exp\left(2\pi inx\right)\nonumber \\
 & = & \sum_{n=1}^{\infty}n^{\ln_{2}z}\exp\left(2\pi inx\right)\label{eq:}\end{eqnarray}

\end_inset 

 Thus, we see that we should equate 
\begin_inset Formula $s=-\ln_{2}z$
\end_inset 

 so that the eigenvalues are 
\begin_inset Formula $z=2^{-s}$
\end_inset 

.
 Multiplying by the appropriate factors, we get the desired relationship
 
\begin_inset Formula \begin{equation}
\beta(x;s)=2\Gamma(s+1)\left(2\pi\right)^{-s}\sum_{k=0}^{\infty}\left(2k+1\right)^{-s}\phi_{z,k}(x)\label{eq:}\end{equation}

\end_inset 

 That is, the Hurwitz zeta eigenfunctions are expressible as a linear combinatio
n of the fractal eigenfunctions.
 Essentially, either set of eigenfunctions can be used to form a set of
 basis states for the Bernoulli Map transfer operator.
 The Hurwitz Zeta eigenfunctions span a larger space than the fractal eigenfunct
ions, as the Hurwitz Zeta is well-defined for eigenvalues with 
\begin_inset Formula $\left|z\right|>1$
\end_inset 

, whereas the fractal eigenfunctions are not.
 Of course, as we saw above, the Hurwitz Zeta eigenfunctions are not square-inte
grable when 
\begin_inset Formula $\left|z\right|>1$
\end_inset 

, which invalidates their consideration for most 
\begin_inset Quotes eld
\end_inset 

physical
\begin_inset Quotes erd
\end_inset 

 uses.
 Note also that through careful work, the fractal eigenfunctions can probably
 be extended to 
\begin_inset Formula $\left|z\right|>1$
\end_inset 

 continuous-nowhere functions by considering their transformation properties
 under 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 This would be in analogy to the exploration of the derivative of the Takagi
 Curve, which, as we saw in an earlier chapter, can be defined as the Cantor
 polynomial, built out of the digits of the binary expansion of 
\begin_inset Formula $x$
\end_inset 

.
 
\layout Standard

We can explicitly demonstrate the change of basis by defining 
\begin_inset Formula \begin{equation}
\beta_{n}(x;s)\equiv\beta(x;s+2\pi ni/\ln2)\label{eq:}\end{equation}

\end_inset 

 which all share the same eigenvalue: 
\begin_inset Formula $U_{B}\beta_{n}=2^{-s}\beta_{n}$
\end_inset 

.
 We can then restrict 
\begin_inset Formula $s$
\end_inset 

 to a principle domain 
\begin_inset Formula $-\pi<\Im s\,\ln2=\arg\, z<\pi$
\end_inset 

 .
 The change of basis can now be written explicitly as 
\begin_inset Formula \begin{equation}
\beta_{n}(x;s)=\sum_{k=0}^{\infty}F_{nk}\phi_{z,k}(x)\label{eq:}\end{equation}

\end_inset 

 where the matrix elements are 
\begin_inset Formula \begin{equation}
F_{nk}=2\Gamma\left(s+1+\frac{2\pi ni}{\ln2}\right)\left(2\pi(2k+1)\right)^{-s}\exp\left[-2n\pi i\frac{\ln\pi(2k+1)}{\ln2}\right]\label{eq:}\end{equation}

\end_inset 

 Presumably 
\begin_inset Formula $F$
\end_inset 

 is invertible; either set of eigenstates span the space.
 Given that one set of basis functions are clearly fractal, while the other
 is clearly analytic, it would be interesting to describe the space of functions
 spanned by these basis states.
 That is, given an arbitrary sequence 
\begin_inset Formula $\{ b_{n}|b_{n}\in\mathbb{C}\}$
\end_inset 

, describe the nature of the functions 
\begin_inset Formula \begin{equation}
\sum_{n=0}^{\infty}b_{n}\beta_{n}(x;s)\label{eq:}\end{equation}

\end_inset 

 considered as functions of 
\begin_inset Formula $x$
\end_inset 

 or alternately of 
\begin_inset Formula $s$
\end_inset 

.
 
\layout Standard

The modular group symmetries of the fractal eigenfunctions do not seem to
 provide any interesting insight into the zeta, since they do not mix or
 permute eigenstates.
 For example, applying the generator 
\begin_inset Formula $g$
\end_inset 

 on the fractal eigenstates gives
\begin_inset Formula \begin{equation}
g\phi_{zk}(x)=\phi_{zk}\left(\frac{x}{2}\right)=\exp((2k+1)\pi ix)+z\phi_{zk}(x)\label{eq:}\end{equation}

\end_inset 

 and so one might hope that since the zetas are a linear combination of
 the fractal eigenfunctions, one might get some new insight.
 However, doing this gives the sum 
\layout Standard


\begin_inset Formula \begin{equation}
g\beta(x;s)=\beta(\frac{x}{2};s)=\frac{2\Gamma(s+1)}{(2\pi)^{s}}\sum_{k=0}^{\infty}\frac{\exp2\pi ix(2k+1)}{(2k+1)^{s}}+2^{-s}\beta(x;s)\label{eq:}\end{equation}

\end_inset 

 as a symmetry, but the evaluation of the sum in the middle yields 
\begin_inset Formula $\beta(x/2;s)-2^{-s}\beta(x;s)$
\end_inset 

 and so one gets a trivial relationship and no insight in particular.
\layout Subsection

Modular Group Symmetry and the Takagi Representation 
\layout Standard

Yet another way to understand the solution of the Bernoulli Map is to note
 that it can be written as 
\begin_inset Formula \begin{equation}
\left[U_{B}f\right](x)=\frac{1}{2}\left(f(g_{D}(x))+f(r_{D}g_{D}r_{D}(x)\right)\label{eq: bern modular}\end{equation}

\end_inset 

 where 
\begin_inset Formula $g_{D}(x)=x/2$
\end_inset 

 and 
\begin_inset Formula $r_{D}(x)=1-x$
\end_inset 

 are the generators of the dyadic representation of the Modular Group 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 Thus, we expect that we should be able to build eigenfunctions out of any
 functions 
\begin_inset Formula $f(x)$
\end_inset 

 that posses a Modular Group symmetry.
\layout Standard

As we saw in a previous chapter, the Takagi Curve fits this bill.
 Start with the triangle wave/tent map: 
\begin_inset Formula \begin{equation}
\tau(x)=\left\{ \begin{array}{ccc}
2(x-\left\lfloor x\right\rfloor ) & \;\textrm{ when }\; & 0\leq x-\left\lfloor x\right\rfloor \leq1/2\\
2(1-x+\left\lfloor x\right\rfloor ) & \;\textrm{ when }\; & 1/2\leq x-\left\lfloor x\right\rfloor \leq1\end{array}\right.\label{eq:}\end{equation}

\end_inset 

 which has the property that it doubles under iteration: 
\begin_inset Formula $\tau^{k}(x)=\tau(2^{k-1}x)$
\end_inset 

.
 The iterated tent map behaves sort-of like a shift state, in that 
\begin_inset Formula \begin{equation}
\left[U_{B}\tau^{k}\right](x)=\tau^{k-1}(x)\label{eq:}\end{equation}

\end_inset 

 although it does not terminate properly for a shift state: 
\begin_inset Formula \begin{equation}
\left[U_{B}\tau\right](x)=\frac{1}{2}\label{eq:}\end{equation}

\end_inset 

 (a true shift state would vanish on the final iteration).
 Thus we see that the Takagi curve transforms as 
\begin_inset Formula \begin{equation}
\left[U_{B}t_{w}\right](x)=\frac{1}{2}+wt_{w}(x)\label{eq:}\end{equation}

\end_inset 

 under the Bernoulli operator.
 We can use this to build an eigenfunction 
\begin_inset Formula \begin{equation}
b_{w}(x)=\frac{-1}{2(1-w)}+t_{w}(x)\label{eq:}\end{equation}

\end_inset 

 so that 
\begin_inset Formula $U_{B}b_{w}=wb_{w}$
\end_inset 

.
 On closer examination, we can see that this eigenvalue has the same countable
 degeneracy we've seen previously.
 That is, we can replace 
\begin_inset Formula $x$
\end_inset 

 on the right-hand-side of the equations above by 
\begin_inset Formula $(2j+1)x$
\end_inset 

 for 
\begin_inset Formula $j\in\mathbb{N}$
\end_inset 

 to obtain the set of eigenfunctions
\begin_inset Formula \begin{equation}
b_{w,j}(x)=\frac{-1}{2(1-w)}+t_{w}((2j+1)x)\label{eq:}\end{equation}

\end_inset 

 all sharing the eigenvalue 
\begin_inset Formula $w.$
\end_inset 

 It follows immediately that, just as above, we should be able to express
 the Hurwitz Zeta eigenfunctions 
\begin_inset Formula $\beta_{n}(x;s)$
\end_inset 

 for fixed 
\begin_inset Formula $s=-\ln_{2}w$
\end_inset 

 as a linear combination of the 
\begin_inset Formula $b_{w,j}$
\end_inset 

 if the 
\begin_inset Formula $b_{w,j}$
\end_inset 

 are a complete set of eigenstates for the eigenvalue 
\begin_inset Formula $w$
\end_inset 

.
 One special case is immediately apparent: the Takagi Curve 
\begin_inset Formula $t_{1/4}(x)$
\end_inset 

 is a parabola, corresponding to the Bernoulli polynomial 
\begin_inset Formula $B_{2}(x)$
\end_inset 

.
\layout Standard

XXX finish me; give the explicit expressions between 
\begin_inset Formula $b_{w,j}$
\end_inset 

 and 
\begin_inset Formula $\beta_{n}$
\end_inset 

.
\layout Standard

We can also obtain other eigenvectors by starting with the Takagi curves
 that transform under the higher-dimensional representations of 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 The equation 
\begin_inset LatexCommand \ref{eq: bern modular}

\end_inset 

 implies that any curve that transforms under a linear representation of
 the Modular Group can be used to build an eigenfunction of the Bernoulli
 Map.
 We exclude the non-linear representations, since we don't know how to build
 a vector space out of a non-linear operator.
 Thus, if 
\begin_inset Formula $t_{w}^{(n)}((2j+1)x)$
\end_inset 

 is a Takagi curve that transforms under an 
\begin_inset Formula $n$
\end_inset 

-dimensional representation, then 
\begin_inset Formula $U_{B}$
\end_inset 

 is represented by 
\begin_inset Formula $(g_{n}+r_{n}g_{n}r_{n})/2$
\end_inset 

 where 
\begin_inset Formula $r_{n},g_{n}\in GL(n,\mathbb{R})$
\end_inset 

 are the generators of that 
\begin_inset Formula $n$
\end_inset 

-dimensional representation of 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 Solving the eigenvalue equation then amounts to diagonalizing the (finite-dimen
sional) matrix 
\begin_inset Formula $(g_{n}+r_{n}g_{n}r_{n})/2$
\end_inset 

.
\layout Standard

For a fixed eigenvalue 
\begin_inset Formula $w$
\end_inset 

, we expect a countably infinite degeneracy built out of the curves 
\begin_inset Formula $t_{w}^{(n)}((2j+1)x)$
\end_inset 

.
 Again, if these form a complete set of eigenstates, then we expect to be
 able to write out 
\begin_inset Formula $\beta_{n}(x;s)$
\end_inset 

 as a linear combination of these, and v.v.
\layout Standard

XXX finish me ..
 Give explicit expression for the higher-dim reps and in particular,the
 matrix from 
\begin_inset Formula $b_{w,j}$
\end_inset 

 and 
\begin_inset Formula $\beta_{n}$
\end_inset 

 in explicit detail.
 Also develop the lower-dim reps (move in opposite direction).
 This material should probably go into the chapter on the Takagi Curves,
 instead of here,right ...
 ???
\layout Standard

Note this is a ladder of isomorphisms between the different dimensional
 reps.
 Note also the ability to choose different set of basis funcs for the higher-dim
 Takagi Curves, viz, any polynomial of degree 
\begin_inset Formula $n-2$
\end_inset 

.
\layout Subsection

The Topological Zeta
\layout Standard

The topological zeta of the Bernoulli operator can be computed very easily
 in the polynomial basis because we know the eigenvalues and these form
 a simple series.
 We'll define the Bernoulli topological zeta as
\begin_inset Formula \begin{equation}
\zeta_{B}(t)\equiv\frac{1}{\det\left[\mathbb{I}-tU_{B}\right]}\label{eq:}\end{equation}

\end_inset 

 We start by noting its inverse: 
\begin_inset Formula \begin{eqnarray}
\det\left[\mathbb{I}-tU_{B}\right] & = & \prod_{n=0}^{\infty}\left(1-t\;2^{-n}\right)\nonumber \\
 & = & 1-t\sum_{j=0}^{\infty}2^{-j}+t^{2}\sum_{j=0}^{\infty}2^{-j}\sum_{\begin{array}{c}
k=0\\
k\neq j\end{array}}^{\infty}2^{-k}-t^{3}...\nonumber \\
 & = & 1-2t+\frac{8}{3}t^{2}-\frac{16}{7}t^{3}+\frac{128}{105}t^{4}-...\label{eq:}\end{eqnarray}

\end_inset 

 Successive terms of this series are hard to compute, and it would be interestin
g to know what the generating function for this series is.
 The series appears to have a circle of convergence of radius one.
 The zeta can be computed directly by working with its logarithm: 
\begin_inset Formula \begin{eqnarray}
\log\zeta_{B}(t) & = & \log\prod_{n=0}^{\infty}\left(1-t\;2^{-n}\right)^{-1}\nonumber \\
 & = & -\sum_{n=0}^{\infty}\log\left(1-t\;2^{-n}\right)\nonumber \\
 & = & \sum_{k=1}^{\infty}\frac{t^{k}}{k}\;\frac{2^{k}}{2^{k}-1}\nonumber \\
 & = & -\log(1-t)+\sum_{k=1}^{\infty}\frac{t^{k}}{k}\;\frac{1}{2^{k}-1}\label{eq:}\end{eqnarray}

\end_inset 

 Thus we have 
\begin_inset Formula $\textrm{Tr}U_{B}^{k}=2^{k}/(2^{k}-1)$
\end_inset 

.
 Of some curiosity is the proximity of the Erdos-Borwein constant: 
\begin_inset Formula \begin{eqnarray}
1.6066... & = & \sum_{n=1}^{\infty}\frac{1}{2^{n}-1}\nonumber \\
 & = & \sum_{n=1}^{\infty}\frac{d(n)}{2^{n}}\label{eq:}\end{eqnarray}

\end_inset 

 which marks the first appearance of a classical number-theoretic function
 in the proceedings so far: 
\begin_inset Formula $d(n)$
\end_inset 

 is the number of divisors of 
\begin_inset Formula $n$
\end_inset 

.
 This arises from the Lambert series
\begin_inset Formula \begin{equation}
\sum_{n=1}^{\infty}d(n)x^{n}=\sum_{n=1}^{\infty}\frac{x^{n}}{1-x^{n}}\label{eq:}\end{equation}

\end_inset 

The sum 
\begin_inset Formula \begin{equation}
E(t)=\sum_{k=1}^{\infty}\frac{t^{k}}{1-2^{-k}}\label{eq:}\end{equation}

\end_inset 

 can be re-summed as a Lambert series, namely, 
\begin_inset Formula \begin{equation}
E(t)=\sum_{k=1}^{\infty}b_{k}2^{-k}\label{eq:}\end{equation}

\end_inset 

 where 
\begin_inset Formula \begin{equation}
b_{k}=\sum_{n|k}(2t)^{n}\label{eq:}\end{equation}

\end_inset 

 The analytic/meromorphic structure of this zeta is not clear; its dull
 within the unit disk, and its not quite obvious what the continuation is
 outside of the disk.
 XXX ToDo: get the full analytic structure.
\layout Subsection

Curiosities
\layout Standard

We list here some intriguing forms that suggest further relationships.
\layout Standard

The Pochhammer symbol 
\begin_inset Formula $(a)_{n}=\Gamma(a+n)/\Gamma(n)$
\end_inset 

 obeys a 
\emph on 
dimidiation formula
\emph default 
 that is reminiscent of the Bernoulli map:
\layout Standard


\begin_inset Formula \begin{eqnarray*}
(a)_{2n} & = & 2^{2n}\left(\frac{a}{2}\right)_{n}\left(\frac{a+1}{2}\right)_{n}\\
(a)_{2n+1} & = & 2^{2n+1}\left(\frac{a}{2}\right)_{n}\left(\frac{a+1}{2}\right)_{n}\end{eqnarray*}

\end_inset 


\layout Section

Conclusions
\layout Standard

Apologies for the format of this paper.
 It's a veritable candy store of goodies; there are all these yummy toys
 to play with, which one first?
\begin_inset LatexCommand \BibTeX[plain]{/home/linas/linas/fractal/paper/fractal}

\end_inset 


\the_end
