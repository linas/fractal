#LyX 1.3 created this file. For more info see http://www.lyx.org/
\lyxformat 221
\textclass amsart
\language english
\inputencoding auto
\fontscheme pslatex
\graphics default
\paperfontsize default
\spacing single 
\papersize Default
\paperpackage a4
\use_geometry 0
\use_amsmath 1
\use_natbib 0
\use_numerical_citations 0
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\quotes_times 2
\papercolumns 1
\papersides 1
\paperpagestyle default

\layout Title

The Bernoulli Operator
\layout Author

Linas Vepstas <linas@linas.org>
\layout Date

2 January 2004 (revised 18 October 2006)
\layout Abstract

This paper reviews a raft of related ideas surrounding the Bernoulli operator.
 The Bernoulli operator is the transfer operator or Frobenius-Perron operator
 of the Bernoulli map.
 The Bernoulli map is a simple map of the unit interval onto itself, which
 has the effect of discarding the leading binary digit of the binary expansion
 of a number upon every iteration.
 This map has been well studied in the literature, and much, if not most,
 of what is presented here is well-known.
 
\layout Abstract

If there is anything new here, then perhaps it is a representation of the
 Bernoulli map eigenfunctions in terms of the Takagi curve (or Blancmange
 curve).
 In particular, it is shown that the Hurwitz-zeta function basis for the
 continuous spectrum is just a linear combination of the Takagi curves,
 and vice-versa.
 I find this curious and important somehow: the Blancmange curve has an
 explicitly fractal self-similarity given by the dyadic monoid.
 The dyadic monoid is the monoid that describes the self-similarity of the
 infinite binary tree, and is a subset of the modular group 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
\layout Abstract

This paper is part of a set of chapters that explore the relationship between
 the real numbers, the modular group, and fractals.
\layout Section

The Bernoulli operator
\layout Standard

THIS IS A SET OF WORKING NOTES.
 Its somewhat loosely structured, sometimes messy, and occasionally assumes
 familiarity with the authors other writings and/or a general knowledge
 of dynamical systems.
 The intro hasn't been written yet.
\layout Standard

The general layout is:
\layout Standard

-- Define the Bernoulli operator, demonstrate some of its eigenfunctions
 and eigenvalues.The presentation is a simplified variant of the material
 in 
\begin_inset LatexCommand \cite{Dri99}

\end_inset 

.
 
\layout Standard

-- Present the Hurwitz Zeta eigenfunctions
\layout Standard

-- Present the topological zeta function
\layout Standard

The Bernoulli map and Bernoulli operator appear in many forms and guises
 throughout the theory of dynamical systems.
 
\layout Standard

Some of the sections, including the section on orthogonality and completeness,
 are awkwardly presented.
 The topic is subtle, the notation is not elegant.
 In a certain sense, this paper illustrates all the wrong ways in which
 to present the notions of completeness with regards to a Hilbert space.
 The notions of what is fractal, and what is differentiable, and what is
 an operator, and what is an eigenvalue, is muddied as a result.
 The journey, however faulty, is still educational, though.
 To do: Riesz representation thm.
\layout Section

Introduction
\layout Standard

The method of the transfer operator was introduced by David Ruelle[need
 ref] as a powerful mechanism for studying the nature of iterated maps.
 The transfer operator, sometimes called the Frobenius-Perron operator,
 or the Ruelle-Frobenius-Perron operator, provides a means to escape the
 narrow confines of point-set topology when considering an iterated function,
 and instead explore the function using wildly different topologies.
 In its most concrete form, it is a linear operator acting on a Banach space
 of functions.
 However, the structure and the properties of the operator depend very much
 on which space of functions one considers.
 In the following, the spaces of polynomial functions of the real numbers,
 as well as the space of square-integrable functions will be considered.
 More broadly, one may also consider the transfer operator acting on other
 spaces, such as the 
\begin_inset Formula $p$
\end_inset 

-adic numbers, endowed with unusual topologies: in particular, with the
 so called 
\begin_inset Quotes eld
\end_inset 

product topology
\begin_inset Quotes erd
\end_inset 

 whose basis are the cylinder sets.
 In this topology, the transfer operator can be made to resemble the lattice
 models of theoretical physics, such as the Ising model, thus offering additiona
l means of gaining insight.
\begin_inset LatexCommand \cite{May91}

\end_inset 

 
\layout Standard

It is easiest to begin with the concrete definition.
 Consider a function 
\begin_inset Formula $g:[0,1]\to[0,1]$
\end_inset 

, that is, a function mapping the unit interval of the real number line
 to itself.
 Upon iteration, the function may have fixed points or orbits of points.
 These orbits may be attractors or repellors, or may be neutral saddle points.
 The action of 
\begin_inset Formula $g$
\end_inset 

 may be ergodic or chaotic, strong-mixing or merely topologically mixing.
 In any case, the language used to discuss 
\begin_inset Formula $g$
\end_inset 

 is inherently based on either the point-set topology of the unit interval,
 or the 
\begin_inset Quotes eld
\end_inset 

natural
\begin_inset Quotes erd
\end_inset 

 topology on the unit interval, the topology of open sets.
 
\layout Standard

A shift in perspective may be gained not by considering how 
\begin_inset Formula $g$
\end_inset 

 acts on points or open sets, but instead by considering how 
\begin_inset Formula $g$
\end_inset 

 acts on distributions on the unit interval.
 Intuitively, one might consider a dusting of points on the unit interval,
 with a local density given by 
\begin_inset Formula $\rho(x)$
\end_inset 

 at point 
\begin_inset Formula $x\in[0,1]$
\end_inset 

, and then consider how this dusting or density evolves upon iteration by
 
\begin_inset Formula $g$
\end_inset 

.
 This verbal description may be given form as 
\begin_inset Formula \begin{equation}
\rho^{\prime}(y)=\int_{0}^{1}\,\delta\left(y-g(x)\right)\rho(x)\; dx\label{eq:transfer-dirac}\end{equation}

\end_inset 

 where 
\begin_inset Formula $\rho^{\prime}(y)$
\end_inset 

 is the new density at point 
\begin_inset Formula $y=g(x)$
\end_inset 

 and 
\begin_inset Formula $\delta$
\end_inset 

 is the Dirac delta function.
 
\layout Standard

In this viewpoint, 
\begin_inset Formula $g$
\end_inset 

 becomes an operator that maps densities 
\begin_inset Formula $\rho$
\end_inset 

 to other densities 
\begin_inset Formula $\rho^{\prime}$
\end_inset 

, or notationally, 
\begin_inset Formula \begin{equation}
\mathcal{L}_{g}\rho=\rho^{\prime}\label{eq:}\end{equation}

\end_inset 

 The operator 
\begin_inset Formula $\mathcal{L}_{g}$
\end_inset 

 is called the transfer operator or the Ruelle-Frobenius-Perron operator.
 It is not hard to see that it is a linear operator, in that 
\begin_inset Formula \begin{equation}
\mathcal{L}_{g}(a\rho_{1}+b\rho_{2})=a\mathcal{L}_{g}\rho_{1}+b\mathcal{L}_{g}\rho_{2}\label{eq:}\end{equation}

\end_inset 

 for constants 
\begin_inset Formula $a,b$
\end_inset 

 and densities 
\begin_inset Formula $\rho_{1},\rho_{2}$
\end_inset 

.
 
\layout Standard

When the function 
\begin_inset Formula $g$
\end_inset 

 is differentiable, and doesn't have a vanishing derivative, the integral
 formulation of the transfer operator above can be rephrased in a more convenien
t form, as 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{g}\rho\right]\left(y\right)=\sum_{x:y=g(x)}\frac{\rho(x)}{\left|dg(x)/dx\right|}\label{eq: transfer-jacobi}\end{equation}

\end_inset 

 where the sum is presumed to extend over at most a countable number of
 points.
 If these conditions do not hold, a transfer operator can still be defined,
 although more care must be taken in its definition.
\layout Standard

One generalization should be immediately apparent: although the word 
\begin_inset Quotes eld
\end_inset 

density
\begin_inset Quotes erd
\end_inset 

 implies that 
\begin_inset Formula $\rho$
\end_inset 

 is a smooth map from the unit interval to the non-negative reals, no such
 requirement need to be enforced: 
\begin_inset Formula $\rho$
\end_inset 

 may be a map from the unit interval to any ring 
\begin_inset Formula $R$
\end_inset 

, and it need not be smooth, differentiable or even continuous.
 This generalization gives a very rich structure to 
\begin_inset Formula $\mathcal{L}_{g}$
\end_inset 

: the precise form of 
\begin_inset Formula $\mathcal{L}_{g}$
\end_inset 

 will take will depend very strongly on 
\begin_inset Formula $R$
\end_inset 

, whether its the reals 
\begin_inset Formula $\mathbb{R}$
\end_inset 

, the complex numbers 
\begin_inset Formula $\mathbb{C}$
\end_inset 

, or some other field or ring.
 It will also depend strongly on whether one restricts oneself to smooth
 functions, continuous functions, square-integrable functions, or some other
 function space.
 An adequate study requires reference to the specific topology that the
 function space is endowed with; many different topologies may be considered.
 That is, in general, one must consider 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 to be an operator acting on a topological space endowed with multiplication
 and addition, that is, a topological vector space.
 A precise definition of the transfer operator is given in the next section,
 as being the pushforward onset of measureable, sigma-additive functions.
 
\layout Standard

The structure of 
\begin_inset Formula $\mathcal{L}_{g}$
\end_inset 

 also depends on the topology applied to the unit interval.
 Besides the natural topology on the real number line, the unit interval
 can be given several other topologies.
 The most important of these is the Cantor set topology, or the 
\begin_inset Formula $p$
\end_inset 

-adic topology.
 Here, one considers the unit interval 
\begin_inset Formula $[0,1]$
\end_inset 

 to consist of the set of strings 
\begin_inset Formula \begin{equation}
\Omega=\left\{ \sigma=(\sigma_{0},\sigma_{1},\sigma_{2},\ldots)\,:\,\sigma_{k}\in\left\{ 0,1,\ldots,p-1\right\} \,,\, x=\sum_{k=0}^{\infty}\sigma_{k}p^{-(k+1)}\;,\, x\in[0,1]\right\} \label{eq:}\end{equation}

\end_inset 

 Intuitively, this set is simply the set of all the digits of a base-
\begin_inset Formula $p$
\end_inset 

 expansion of the real numbers 
\begin_inset Formula $x\in[0,1]$
\end_inset 

.
 The connection with physics comes from the realization that this set can
 be understood to be the collection of all field configurations of a one-dimensi
onal, one-sided lattice, where each lattice location can take on one of
 
\begin_inset Formula $p$
\end_inset 

 values.
 Such lattices are commonly given the product topology, where the open sets
 are the cylinder sets consisting of substrings of sequences of letters.
 The topology also has a natural measure, derived from the length of letter
 sequences.
 Aside from the 
\begin_inset Formula $p$
\end_inset 

-adic expansion above, one also has the continued fraction expansion, where
 one considers the sequence of integers making up the continued fraction
 
\begin_inset Formula \begin{equation}
x=[0;\sigma_{1},\sigma_{2},\sigma_{3},\ldots]=\frac{1}{\sigma_{1}+\frac{1}{\sigma_{2}+\frac{1}{\sigma_{3}+\ldots}}}\label{eq:}\end{equation}

\end_inset 

 where each 
\begin_inset Formula $\sigma_{k}$
\end_inset 

 is a positive integer; the entire sequence again be given a product topology,
 although the measure is constructed differently.
\layout Standard

In most of what follows, the topological rings that will be considered will
 be very concrete: these will be the Banach spaces of polynomial functions,
 and of square-integrable functions.
 Some exploration of the lattice-model topology is explored in 
\begin_inset LatexCommand \cite{Ve-L06}

\end_inset 

.
 Since 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 is a linear operator, the primary focus of study is to characterize it
 along traditional lines: find its representations, find the eigenvectors
 and eigenspaces associated with each representation, discuss any symmetries
 and pertinent isomorphisms these spaces might have.
 
\layout Standard

The eigenfunctions of 
\begin_inset Formula $\mathcal{L}_{g}$
\end_inset 

 are called Ruelle resonances [need citation], elaborate.
\layout Section

Measure-theoretic description
\layout Standard

The clearest and most precise, although also the most abstract formulation
 of the transfer operator is in the language of measure theory, where it
 is seen to be same thing as the push-forward.
 In this language, it gains a topological setting, which helps clarify how
 the transfer function behaves on spaces of functions.
 This definition is formulated, from first principles, below.
 
\layout Standard

Consider a topological space 
\begin_inset Formula $X$
\end_inset 

, and a field 
\begin_inset Formula $F$
\end_inset 

 over the reals 
\begin_inset Formula $\mathbb{R}$
\end_inset 

.
 Here, 
\begin_inset Formula $F$
\end_inset 

 may be taken to be 
\begin_inset Formula $\mathbb{R}$
\end_inset 

 itself, or 
\begin_inset Formula $\mathbb{C}$
\end_inset 

 or some more general field over 
\begin_inset Formula $\mathbb{R}$
\end_inset 

.
 The restriction of 
\begin_inset Formula $F$
\end_inset 

 being a field over the reals is necessitated by the measure-theoretic manipulat
ions below, where functions will need to be multiplied by the real-valued
 measure.
 
\layout Standard

One may then define the algebra of functions 
\begin_inset Formula $\mathcal{F}(X)$
\end_inset 

 on 
\begin_inset Formula $X$
\end_inset 

 as the set of functions 
\begin_inset Formula $f\in\mathcal{F}(X)$
\end_inset 

 such that 
\begin_inset Formula $f:X\to F$
\end_inset 

.
 The algebra of functions is a vector space, in that given two functions
 
\begin_inset Formula $f_{1},f_{2}\in\mathcal{F}(X)$
\end_inset 

, their linear combination 
\begin_inset Formula $af_{1}+bf_{2}$
\end_inset 

 is also an element of 
\begin_inset Formula $\mathcal{F}(X)$
\end_inset 

; thus 
\begin_inset Formula $f_{1}$
\end_inset 

 and 
\begin_inset Formula $f_{2}$
\end_inset 

 may be interpreted to be the vectors of a vector space.
 An algebra is a vector space for which the multiplication of vectors is
 defined.
 In the case of 
\begin_inset Formula $\mathcal{F}(X)$
\end_inset 

, the multiplication is the pair-wise multiplication of functions; that
 is, the product 
\begin_inset Formula $f_{1}f_{2}$
\end_inset 

 is defined as the function 
\begin_inset Formula $(f_{1}f_{2})(x)=f_{1}(x)\cdot f_{2}(x)$
\end_inset 

, and so 
\begin_inset Formula $f_{1}f_{2}$
\end_inset 

 is again an element of 
\begin_inset Formula $\mathcal{F}(X)$
\end_inset 

.
 Sine one clearly has 
\begin_inset Formula $f_{1}f_{2}=f_{2}f_{1}$
\end_inset 

, multiplication is commutative, and so 
\begin_inset Formula $\mathcal{F}(X)$
\end_inset 

 is also a commutative ring.
\layout Standard

The space 
\begin_inset Formula $\mathcal{F}(X)$
\end_inset 

 may be endowed with a topology.
 The coarsest topology on 
\begin_inset Formula $\mathcal{F}(X)$
\end_inset 

 is the 
\emph on 
weak topology
\emph default 
, which is obtained by taking 
\begin_inset Formula $\mathcal{F}(X)$
\end_inset 

 to be the space that is dual to 
\begin_inset Formula $X$
\end_inset 

.
 As a vector space, 
\begin_inset Formula $\mathcal{F}(X)$
\end_inset 

 may be endowed with a norm 
\begin_inset Formula $\left\Vert f\right\Vert $
\end_inset 

.
 For example, one may take the norm to be the 
\begin_inset Formula $L^{p}$
\end_inset 

-norm 
\begin_inset Formula \begin{equation}
\left\Vert f\right\Vert _{p}=\left(\int\left|f(x)\right|^{p}dx\right)^{1/p}\label{eq:}\end{equation}

\end_inset 

 For 
\begin_inset Formula $p=2$
\end_inset 

, this norm converts the space 
\begin_inset Formula $\mathcal{F}(X)$
\end_inset 

 into the Hilbert space of square-integrable functions on 
\begin_inset Formula $X$
\end_inset 

.
 Other norms are possible, in which case 
\begin_inset Formula $\mathcal{F}(X)$
\end_inset 

 has the structure of a Banach space rather than a Hilbert space.
\layout Standard

Consider now a homomorphism of topological spaces 
\begin_inset Formula $g:X\to Y$
\end_inset 

.
 This homomorphism induces the pullback 
\begin_inset Formula $g^{*}:\mathcal{F}(Y)\to\mathcal{F}(X)$
\end_inset 

 on the algebra of functions, by mapping 
\begin_inset Formula $f\mapsto g^{*}(f)=f\circ g$
\end_inset 

 so that 
\begin_inset Formula $f\circ g:Y\to F$
\end_inset 

.
 The pullback is a linear operator, in that 
\begin_inset Formula \begin{equation}
g^{*}(af_{1}+bf_{2})=ag^{*}(f_{1})+bg^{*}(f_{2})\label{eq:}\end{equation}

\end_inset 

 This is very easily demonstrated by considering how 
\begin_inset Formula $g^{*}f$
\end_inset 

 acts at a point: 
\begin_inset Formula $(g^{*}f)(x)=(f\circ g)(x)=f(g(x))$
\end_inset 

 and so the linearity of 
\begin_inset Formula $g^{*}$
\end_inset 

 on 
\begin_inset Formula $af_{1}+bf_{2}$
\end_inset 

 follows trivially.
\layout Standard

One may construct an analogous mapping, but going in the opposite direction,
 called the push-forward: 
\begin_inset Formula $g_{*}:\mathcal{F}(X)\to\mathcal{F}(Y)$
\end_inset 

.
 There are two ways of defining a push-forward.
 One way is to define it in terms of the sheaves of functions on subsets
 of 
\begin_inset Formula $X$
\end_inset 

 and 
\begin_inset Formula $Y$
\end_inset 

.
 The sheaf-theoretic description is more or less insensitive to the ideas
 of measurability, whereas this is important to the definition of the transfer
 operator, as witnessed by the appearance of the Jacobian determinant in
 equation 
\begin_inset LatexCommand \ref{eq: transfer-jacobi}

\end_inset 

.
 By contrast, the measure-theoretic push-forward captures this aspect.
 It may be defined as follows.
\layout Standard

One endows the spaces 
\begin_inset Formula $X$
\end_inset 

 and 
\begin_inset Formula $Y$
\end_inset 

 with sigma-algebras 
\begin_inset Formula $(X,\mathcal{A})$
\end_inset 

 and 
\begin_inset Formula $(Y,\mathcal{B})$
\end_inset 

, so that 
\begin_inset Formula $\mathcal{A}$
\end_inset 

 is the set of subsets of 
\begin_inset Formula $X$
\end_inset 

 obeying the axioms of a sigma-algebra, and similarly for 
\begin_inset Formula $\mathcal{B}$
\end_inset 

.
 A mapping 
\begin_inset Formula $g:X\to Y$
\end_inset 

 is called 
\begin_inset Quotes eld
\end_inset 

measurable
\begin_inset Quotes erd
\end_inset 

 if, for all Borel sets 
\begin_inset Formula $B\in\mathcal{B}$
\end_inset 

, one has the pre-image 
\begin_inset Formula $g^{-1}(B)\in\mathcal{A}$
\end_inset 

 being a Borel set as well.
 Thus, a measurable mapping induces a push-forward on the sigma-algebras:
 that is, one has a push-forward 
\begin_inset Formula $g_{*}:\mathcal{F}(\mathcal{A})\to\mathcal{F}(\mathcal{B})$
\end_inset 

 given by 
\begin_inset Formula $f\mapsto g_{*}(f)=f\circ g^{-1}$
\end_inset 

, which is defined by virtue of the measurability of 
\begin_inset Formula $g$
\end_inset 

.
 The push-forward is a linear operator, in that 
\begin_inset Formula $g_{*}(af_{1}+bf_{2})=ag_{*}(f_{1})+bg_{*}(f_{2})$
\end_inset 

.
 
\layout Standard

One regains the transfer operator as defined in equation 
\begin_inset LatexCommand \ref{eq: transfer-jacobi}

\end_inset 

 by considering the limiting behavior of the push-forward on progressively
 smaller sets.
 That is, one has
\layout Theorem

The transfer operator is the point-set topology limit of the measure-theoretic
 push-forward.
 
\layout Proof

The proof that follows is rather informal, so as to keep it simple.
 It is aimed mostly at articulating the language and terminology of measure
 theory.
 The result is none-the-less rigorous, if taken within the confines of the
 definitions presented.
\layout Proof

Introduce a measure 
\begin_inset Formula $\mu:\mathcal{A}\to\mathbb{R}^{+}$
\end_inset 

 and analogously 
\begin_inset Formula $\nu:\mathcal{B}\to Y$
\end_inset 

.
 The mapping 
\begin_inset Formula $g$
\end_inset 

 is measure-preserving if 
\begin_inset Formula $\nu$
\end_inset 

 is a push-forward of 
\begin_inset Formula $\mu$
\end_inset 

, that is, if 
\begin_inset Formula $\nu=g_{*}\mu=\mu\circ g^{-1}$
\end_inset 

.
 The measure is used to rigorously define integration on 
\begin_inset Formula $X$
\end_inset 

 and 
\begin_inset Formula $Y$
\end_inset 

.
 Elements of 
\begin_inset Formula $\mathcal{F}(\mathcal{A})$
\end_inset 

 can be informally understood to be integrals, in that 
\begin_inset Formula $f(A)$
\end_inset 

 for 
\begin_inset Formula $A\in\mathcal{A}$
\end_inset 

 may be understood as 
\begin_inset Formula \begin{equation}
f(A)=\int_{A}\tilde{f}(z)d\mu(z)=\int_{A}\tilde{f}(z)\left|\mu^{\prime}(z)\right|dz\label{eq:}\end{equation}

\end_inset 

 where 
\begin_inset Formula $\left|\mu^{\prime}(x)\right|$
\end_inset 

 is to be understood as the Jacobean determinant at a point 
\begin_inset Formula $x\in X$
\end_inset 

.
 Here, 
\begin_inset Formula $\tilde{f}$
\end_inset 

 can be understood to be a function that is being integrated over the set
 
\begin_inset Formula $A$
\end_inset 

, whose integral is denoted by 
\begin_inset Formula $f(A)$
\end_inset 

.
 The value of 
\begin_inset Formula $\tilde{f}$
\end_inset 

 at a point 
\begin_inset Formula $x\in X$
\end_inset 

 can be obtained by means of a limit.
 One considers a sequence of 
\begin_inset Formula $A\in\mathcal{A}$
\end_inset 

, each successively smaller than the last, each containing the point 
\begin_inset Formula $x$
\end_inset 

.
 One then has 
\begin_inset Formula \begin{equation}
\lim_{\overrightarrow{A\ni x}}\,\frac{f(A)}{\mu(A)}=\tilde{f}(x)\label{eq:}\end{equation}

\end_inset 

 which can be intuitively proved by considering 
\begin_inset Formula $A$
\end_inset 

 so small that 
\begin_inset Formula $\tilde{f}$
\end_inset 

 is approximately constant over 
\begin_inset Formula $A$
\end_inset 

: 
\begin_inset Formula \begin{equation}
f(A)=\int_{A}\tilde{f}(z)d\mu(z)\approx\tilde{f}(x)\int_{A}d\mu=\tilde{f}(x)\mu(A)\label{eq:}\end{equation}

\end_inset 

 To perform the analogous limit for the push-forward, one must consider
 a point 
\begin_inset Formula $y\in Y$
\end_inset 

 and sets 
\begin_inset Formula $B\in\mathcal{B}$
\end_inset 

 containing 
\begin_inset Formula $y$
\end_inset 

.
 In what follows, it is now assumed that 
\begin_inset Formula $g:X\to Y$
\end_inset 

 is a multi-sheeted countable covering of 
\begin_inset Formula $Y$
\end_inset 

 by 
\begin_inset Formula $X$
\end_inset 

.
 By this it is meant that for any 
\begin_inset Formula $y$
\end_inset 

 that is not a branch-point, there is a nice neighborhood of 
\begin_inset Formula $y$
\end_inset 

 such that its pre-image consists of the union of an at most countable number
 of pair-wise disjoint sets.
 That is, for 
\begin_inset Formula $y$
\end_inset 

 not a branch point, and for 
\begin_inset Formula $B\ni y$
\end_inset 

 sufficiently small, one may write 
\begin_inset Formula \begin{equation}
g^{-1}(B)=A_{1}\cup A_{2}\cup\cdots=\bigcup_{j=1}^{k}A_{j}\label{eq:}\end{equation}

\end_inset 

 where 
\begin_inset Formula $k$
\end_inset 

 is either finite or stands for 
\begin_inset Formula $\infty$
\end_inset 

, and where 
\begin_inset Formula $A_{i}\cap A_{j}=\varnothing$
\end_inset 

 for all 
\begin_inset Formula $i\ne j$
\end_inset 

.
 A branch points, such a decomposition may not be possible.
 The axiom of sigma-additivity guarantees that such multi-sheeted covers
 behave just the way one expects integrals to behave: in other words, one
 has 
\begin_inset Formula \begin{equation}
\mu\left(g^{-1}(B)\right)=\mu\left(\bigcup_{j=1}^{k}A_{j}\right)=\sum_{j=1}^{k}\mu\left(A_{j}\right)\label{eq:}\end{equation}

\end_inset 

 whenever the collection of 
\begin_inset Formula $A_{j}$
\end_inset 

 are pair-wise disjoint.
 Similarly, in order to have the elements 
\begin_inset Formula $f\in\mathcal{F}(\mathcal{A})$
\end_inset 

 behave as one expects integrals to behave, one must restrict 
\begin_inset Formula $\mathcal{F}(\mathcal{A})$
\end_inset 

 to contain only sigma-additive functions as well, so that 
\begin_inset Formula \begin{equation}
f\left(g^{-1}(B)\right)=f\left(\bigcup_{j=1}^{k}A_{j}\right)=\sum_{j=1}^{k}f\left(A_{j}\right)\label{eq:}\end{equation}

\end_inset 

 As the set 
\begin_inset Formula $B$
\end_inset 

 is taken to be smaller and smaller, the sets 
\begin_inset Formula $A_{j}$
\end_inset 

 will become smaller as well.
 Denote by 
\begin_inset Formula $x_{j}$
\end_inset 

 the corresponding limit point of each 
\begin_inset Formula $A_{j}$
\end_inset 

, so that 
\begin_inset Formula $g(x_{j})=y$
\end_inset 

 and the pre-image of 
\begin_inset Formula $y$
\end_inset 

 consists of these points: 
\begin_inset Formula $g^{-1}(y)=\left\{ x_{1},x_{2},\cdots\left|\, g(x_{j})=y\right.\right\} $
\end_inset 

.
 One now combines these provisions to write 
\begin_inset Formula \begin{eqnarray}
\left[g_{*}\tilde{f}\right](y) & = & \lim_{\overrightarrow{B\ni y}}\,\left[\frac{\left(g_{*}f\right)(B)}{\nu(B)}\right]\nonumber \\
 & = & \lim_{\overrightarrow{B\ni y}}\,\left[\frac{\left(f\circ g^{-1}\right)(B)}{\nu(B)}\right]\nonumber \\
 & = & \lim_{\overrightarrow{A_{j}\ni g^{-1}(y)}}\,\frac{f\left(A_{1}\cup A_{2}\cup\cdots\right)}{\nu(B)}\nonumber \\
 & = & \lim_{\overrightarrow{A_{j}\ni g^{-1}(y)}}\,\frac{\sum_{j=1}^{k}f\left(A_{j}\right)}{\nu(B)}\nonumber \\
 & = & \sum_{j=1}^{k}\tilde{f}\left(x_{j}\right)\lim_{\overrightarrow{A_{j}\ni x_{j}}}\,\frac{\mu\left(A_{j}\right)}{\nu(B)}\label{eq:}\end{eqnarray}

\end_inset 

 The limit in the last line of this sequence of manipulations may be interpreted
 in two ways, depending on whether one wants to define the measure 
\begin_inset Formula $\nu$
\end_inset 

 on 
\begin_inset Formula $Y$
\end_inset 

 to be the push-forward of 
\begin_inset Formula $\mu$
\end_inset 

, or not.
 If one does take it to be the push-forward, so that 
\begin_inset Formula $\nu=g_{*}\mu$
\end_inset 

, then one has 
\begin_inset Formula \begin{equation}
\lim_{\overrightarrow{A_{j}\ni x_{j}}}\,\frac{\mu\left(A_{j}\right)}{g_{*}\mu(B)}=\frac{1}{\left|g^{\prime}\left(x_{j}\right)\right|}\label{eq:}\end{equation}

\end_inset 

 where 
\begin_inset Formula $\left|g^{\prime}\left(x_{j}\right)\right|$
\end_inset 

 is the Jacobian determinant of 
\begin_inset Formula $g$
\end_inset 

 at 
\begin_inset Formula $x_{j}$
\end_inset 

.
 This last is a standard result of measure theory, and can be intuitively
 proved by noting that 
\begin_inset Formula $g\left(A_{j}\right)=B$
\end_inset 

, so that 
\begin_inset Formula \begin{equation}
\nu\left(B\right)=\int_{A_{j}}g^{\prime}(z)\, d\mu(z)\approx g^{\prime}\left(x_{j}\right)\mu\left(A_{j}\right)\label{eq:}\end{equation}

\end_inset 

 for 
\begin_inset Quotes eld
\end_inset 

small enough
\begin_inset Quotes erd
\end_inset 

 
\begin_inset Formula $B$
\end_inset 

.
 Assembling this with the previous result, one has 
\begin_inset Formula \begin{equation}
\left[g_{*}\tilde{f}\right](y)=\sum_{x_{j}\in g^{-1}(y)}\frac{\tilde{f}\left(x_{j}\right)}{\left|g^{\prime}\left(x_{j}\right)\right|}\label{eq:Transfer-point}\end{equation}

\end_inset 

 which may be easily recognized as equation 
\begin_inset LatexCommand \ref{eq: transfer-jacobi}

\end_inset 

.
 This concludes the proof of the theorem, that the transfer operator is
 just the point-set topology limit of the push-forward.
 
\layout Standard

Some curious lemmas show up along the way.
 
\layout Lemma

One has 
\begin_inset Formula \begin{equation}
\sum_{j=1}^{k}\frac{1}{\left|g^{\prime}\left(x_{j}\right)\right|}=1\label{eq:}\end{equation}

\end_inset 

 
\layout Proof

This follows by taking the limit 
\begin_inset Formula $\overrightarrow{A_{j}\ni x_{j}}$
\end_inset 

 of 
\begin_inset Formula \[
\frac{\mu\left(A_{j}\right)}{g_{*}\mu(B)}=\frac{\mu\left(A_{j}\right)}{\sum_{i=1}^{k}\mu\left(A_{i}\right)}\]

\end_inset 

 and then summing over 
\begin_inset Formula $j$
\end_inset 

.
\layout Corollary

The constant function is an eigenvector of the transfer operator, associated
 with the eigenvalue one.
 
\layout Proof

This may be proved in two ways.
 From the viewpoint of point-sets, one simply takes 
\begin_inset Formula $\tilde{f}=\mbox{const.}$
\end_inset 

 in equation 
\begin_inset LatexCommand \ref{eq:Transfer-point}

\end_inset 

, and applies the lemma above.
 From the viewpoint of the sigma-algebra, this is nothing more than the
 seemingly vacuous statement that 
\begin_inset Formula $\nu=g_{*}\mu$
\end_inset 

.
 This becomes slightly less vacuous if one takes the space 
\begin_inset Formula $Y=X$
\end_inset 

, so that 
\begin_inset Formula $g:X\to X$
\end_inset 

 is a measure-preserving map: 
\begin_inset Formula $g_{*}\mu=\mu$
\end_inset 

.
 
\layout Standard

The last corollary suggests two interesting conjectures.
 
\layout Conjecture

(Ruelle-Perron-Frobenius theorem).
 All transfer operators are compact, bounded operators.
\layout Standard

This conjecture is of course just the Frobenius-Perron theorem, recast in
 the context of measure theory.
 I suppose it has a simple-enough proof that the author hasn't yet seen
 or re-discovered.
 XXX Don't let this sit there.
 XXX, Ref:Dunford and Schwartz.
 A corollary to the Perron-Frobenius theorem is then:
\layout Corollary

(Haar measure) For any homomorphisms 
\begin_inset Formula $g:X\to X$
\end_inset 

, one may find a measure 
\begin_inset Formula $\mu$
\end_inset 

 such that 
\begin_inset Formula $g_{*}\mu=\mu$
\end_inset 

; that is, every homomorphism 
\begin_inset Formula $g$
\end_inset 

 of 
\begin_inset Formula $X$
\end_inset 

 induces a measure 
\begin_inset Formula $\mu$
\end_inset 

 on 
\begin_inset Formula $X$
\end_inset 

 such that 
\begin_inset Formula $g$
\end_inset 

 is a measure-preserving map.
 The measure is unique.
 
\layout Standard

By the Frobenius-Perron theorem, this measure is unique.
 It is, of course the Haar measure, although this seems to be an unusual
 way of finding the Haar measure.
 Sketch of semi-proof: 
\begin_inset Formula $\mu$
\end_inset 

 is a fixed point of 
\begin_inset Formula $g_{*}$
\end_inset 

.
 The fixed point exists because 
\begin_inset Formula $g_{*}$
\end_inset 

is a bounded operator, and the space of measures is compact, and so a bounded
 operator on a compact space will have a fixed point.
 Ref.
 some appropriate fixed-point thm (Ref Dunford and Schwartz).
 To prove uniqueness, we have to show that 
\begin_inset Formula $g$
\end_inset 

 is ergodic, i.e.
 that there are no invariant subspaces, that orbit of 
\begin_inset Formula $g$
\end_inset 

 is the whole space.
 Else, if 
\begin_inset Formula $g$
\end_inset 

 is not ergodic on the whole space, then show that orbit of 
\begin_inset Formula $g$
\end_inset 

 splits or foliates the measure space into a bunch of pairwise disjoint
 leaves, and its ergodic on each leaf, there's a distinct fixed point 
\begin_inset Formula $\mu$
\end_inset 

 in each leaf, and there's a symmetry group that takes 
\begin_inset Formula $\mu$
\end_inset 

 in one leaf to that in another.
 
\layout Standard

XXX argue that push-forward and pullback are opposites, that pullback is
 the Koopman operator.
\layout Standard

XXX Make the note that 
\begin_inset Formula $\rho$
\end_inset 

 is an element of the dual topology.
 That is, given a topology, and a function on topology that blah dual...
 
\layout Section

Transfer Operator of the Bernoulli Map
\layout Standard

The Bernoulli map is an exactly solvable example of deterministic chaos.
 A presentation of this map, its associated transfer operator and its solution
 in terms of polynomial eigenfunctions is given by Driebe
\begin_inset LatexCommand \cite{Dri99}

\end_inset 

.
 This and the next section recaps those results using a simplified development
 and simpler tools.
 The simplified development enables the discussion of more complex scenarios,
 given in later sections.
 
\layout Standard

The Bernoulli map is given by 
\begin_inset Formula \begin{equation}
b(x)=2x-\left\lfloor 2x\right\rfloor \label{eq:}\end{equation}

\end_inset 

 where 
\begin_inset Formula $\left\lfloor x\right\rfloor $
\end_inset 

 denotes the integer part of 
\begin_inset Formula $x$
\end_inset 

.
 The map can be intuitively thought of as popping the leading digit off
 of the binary or 2-adic expansion of 
\begin_inset Formula $x.$
\end_inset 

 This map has a positive Lyapunov exponent and is highly chaotic, as, in
 a certain sense, one can say that the digits of the binary expansion of
 some 'arbitrary' number are unpredictable, and that the orbits of two close-by
 numbers will eventually become 'uncorellated' (after suitably defining
 what we mean by 'arbitrary' and 'unpredictable').
 Closely related is the 
\begin_inset Formula $p$
\end_inset 

-adic map, given by 
\begin_inset Formula \begin{equation}
a(x)=px-\left\lfloor px\right\rfloor \label{eq:}\end{equation}

\end_inset 

 for 
\begin_inset Formula $p$
\end_inset 

 an integer.
 As above, this map has the effect of popping off the leading digit of the
 base-
\begin_inset Formula $p$
\end_inset 

 expansion of 
\begin_inset Formula $x$
\end_inset 

.
 In the same vein, one may also consider the Gauss map 
\begin_inset Formula \begin{equation}
g(x)=\frac{1}{x}-\left\lfloor \frac{1}{x}\right\rfloor \label{eq:}\end{equation}

\end_inset 

 which has the effect of lopping of the leading digit of the continued fraction
 expansion of 
\begin_inset Formula $x$
\end_inset 

.
 What these three maps have in common is that they deal with different (and,
 in a certain sense, inequivalent) representations of the continuum of real
 numbers.
 Each map is chaotic, but in a different way.
\layout Standard

The Ruelle-Frobenius-Perron operator or transfer operator of the Bernoulli
 map is given by
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}f\right](x)=\frac{1}{2}\left[f\left(\frac{x}{2}\right)+f\left(\frac{x+1}{2}\right)\right]\label{eq:Bernoulli operator}\end{equation}

\end_inset 

 which follows directly from equation 
\begin_inset LatexCommand \ref{eq: transfer-jacobi}

\end_inset 

.
 Similarly, the transfer operator for the general 
\begin_inset Formula $p$
\end_inset 

-adic map is 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{p}f\right](x)=\frac{1}{p}\sum_{k=0}^{p-1}f\left(\frac{x+k}{p}\right)\label{eq:p-adic operator}\end{equation}

\end_inset 

 while that for the Gauss map is 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{G}f\right](x)=\sum_{k=1}^{\infty}\;\frac{1}{(x+k)^{2}}\; f\left(\frac{1}{1+x}\right)\label{eq:}\end{equation}

\end_inset 

 This last is known as the Gauss-Kuzmin-Wirsing operator [give ref].
 It is not studied further here, although it has bearing on some results,
 due to its relationship to the representation of the real numbers.
 
\layout Standard

As indicated in the introduction a critical issue and a point of confusion
 is that the operator 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 is not well-defined without also specifying the function space on which
 it acts, and without also specifying the topology to be used on the unit
 interval.
 In particular, the spectrum of eigenvalues and eigenvectors for 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 can vary from being discrete, to being continuous, depending on the the
 function space and the topology.
 The simplest case assumes the natural topology of the reals on the unit
 interval, and takes as the function space the set of orthogonal polynomials
 on the unit interval.
 In this case, the eigenfunctions may be shown to be the Bernoulli polynomials
 
\begin_inset Formula $B_{n}(x)$
\end_inset 

, associated with the eigenvalues 
\begin_inset Formula $2^{-n}$
\end_inset 

.
 That is, one finds that 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}B_{n}\right](x)=\frac{1}{2^{n}}B_{n}(x)\label{eq:}\end{equation}

\end_inset 

where the first few 
\begin_inset Formula $B_{n}(x)$
\end_inset 

 are 
\begin_inset Formula \begin{eqnarray}
B_{0}(x) & = & 1\nonumber \\
B_{1}(x) & = & x-\frac{1`}{2}\nonumber \\
B_{2}(x) & = & x^{2}-x+\frac{1}{6}\nonumber \\
B_{3}(x) & = & x^{3}-\frac{3x^{2}}{2}+\frac{x}{2}\label{eq:}\end{eqnarray}

\end_inset 

 and so on.
 Perhaps the easiest proof that these are the eigenfunctions may be obtained
 by considering the generating function for the Bernoulli polynomials: 
\begin_inset Formula \begin{equation}
G(x,t)=\frac{te^{xt}}{e^{t}-1}=\sum_{n=0}^{\infty}B_{n}(x)\,\frac{t^{n}}{n!}\label{eq:}\end{equation}

\end_inset 

 It is then straight-forward to verify that 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}G\right](x,t)=\frac{1}{2}\left[G\left(\frac{x}{2},t\right)+G\left(\frac{x+1}{2},t\right)\right]=G\left(x,\frac{t}{2}\right)\label{eq:}\end{equation}

\end_inset 

 or equivalently, by applying the linearity of 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

, that
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}G\right](x,t)=\sum_{n=0}^{\infty}\frac{t^{n}}{n!}\left[\mathcal{L}_{B}B_{n}\right](x)=\sum_{n=0}^{\infty}\left(\frac{t}{2}\right)^{n}\frac{B_{n}(x)}{n!}\label{eq:}\end{equation}

\end_inset 

 and then equating the coefficients of the powers of 
\begin_inset Formula $t$
\end_inset 

.
 This derivation follows for the general 
\begin_inset Formula $p$
\end_inset 

-adic case:
\layout Theorem

The eigenvalues of the 
\begin_inset Formula $p$
\end_inset 

-adic transfer operator are the Bernoulli polynomials, and are associated
 with the eigenvalues 
\begin_inset Formula $p^{-n}$
\end_inset 

.
 That is, one has
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{p}B_{n}\right](x)=\frac{1}{p^{n}}B_{n}(x)\label{eq:}\end{equation}

\end_inset 

 
\layout Proof

The proof proceeds as in the above 2-adic case, and hinges on the well-known
 factorization 
\begin_inset Formula \[
w^{p}-1=\left(w-1\right)\left(w^{p-1}+w^{p-2}+\cdots+1\right)\]

\end_inset 

 Here, take 
\begin_inset Formula $w^{p}-1=e^{t}-1$
\end_inset 

, so that 
\begin_inset Formula \begin{eqnarray*}
\left[\mathcal{L}_{p}G\right](x,t) & = & \frac{1}{p}\sum_{k=0}^{p-1}G\left(\frac{x+k}{p},t\right)\\
 & = & \frac{1}{p}\frac{t}{e^{t}-1}\,\sum_{k=0}^{p-1}\exp\left(\frac{(x+k)t}{p}\right)\\
 & = & \frac{t}{p}\;\frac{\left(1+e^{t/p}+e^{2t/p}+\cdots+e^{(p-1)t/p}\right)}{e^{t}-1}\\
 & = & G\left(x,\frac{t}{p}\right)\end{eqnarray*}

\end_inset 

 Then, equating coefficients of powers of 
\begin_inset Formula $t$
\end_inset 

 of the generating function, one obtains the desired result.
 
\layout Standard

The above theorem is a fancy restatement of an old and well-known result
 on the Bernoulli polynomials, namely, the so-called 
\begin_inset Quotes eld
\end_inset 

multiplication theorem
\begin_inset Quotes erd
\end_inset 

 given by Joseph Ludwig Raabe in 1851.
 This is usually given in the much more prosaic form of 
\begin_inset Formula \begin{equation}
B_{n}(px)=p^{n-1}\sum_{k=0}^{p-1}B_{n}\left(x+\frac{k}{p}\right)\label{eq:}\end{equation}

\end_inset 

 but amounts to the same thing.
 What the language of the transfer operator provides is an abstraction that
 allows the multiplication theorem to be examined in a broader fashion.
 In particular, multiplication theorems exist not only for the Bernoulli
 polynomials, but more broadly, including the Gamma function and the Hurwitz
 zeta function.
 These will be re-discovered in later sections.
 
\layout Standard

The following two sections provide an alternate and more abstract and labored
 derivation of the above result.
 The goal of the abstraction is to develop the machinery needed to explore
 the Bernoulli operator in more general topological settings.
 Rather than starting with the Hilbert space of orthogonal polynomials on
 the unit interval, the next section defines a Banach space on monomials,
 and its dual.
 The subsequent section then exposes the matrix elements of the Bernoulli
 operator in this space.
\layout Section

The Polynomial Representation 
\layout Standard

The polynomial eigenvectors of the Bernoulli operator can be derived in
 several ways.
 One seemingly natural approach is to start with a Hilbert space of orthogonal
 polynomials on the unit interval.
 This approach is taken by Driebe
\begin_inset LatexCommand \cite{Dri99}

\end_inset 

, who starts with the Legendre polynomials, rescaled to the unit interval,
 and obtains the resulting Bernoulli polynomials.
 This allows for a derivation of the right eigenvectors, but is then discovered
 to generate difficulties when considering the left eigenvectors.
 This arises because the the Bernoulli operator is not invertible in this
 Hilbert space: it is quite singular, in that 
\begin_inset Formula $\left[\mathcal{L}_{B}f\right]=0$
\end_inset 

 whenever 
\begin_inset Formula $f$
\end_inset 

 is skew about 1/2, that is, whenever 
\begin_inset Formula $f(y)=-f(1/2+y)$
\end_inset 

.
 A set of left eigenvectors can be found, but these are not polynomials
 or even ordinary real-valued functions; rather, they are generalized functions,
 expressed as derivatives of the Dirac delta function.
 From this exercise, one concludes that the starting assumption of envisioning
 the transfer operator acting on a Hilbert space does not provide any particular
 benefit or insight, and thus can be dispensed with.
 
\layout Standard

Generalized functions can be loosely defined as linear functionals from
 the space of functions to the reals.
 In this sense, generalized functions belong to the dual space of a function
 space.
 Given that the left eigenvectors of the Bernoulli operator can be shown
 to belong to such a dual space, it then makes sense to start in this way.
 Thus, for the following, an infinite-dimensional vector space will be construct
ed, with the basis elements being the monomials.
 The generalized functions appear naturally as elements of the dual space.
 The transfer operator then has a direct representation in this space.
 In principle, this infinite-dimensional vector space may be taken to be
 a Banach space; however, the development below does not make any particular
 use of the norm that Banach spaces are equipped with.
 
\layout Standard

This is perhaps a critical point, and deserves being belabored.
 In this section, the vocabulary for discussing an infinite-dimensional
 vector space will be developed.
 The sums appearing herein range formally over the countable infinity.
 However, the language of this section avoids questions of the convergence
 of these sums; the question of convergence can be deferred to later sections,
 when one is manipulating actual operators, and the sums take a concrete
 form.
 Thus, for the development of this section, a discussion of the vector norm,
 a discussion of a metric on the vector space, and a discussion of the topology
 of the vector space can be completely avoided.
 The manipulations are completely algebraic in nature.
 Curiously, this will continue to be the case when these algebraic manipulations
 are applied to the Bernoulli operator.
 That is, the resulting concrete sums will turn out to range over only a
 finite number of non-zero terms, and so the question of convergence will
 not come up.
 As a result, the foundations do not require a notion of norm, metric or
 topology on this vector space.
 When the exceptions to this rule crop up, they will be discussed explicitly.
\layout Standard

XXX the above is false, as there are plenty of places below where it is
 assumed that an infinite number of elts are non-zero.
 Again, need to refine the algebraic vs.
 topological discussion to handle these subtleties XXX.
\layout Standard

Consider an infinite-dimensional vector space 
\begin_inset Formula $V$
\end_inset 

 with a countable ordered set of linearly independent basis vectors 
\begin_inset Formula $e_{k}$
\end_inset 

 labelled by the natural numbers 
\begin_inset Formula $k$
\end_inset 

.
 A general element 
\begin_inset Formula $v\in V$
\end_inset 

 may be written as 
\begin_inset Formula $v=\sum_{k=0}^{\infty}a_{k}e_{k}$
\end_inset 

.
 The dual space 
\begin_inset Formula $V^{*}$
\end_inset 

 is the set of all linear functionals 
\begin_inset Formula $L:V\to\mathbb{R}$
\end_inset 

.
 General elements of the dual space may be written as linear combinations
 of the basis elements 
\begin_inset Formula $e_{k}^{*}$
\end_inset 

, which are the maps such that 
\begin_inset Formula $e_{j}^{*}(e_{k})=\delta_{jk}$
\end_inset 

.
 
\layout Standard

For the space 
\begin_inset Formula $\mathcal{P}$
\end_inset 

 of real-analytic functions on the unit interval, the basis elements may
 be taken to be the monomials 
\begin_inset Formula $e_{k}=x^{k}$
\end_inset 

, so that a general real-analytic function 
\begin_inset Formula $f\in\mathcal{P}$
\end_inset 

 is written as 
\begin_inset Formula \begin{equation}
f(x)=\sum_{n=0}^{\infty}a_{n}x^{n}\label{eq:taylor-f}\end{equation}

\end_inset 

 This may be trivially interpreted as nothing more than the Taylor's series
 for a real-valued function expanded at 
\begin_inset Formula $x=0$
\end_inset 

.
 The correct formalism for discussing the dual space is a bit trickier.
 There is a strong historical desire to represent the linear operators of
 the dual space by means of integrals, that is, to represent the linear
 functional 
\begin_inset Formula $L:\mathcal{P}\to\mathbb{R}$
\end_inset 

 by an integral 
\begin_inset Formula \begin{equation}
\int_{0}^{1}l(x)\, f(x)\, dx\label{eq:}\end{equation}

\end_inset 

 where 
\begin_inset Formula $f\in\mathcal{P}$
\end_inset 

 and 
\begin_inset Formula $l$
\end_inset 

 is some 
\begin_inset Quotes eld
\end_inset 

generalized function
\begin_inset Quotes erd
\end_inset 

.
 Momentarily succumbing to this desire, one finds that the  dual vectors
 may be written as 
\begin_inset Formula \begin{equation}
e_{k}^{*}=\frac{(-1)^{k}}{k!}\delta^{(k)}(x)\label{eq:}\end{equation}

\end_inset 

 where 
\begin_inset Formula $\delta(x)$
\end_inset 

 is the Dirac delta function.
 Thus, one has as the duality relation 
\begin_inset Formula \begin{equation}
e_{j}^{*}\left(e_{k}\right)=\int_{0}^{1}x^{k}\;\frac{(-1)^{j}}{j!}\delta^{(j)}(x)\, dx=\int_{0}^{1}\,\delta(x)\,\frac{d^{j}x^{k}}{dx^{j}}\, dx=\delta_{jk}\label{eq:orthogonality}\end{equation}

\end_inset 

 after integration by parts.
 Generalized functions are less than an ideal mechanism for representing
 elements of the dual space, but it is a mostly workable and consistent
 mechanism; its drawbacks in this particular context will be discussed in
 great detail below.
 The relation 
\begin_inset LatexCommand \ref{eq:orthogonality}

\end_inset 

 above demonstrates orthogonality; one may also show completeness: 
\begin_inset Formula \begin{equation}
\sum_{n=0}^{\infty}e_{n}\otimes e_{n}^{*}=\sum_{n=0}^{\infty}x^{n}\,\frac{(-1)^{n}}{n!}\delta^{(n)}(x)=\delta(x-y)\label{eq:}\end{equation}

\end_inset 

 
\layout Standard

The remainder of the text switches to the quantum mechanical bra-ket notation,
 writing 
\begin_inset Formula $\left|n\right\rangle =e_{n}$
\end_inset 

 and 
\begin_inset Formula $\left\langle n\right|=e_{n}^{*}$
\end_inset 

.
 The orthogonality condition becomes 
\begin_inset Formula $\left\langle n\right|\left.m\right\rangle =\delta_{nm}$
\end_inset 

 while for completeness one writes 
\begin_inset Formula \[
\mathbb{I}=\sum_{n=0}^{\infty}e_{n}\otimes e_{n}^{*}=\sum_{n=0}^{\infty}\left|n\right\rangle \left\langle n\right|\]

\end_inset 

 The re-introduction of the coordinate 
\begin_inset Formula $x$
\end_inset 

 is done by writing 
\begin_inset Formula $\left\langle x\right|\left.m\right\rangle =x^{m}$
\end_inset 

, while for the transpose one writes 
\begin_inset Formula $\left\langle n\right|\left.x\right\rangle =(-1)^{n}\delta^{(n)}(x)/n!$
\end_inset 

.
 The advantage of the bra-ket notation over the use of the 
\begin_inset Formula $e_{k}$
\end_inset 

 is that it can be used to make clear when one is discussing the coordinate
 representation, involving 
\begin_inset Formula $x$
\end_inset 

 or 
\begin_inset Formula $\delta(x)$
\end_inset 

, and when one is discussing the vector space elements in the abstract,
 without reference to the coordinate representation.
 To fully articulate this notation, one may write the Taylor's series as
 
\begin_inset Formula \begin{eqnarray}
f(x) & = & \left\langle x|f\right\rangle \nonumber \\
 & = & \sum_{n=0}^{\infty}\left\langle x|n\right\rangle \left\langle n|f\right\rangle \nonumber \\
 & = & \sum_{n=0}^{\infty}x^{n}\left\langle n|f\right\rangle \nonumber \\
 & = & \sum_{n=0}^{\infty}x^{n}\int dy\left\langle n|y\right\rangle \left\langle y|f\right\rangle \nonumber \\
 & = & \sum_{n=0}^{\infty}x^{n}\int dy(-)^{n}\frac{\delta^{(n)}(y)}{n!}f(y)\nonumber \\
 & = & \sum_{n=0}^{\infty}x^{n}\frac{f^{(n)}(0)}{n!}\label{eq:Taylors bra-kets}\end{eqnarray}

\end_inset 

 
\layout Standard

This notation allows the matrix elements 
\begin_inset Formula $U_{mn}=\left\langle m\left|\mathcal{L}\right|n\right\rangle $
\end_inset 

 of the transfer operator to be articulated as well.
 Starting with the classical notation of equation 
\begin_inset LatexCommand \ref{eq:taylor-f}

\end_inset 

, one has 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}f\right](x)=\sum_{m=0}^{\infty}b_{m}x^{m}=\sum_{m=0}^{\infty}x^{m}\sum_{n=0}^{\infty}U_{mn}a_{n}\label{eq:}\end{equation}

\end_inset 

 or, equivalently 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}f\right](x)=\left\langle x\left|\mathcal{L}f\right.\right\rangle =\sum_{m=0}^{\infty}\left\langle x\left|m\right.\right\rangle \left\langle m\left|\mathcal{L}f\right.\right\rangle =\sum_{m=0}^{\infty}\sum_{n=0}^{\infty}\left\langle x\left|m\right.\right\rangle \left\langle m\left|\mathcal{L}\right|n\right\rangle \left\langle n|f\right\rangle \label{eq:}\end{equation}

\end_inset 

where 
\begin_inset Formula $\left\langle n|f\right\rangle =a_{n}$
\end_inset 

 and 
\begin_inset Formula $\left\langle n\left|\mathcal{L}f\right.\right\rangle =b_{n}$
\end_inset 

.
 Equating each power of 
\begin_inset Formula $x^{m}$
\end_inset 

 one finds, in the classical notation, that 
\begin_inset Formula \begin{equation}
\left.\frac{1}{m!}\;\frac{d^{m}\left[\mathcal{L}f\right](x)}{dx^{m}}\right|_{x=0}=\sum_{n=0}^{\infty}U_{mn}\left.\frac{1}{n!}\;\frac{d^{n}f(x)}{dx^{n}}\right|_{x=0}\label{eq:}\end{equation}

\end_inset 

 where 
\begin_inset Formula \begin{equation}
\left\langle n|f\right\rangle =a_{n}=\left.\frac{1}{n!}\;\frac{d^{n}f(x)}{dx^{n}}\right|_{x=0}\label{eq:}\end{equation}

\end_inset 

 and so on.
 The formulation of the transfer operator given in equation 
\begin_inset LatexCommand \ref{eq:transfer-dirac}

\end_inset 

 fits in this framework as well; it is merely the spatial representation
 of the matrix elements: 
\begin_inset Formula \begin{eqnarray}
\delta\left(x-g(y)\right)=\mathcal{L}(x,y) & = & \left\langle x\left|\mathcal{L}\right|y\right\rangle \nonumber \\
 & = & \sum_{m=0}^{\infty}\sum_{n=0}^{\infty}\left\langle x|m\right\rangle \left\langle m\left|\mathcal{L}\right|n\right\rangle \left\langle n|y\right\rangle \label{eq:}\end{eqnarray}

\end_inset 


\layout Standard

Armed with this notation, the following section explores the matrix elements
 of the Bernoulli operator in this polynomial basis.
 
\layout Section

The Bernoulli Operator in the Polynomial Basis
\layout Standard

This section reviews the structure of the Bernoulli operator 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 in the polynomial basis developed above.
 The matrix elements in the monomial basis are given by
\layout Standard


\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}\right]_{mk}\equiv U_{mk}\equiv\left\langle m\right|U\left|k\right\rangle =\frac{\delta_{mk}}{2^{m}}+\left(\begin{array}{c}
k\\
m\end{array}\right)\frac{\Theta_{mk}}{2^{k+1}}\label{eq:U_mn}\end{equation}

\end_inset 

 where 
\begin_inset Formula $\left(\begin{array}{c}
m\\
k\end{array}\right)=\frac{m!}{k!(m-k)!}$
\end_inset 

 is the binomial coefficient, and 
\begin_inset Formula \begin{equation}
\Theta_{mk}=\left\{ \begin{array}{c}
0\;\textrm{ if }\; k\leq m\\
1\;\textrm{ if }\; k>m\end{array}\right.\label{eq:}\end{equation}

\end_inset 

 is a traceless, pure upper-triangular matrix.
 These matrix elements are easily obtained by direct substitution, that
 is, by contemplating the coefficient to the 
\begin_inset Formula $x^{m}$
\end_inset 

 term in the expansion of 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}x^{k}\right]=\frac{1}{2}\left[\left(\frac{x}{2}\right)^{k}+\left(\frac{1+x}{2}\right)^{k}\right]\label{eq:}\end{equation}

\end_inset 

 Both the diagonal elements, and the reason for the appearance of the binomial
 coefficients should be immediately clear.
 Note that the evaluation of these matrix elements does not require the
 evaluation of any sums with an infinite number of non-zero terms.
\layout Standard

The eigenvalues may be promptly read off the diagonal; these eigenvalues
 are 
\begin_inset Formula $\lambda_{n}=2^{-n}$
\end_inset 

.
 Because the matrix is upper-triangular, it is easily solvable for both
 the left and right eigenvectors, which agree perfectly with those given
 by Driebe
\begin_inset LatexCommand \cite{Dri99}

\end_inset 

.
 Visually, the upper-left of this matrix looks like 
\begin_inset Formula \begin{equation}
U_{mk}=\left[\begin{array}{cccccc}
1 & \frac{1}{4} & \frac{1}{8} & \frac{1}{16} & \frac{1}{32} & ...\\
0 & \frac{1}{2} & \frac{1}{4} & \frac{3}{16} & \frac{1}{8}\\
0 & 0 & \frac{1}{4} & \frac{3}{16} & \frac{3}{16}\\
0 & 0 & 0 & \frac{1}{8} & \frac{1}{8}\\
0 & 0 & 0 & 0 & \frac{1}{16}\\
... &  &  &  &  & ...\end{array}\right]\label{eq:}\end{equation}

\end_inset 

 The right and left eigenvectors are developed in the following sections.
\layout Subsection

Right eigenvectors
\layout Standard

The right eigenvectors are denoted by 
\begin_inset Formula $\left|B_{n}\right\rangle $
\end_inset 

 and have the vector components 
\begin_inset Formula \begin{equation}
\left\langle k\left|B_{n}\right.\right\rangle =\left(\begin{array}{c}
n\\
k\end{array}\right)\left(1-\Theta_{n,k}\right)B_{n-k}=\left\{ \begin{array}{ccc}
\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k} & \;\textrm{ for }\; & k\leq n\\
0 & \;\textrm{ for }\; & k>n\end{array}\right.\label{eq:B-right matrix elts}\end{equation}

\end_inset 

 where 
\begin_inset Formula $B_{k}$
\end_inset 

 are the Bernoulli numbers.
 Note that only a finite number of these vector components are non-vanishing.
\layout Theorem

The 
\begin_inset Formula $\left|B_{n}\right\rangle $
\end_inset 

 are eigenvectors of 
\begin_inset Formula $U_{mk}$
\end_inset 

, associated with eigenvalues 
\begin_inset Formula $2^{-n}$
\end_inset 

.
 That is, 
\begin_inset Formula \begin{equation}
\mathcal{L}_{B}\left|B_{n}\right\rangle =\frac{1}{2^{n}}\left|B_{n}\right\rangle \label{eq:}\end{equation}

\end_inset 

 
\layout Proof

This may be verified in the monomial basis through brute-force multiplication
 of the vector into the matrix: 
\begin_inset Formula \begin{eqnarray*}
\sum_{k=0}^{\infty}\left\langle m\right|U\left|k\right\rangle \left\langle k\left|B_{n}\right.\right\rangle  & = & \sum_{k=m}^{n}\left[\frac{\delta_{mk}}{2^{m}}+\left(\begin{array}{c}
k\\
m\end{array}\right)\frac{\Theta_{mk}}{2^{k+1}}\right]\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k}\\
 & = & \frac{1}{2^{m}}\left(\begin{array}{c}
n\\
m\end{array}\right)B_{n-m}+...non-trivial-taylor-expn\\
 & = & \frac{1}{2^{n}}\left\langle m\left|B_{n}\right.\right\rangle \end{eqnarray*}

\end_inset 

 XXX fill in details.
 Note that this proof does not require the evaluation of any sums with an
 infinite number of non-zero elements; all sums are algebraically finite.
\layout Standard

The right eigenvectors can be given a representation in coordinate space,
 and these are found to be the Bernoulli polynomials discussed previously:
\layout Standard


\begin_inset Formula \begin{equation}
\sum_{k=0}^{\infty}\left\langle x|k\right\rangle \left\langle k\left|B_{n}\right.\right\rangle =\sum_{k=0}^{n}\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k}x^{k}=B_{n}(x)\label{eq:}\end{equation}

\end_inset 

 These were previously shown to be eigenvectors, and so this is consistent
 with the above.
 Thus, at this level, one may conclude that the coordinate representation
 and the matrix representation for this transfer operator are consistent.
 
\layout Subsection

Left Eigenvectors
\layout Standard

This matrix expression for 
\begin_inset Formula $U_{mn}$
\end_inset 

 also admits left eigenvectors which can be given an explicit representation.
 Letting the left eigenvectors be denoted by 
\begin_inset Formula $\left\langle \tilde{B}_{n}\right|$
\end_inset 

, they have, for 
\begin_inset Formula $n>0$
\end_inset 

, the components 
\begin_inset Formula \begin{equation}
\left\langle \left.\tilde{B}_{n}\right|k\right\rangle =\left(\begin{array}{c}
k\\
n-1\end{array}\right)\frac{1}{n}\left(\delta_{nk}+\Theta_{nk}\right)\label{eq:B-left matrix elts}\end{equation}

\end_inset 

 The zeroth left eigenvector is a special-case; it has components 
\begin_inset Formula $\left\langle \left.\tilde{B}_{0}\right|k\right\rangle =1/(k+1)$
\end_inset 

.
 Unlike the right eigenvectors, the left eigenvectors all have an infinite
 number of non-zero components.
 They share the same eigenvalue spectrum with the right eigenvectors, so
 that 
\begin_inset Formula \begin{equation}
\sum_{k=0}^{\infty}\left\langle \left.\tilde{B}_{n}\right|m\right\rangle U_{mk}=\frac{1}{2^{n}}\left\langle \left.\tilde{B}_{n}\right|k\right\rangle \label{eq:}\end{equation}

\end_inset 

 which may again be demonstrated by a brute-force evaluation of the sum.
 Despite the fact that an infinite number of the left eigenvector components
 are non-vanishing, this sum will only contain a finite number of non-zero
 terms, and thus its finiteness is guaranteed on algebraic grounds.
\layout Standard

One may write down a coordinate-space representation for the left eigenvectors,
 by contracting them against the dual-space basis elements 
\begin_inset Formula $\left\langle k|x\right\rangle $
\end_inset 

.
 This leads directly to the generalized functions: 
\begin_inset Formula \begin{eqnarray}
\left\langle \tilde{B}_{n}|x\right\rangle  & = & \sum_{k=0}^{\infty}\left\langle \left.\tilde{B}_{n}\right|k\right\rangle \left\langle k|x\right\rangle \nonumber \\
 & = & \sum_{k=0}^{\infty}\left\langle \left.\tilde{B}_{n}\right|k\right\rangle (-)^{k}\frac{\delta^{(k)}(x)}{k!}\nonumber \\
 & = & \frac{1}{n}\sum_{k=n}^{\infty}\left(\begin{array}{c}
k\\
n-1\end{array}\right)(-)^{k}\frac{\delta^{(k)}(x)}{k!}\nonumber \\
 & = & \frac{(-)^{n+1}}{n!}\left[\delta^{(n-1)}(1-x)-\delta^{(n-1)}(x)\right]\label{eq:left bernoulli}\end{eqnarray}

\end_inset 

 for the 
\begin_inset Formula $n>0$
\end_inset 

 case.
 The 
\begin_inset Formula $n=0$
\end_inset 

 left eigenvector is best understood by integrating it over some arbitrary
 function 
\begin_inset Formula $f(x)$
\end_inset 

: 
\begin_inset Formula \begin{eqnarray}
\int_{0}^{1}dx\,\left\langle \left.\tilde{B}_{0}\right|x\right\rangle f(x) & = & \int_{0}^{1}dx\, f(x)\sum_{k=0}^{\infty}(-)^{k}\frac{\delta^{(k)}(x)}{(k+1)!}\nonumber \\
 & = & \sum_{k=0}^{\infty}\frac{f^{(k)}(0)}{(k+1)!}\nonumber \\
 & = & \sum_{k=0}^{\infty}\frac{f^{(k)}(0)}{k!}\int_{0}^{1}x^{k}dx\nonumber \\
 & = & \int_{0}^{1}f(x)dx\nonumber \\
 & = & \left\langle \left.\tilde{B}_{0}\right|f\right\rangle \label{eq:}\end{eqnarray}

\end_inset 

 The other left eigenvectors can also be made more concrete by looking at
 how they act on some function 
\begin_inset Formula $f(x)$
\end_inset 

; this may be written as 
\begin_inset Formula \begin{equation}
\left\langle \left.\tilde{B}_{n}\right|f\right\rangle =\frac{1}{n!}\left[f^{(n-1)}(1)-f^{(n-1)}(0)\right]\label{eq:B-tilde acting on f}\end{equation}

\end_inset 


\layout Subsection

Duality
\layout Standard

That the left eigenvectors are dual to the Bernoulli polynomials, which
 can be verified in either the matrix-element basis, or the coordinate-space
 representation.
\layout Theorem

The left and right eigenvectors are dual, in that
\begin_inset Formula \begin{equation}
\left\langle \left.\tilde{B}_{n}\right|B_{m}\right\rangle =\sum_{k=0}^{\infty}\left\langle \left.\tilde{B}_{n}\right|k\right\rangle \left\langle k\left|B_{m}\right.\right\rangle =\delta_{nm}\label{eq:}\end{equation}

\end_inset 

 and furthermore, the duality is algebraic, in that no infinite sums need
 be performed to demonstrate duality.
\layout Proof

Consider first the 
\begin_inset Formula $n=0$
\end_inset 

 case.
 One has 
\begin_inset Formula \begin{eqnarray*}
\left\langle \left.\tilde{B}_{0}\right|B_{m}\right\rangle  & = & \sum_{k=0}^{\infty}\left\langle \left.\tilde{B}_{0}\right|k\right\rangle \left\langle k\left|B_{m}\right.\right\rangle \\
 & = & \sum_{k=0}^{m}\frac{1}{k+1}\left(\begin{array}{c}
m\\
k\end{array}\right)B_{m-k}\\
 & = & \frac{1}{m+1}\sum_{j=0}^{m}\left(\begin{array}{c}
m+1\\
j\end{array}\right)B_{j}\\
 & = & \delta_{m0}\end{eqnarray*}

\end_inset 

 where the substitution 
\begin_inset Formula $j=m-k$
\end_inset 

 was made to obtain the last sum.
 The vanishing of the last sum is a well-known identity on the Bernoulli
 numbers.
 The 
\begin_inset Formula $n\ne0$
\end_inset 

 case requires more work, but ends similarly: 
\begin_inset Formula \begin{eqnarray*}
\left\langle \left.\tilde{B}_{n}\right|B_{m}\right\rangle  & = & \sum_{k=0}^{\infty}\left\langle \left.\tilde{B}_{n}\right|k\right\rangle \left\langle k\left|B_{m}\right.\right\rangle \\
 & = & \sum_{k=0}^{m}\left(\begin{array}{c}
k\\
n-1\end{array}\right)\frac{1}{n}\left(\delta_{nk}+\Theta_{nk}\right)\left(\begin{array}{c}
m\\
k\end{array}\right)B_{m-k}\\
 & = & \frac{1}{n}\left(\begin{array}{c}
n\\
n-1\end{array}\right)\left(\begin{array}{c}
m\\
n\end{array}\right)B_{m-n}+\sum_{k=n+1}^{m}\left(\begin{array}{c}
k\\
n-1\end{array}\right)\frac{1}{n}\left(\begin{array}{c}
m\\
k\end{array}\right)B_{m-k}\\
 & = & \begin{cases}
0 & \mbox{ for }n>m\\
B_{0} & \mbox{ for }n=m\\
\left(\begin{array}{c}
m\\
n\end{array}\right)B_{m-n}+\frac{m!}{n!(m-n+1)!}\sum_{k=n+1}^{m}\left(\begin{array}{c}
m-n+1\\
m-k\end{array}\right)B_{m-k} & \mbox{ for }n<m\end{cases}\end{eqnarray*}

\end_inset 

 The last case can be shown to vanish, by again making the substitution
 
\begin_inset Formula $j=m-k$
\end_inset 

, to get 
\begin_inset Formula \begin{eqnarray*}
\left(\begin{array}{c}
m\\
n\end{array}\right)B_{m-n} & + & \frac{m!}{n!(m-n+1)!}\sum_{j=0}^{m-n-1}\left(\begin{array}{c}
m-n+1\\
j\end{array}\right)B_{j}\\
 & = & \frac{m!}{n!(m-n+1)!}\sum_{j=0}^{m-n}\left(\begin{array}{c}
m-n+1\\
j\end{array}\right)B_{j}=0\end{eqnarray*}

\end_inset 

 thus concluding the proof.
 Notice that this proof does not require the evaluation of any infinite
 sums: all sums are performed over a finite number of terms.
\layout Standard

This proof of duality may also be conducted in coordinate space, where it
 takes the form 
\begin_inset Formula \begin{eqnarray}
\left\langle \left.\tilde{B}_{n}\right|B_{m}\right\rangle  & = & \int_{0}^{1}\left\langle \left.\tilde{B}_{n}\right|x\right\rangle \left\langle x\left|B_{m}\right.\right\rangle \, dx\nonumber \\
 & = & \int_{0}^{1}\frac{(-1)^{n+1}}{n!}\left[\delta^{(n-1)}(1-x)-\delta^{(n-1)}(x)\right]B_{m}(x)\, dx\nonumber \\
 & = & \begin{cases}
0 & \mbox{ for }m<n-1\\
\frac{m!}{n!(m-n+1)!}\left[B_{m-n+1}(1)-B_{m-n+1}(0)\right] & \mbox{ for }m\ge n-1\end{cases}\nonumber \\
 & = & \delta_{mn}\label{eq:}\end{eqnarray}

\end_inset 

 and so, as with most of the previous results, one may be lulled into a
 sense of complacency about the equivalence of the coordinate-space and
 monomial-vector-space representations.
 This complacency is ill-founded, as demonstrated below.
\layout Subsection

Completeness
\layout Standard

Given this duality, the operator 
\begin_inset Formula \begin{equation}
\mathbb{I}_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|\label{eq:Bern-ident}\end{equation}

\end_inset 

 can then be recognized as a projection operator.
 In fact, it is complete in the monomial basis, in that 
\begin_inset Formula \begin{equation}
\left\langle j\left|\mathbb{I}_{B}\right|k\right\rangle =\left\langle j\right|\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|\left|k\right\rangle =\delta_{jk}\label{eq:B-complete}\end{equation}

\end_inset 

 can be shown, using essentially the same operations as in the proof above.
 Also, as before, this demonstration involves sums with only a finite number
 of terms, and so completeness may be taken as an algebraic property.
 That is, 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 may be taken to be the identity operator on the vector space of polynomials.
\layout Standard

Curiously, this identity operator 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 expanded in the Bernoulli basis as in formula 
\begin_inset LatexCommand \ref{eq:Bern-ident}

\end_inset 

 is the Euler-Maclaurin summation formula in disguise.
 This may be seen by expanding
\layout Standard


\begin_inset Formula \begin{eqnarray}
f(x) & = & \left\langle x|f\right\rangle \nonumber \\
 & = & \sum_{m=0}^{\infty}B_{m}(x)\left\langle \left.\tilde{B}_{m}\right|f\right\rangle \label{eq:B-maclaurin}\\
 & = & \int_{0}^{1}f(y)\, dy+\sum_{m=0}^{\infty}\frac{B_{m}(x)}{m!}\left[f^{(m-1)}(1)-f^{(m-1)}(0)\right]\nonumber \end{eqnarray}

\end_inset 

 This may be compared to the 
\begin_inset Formula $n=1$
\end_inset 

 case of the traditional Euler-Maclaurin summation formula, 
\begin_inset Formula \begin{equation}
\frac{1}{n}\sum_{k=0}^{n-1}f\left(\frac{k+x}{n}\right)=\int_{0}^{1}f(y)\, dy+\sum_{m=0}^{\infty}\frac{B_{m}(x)}{n^{m}m!}\left[f^{(m-1)}(1)-f^{(m-1)}(0)\right]\label{eq:}\end{equation}

\end_inset 

 By combining equations 
\begin_inset LatexCommand \ref{eq:Bern-ident}

\end_inset 


\begin_inset LatexCommand \ref{eq:B-complete}

\end_inset 

 and 
\begin_inset LatexCommand \ref{eq:B-maclaurin}

\end_inset 

 one is sorely tempted to deduce orthogonality over coordinate space.
 That is, one wants to deduce that 
\begin_inset Formula \begin{equation}
\sum_{n=0}^{\infty}\left\langle x\left|B_{n}\right.\right\rangle \left\langle \left.\tilde{B}_{n}\right|y\right\rangle =\delta(x-y)\label{eq: Bernoulli-faulty}\end{equation}

\end_inset 

 which superficially seems to be entirely reasonable.
 The problem with equation 
\begin_inset LatexCommand \ref{eq: Bernoulli-faulty}

\end_inset 

 is that it is misleading, as will be expanded upon in the following sections.
 As long as the functions 
\begin_inset Formula $f(x)$
\end_inset 

 are in all cases understood to be polynomials, then there is no harm in
 using equation 
\begin_inset LatexCommand \ref{eq: Bernoulli-faulty}

\end_inset 

.
 This follows in part because 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 really is the identity operator on the space of polynomials: there are
 no polynomials (other than 
\begin_inset Formula $f(x)=0$
\end_inset 

) that are in the kernel of 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

.
 However, one may consider larger function spaces than those consisting
 of polynomials; on these spaces, 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 will be found to have a large and non-trivial kernel, while by contrast,
 the Dirac delta function 
\begin_inset Formula $\delta(x-y)$
\end_inset 

 does not have a non-trivial kernel on these same spaces.
 This will be delved into in the next section.
\layout Subsection

The Bernoulli operator in diagonal form; the Koopman operator
\layout Standard

From the above manipulations, one may deduce that, in the polynomial representat
ion, the Frobenius-Perron operator of the Bernoulli map is 
\begin_inset Formula \begin{equation}
\mathcal{L}_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \lambda_{n}\left\langle \tilde{B}_{n}\right|\label{eq:}\end{equation}

\end_inset 

 We can make use of this diagonal form to easily compute formal expressions
 involving 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

.
 Thus, for a function 
\begin_inset Formula $f(x)$
\end_inset 

 that is expressible as a polynomial series in 
\begin_inset Formula $x$
\end_inset 

, one may write the operator 
\begin_inset Formula \begin{equation}
f\left(\mathcal{L}_{B}\right)=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle f\left(\lambda_{n}\right)\left\langle \tilde{B}_{n}\right|\label{eq:}\end{equation}

\end_inset 

 whose matrix elements can be explicitly demonstrated in the monomial basis:
 
\begin_inset Formula \begin{equation}
\left\langle j\left|f\left(\mathcal{L}_{B}\right)\right|k\right\rangle =\sum_{j\leq n\leq k}\left(\begin{array}{c}
n\\
j\end{array}\right)\left(\begin{array}{c}
k\\
n-1\end{array}\right)\frac{B_{n-j}}{n}f\left(2^{-n}\right)\label{eq:}\end{equation}

\end_inset 

 As in previous cases, note that the summation involves only a finite number
 of terms, and is thus manifestly finite (provided that 
\begin_inset Formula $f$
\end_inset 

 is finite).
 As curious example, one may write, 
\begin_inset Formula $\mathcal{L}_{B}=\exp(-H_{B})$
\end_inset 

 so that 
\begin_inset Formula $H_{B}=-\log\mathcal{L}_{B}$
\end_inset 

 has matrix elements 
\begin_inset Formula \begin{equation}
\left\langle j\left|H_{B}\right|k\right\rangle =\frac{\log(2)}{k+1}\left(\begin{array}{c}
k+1\\
j\end{array}\right)\sum_{m=0}^{k-j}\left(\begin{array}{c}
k-j+1\\
m\end{array}\right)(j+m)\, B_{m}\label{eq:}\end{equation}

\end_inset 


\layout Standard

None of the eigenvalues 
\begin_inset Formula $\lambda_{n}$
\end_inset 

 are zero.
 In the previous section, it was shown that the kernel of 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 is trivial.
 Thus, 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 is invertible.
 This inverse is known as the 
\emph on 
Koopman operator
\emph default 
, and is denoted by 
\begin_inset Formula $\mathcal{K}_{B}$
\end_inset 

: 
\begin_inset Formula \begin{equation}
\mathcal{K}_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \frac{1}{\lambda_{n}}\left\langle \tilde{B}_{n}\right|\label{eq:}\end{equation}

\end_inset 

 By duality and completeness, one has that the Koopman operator is both
 a left and a right inverse, 
\begin_inset Formula \begin{equation}
\mathcal{L}_{B}\mathcal{K}_{B}=\mathcal{K}_{B}\mathcal{L}_{B}=\mathbb{I}_{B}\label{eq:}\end{equation}

\end_inset 

 in the polynomial representation.
 In this representation, one may honestly write 
\begin_inset Formula $\mathcal{K}_{B}=\mathcal{L}_{B}^{-1}$
\end_inset 

.
 This will not at all be the case when one considers the Bernoulli operator
 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 acting on other function spaces: it will be seen to have a large and non-trivia
l kernel, and so it will not be invertible (as 
\begin_inset Quotes eld
\end_inset 

half
\begin_inset Quotes erd
\end_inset 

 of its eigenvlaues will be seen to be zero).
\layout Subsection

Change of Basis Recap
\layout Standard

This section simply recaps the previous results.
 It was seen above that the monomials form a complete set of basis states
 that can be used to represent polynomials.
 The operator 
\begin_inset Formula $\mathbb{I}_{M}=\sum_{n=0}^{\infty}\left|n\right\rangle \left\langle n\right|$
\end_inset 

 can be called the identity operator over the space of polynomials; it has
 no non-trivial kernel in that space.
 Here, the subscript 
\begin_inset Formula $M$
\end_inset 

 is used to indicate that the identity operator is built from the monomial
 states.
 Thus, for the Bernoulli operator 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

, one may confidently write 
\begin_inset Formula $\mathcal{L}_{B}=\mathbb{I}_{M}\mathcal{L}_{B}\mathbb{I}_{M}$
\end_inset 

 which expands to 
\begin_inset Formula \begin{equation}
\mathcal{L}_{B}=\mathcal{L}_{B}^{\mbox{Monomial}}=\sum_{m=0}^{\infty}\sum_{n=0}^{\infty}\left|m\right\rangle \left\langle m\left|\mathcal{L}_{B}\right|n\right\rangle \left\langle n\right|\label{eq:}\end{equation}

\end_inset 

 The superscript 
\begin_inset Quotes eld
\end_inset 

Monomial
\begin_inset Quotes erd
\end_inset 

 is a formal label, used only to emphasize the basis in which the operator
 was expanded in.
 As seen above, the matrix elements 
\begin_inset Formula $U_{mn}\equiv\left\langle m\left|\mathcal{L}_{B}\right|n\right\rangle $
\end_inset 

 are upper-triangular.
 
\layout Standard

The operator 
\begin_inset Formula $\mathbb{I}_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|$
\end_inset 

 is also the identity operator on the space of polynomials.
 Using the same trick to write 
\begin_inset Formula \begin{equation}
\mathcal{L}_{B}=\mathcal{L}_{B}^{\mbox{Bernoulli}}=\mathbb{I}_{B}\mathcal{L}_{B}\mathbb{I}_{B}=\sum_{m=0}^{\infty}\sum_{n=0}^{\infty}\left|B_{m}\right\rangle \left\langle \tilde{B}_{m}\left|\mathcal{L}_{B}\right|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|\label{eq:}\end{equation}

\end_inset 

 one finds that 
\begin_inset Formula $\mathcal{L}_{B}^{\mbox{Bernoulli}}$
\end_inset 

 is an operator which has matrix elements that are non-zero only on the
 diagonal: 
\begin_inset Formula $\left\langle B_{m}\left|U_{B}\right|\tilde{B}_{n}\right\rangle =\delta_{mn}\lambda_{n}$
\end_inset 

.
 
\layout Standard

Consider now the change of basis from the monomial basis to the Bernoulli
 basis.
 Explicitly, this change of basis is 
\begin_inset Formula \begin{eqnarray}
\mathcal{L}_{B}^{\mbox{Bernoulli}} & = & \sum_{j,k=0}^{\infty}\left|B_{j}\right\rangle \delta_{jk}\lambda_{k}\left\langle \tilde{B}_{k}\right|\nonumber \\
 & = & \sum_{j,k,m,n=0}^{\infty}\left|B_{j}\right\rangle \left\langle \left.\tilde{B}_{j}\right|m\right\rangle \left\langle m\left|\mathcal{L}_{B}^{\mbox{Monomial}}\right|n\right\rangle \left\langle n\left|B_{k}\right.\right\rangle \left\langle \tilde{B}_{k}\right|\nonumber \\
 & = & \tilde{B}\,\mathcal{L}_{B}^{\mbox{Monomial}}\, B\label{eq:}\end{eqnarray}

\end_inset 

 where the operators 
\begin_inset Formula $\tilde{B}$
\end_inset 

 and 
\begin_inset Formula $B$
\end_inset 

 show the change of basis: 
\begin_inset Formula \begin{equation}
\tilde{B}=\sum_{j,m=0}^{\infty}\left|B_{j}\right\rangle \left\langle \left.\tilde{B}_{j}\right|m\right\rangle \left\langle m\right|\label{eq:}\end{equation}

\end_inset 

 and 
\begin_inset Formula \begin{equation}
B=\sum_{k,n=0}^{\infty}\left|n\right\rangle \left\langle n\left|B_{k}\right.\right\rangle \left\langle \tilde{B}_{k}\right|\label{eq:}\end{equation}

\end_inset 

 It is not hard to work out that 
\begin_inset Formula $\tilde{B}B=\mathbb{I}_{B}$
\end_inset 

 and that 
\begin_inset Formula $B\tilde{B}=\mathbb{I}_{M}$
\end_inset 

 so 
\begin_inset Formula $\tilde{B}$
\end_inset 

 is both a left- and right-inverse of 
\begin_inset Formula $B$
\end_inset 

; one may confidently write 
\begin_inset Formula $B^{-1}=\tilde{B}$
\end_inset 

 as a two-sided inverse.
 Although 
\begin_inset Formula $B$
\end_inset 

 and 
\begin_inset Formula $\tilde{B}$
\end_inset 

 are inverses of one-another, they are in no way orthogonal.
 The matrix elements of the transpose of an orthogonal operator are equal
 to those of the inverse; a quick review of equations 
\begin_inset LatexCommand \ref{eq:B-right matrix elts}

\end_inset 

 and 
\begin_inset LatexCommand \ref{eq:B-left matrix elts}

\end_inset 

 makes it clear that 
\begin_inset Formula $\left\langle \left.\tilde{B}_{k}\right|n\right\rangle \ne\left\langle n\left|B_{k}\right.\right\rangle $
\end_inset 

, and so 
\begin_inset Formula $B$
\end_inset 

 is not an orthogonal operator.
 This is not a surprise: orthogonal operators cannot take a diagonal operator
 and make it triangular.
\layout Subsection

Operator recap
\layout Standard

XXX Talk about the operator 
\begin_inset Formula \begin{equation}
\sum_{n}\lambda_{n}e_{n}\otimes e_{n}^{*}\label{eq:}\end{equation}

\end_inset 

 in terms of bein a compact operator, a nuclear operator, etc.
 Talk about the order of the operator, Talk about the projective topological
 tensor product, in the language of Grothendieck.
\layout Section

Topology, Completeness and Orthogonality
\layout Standard

The notions of completeness and orthogonality are treated above without
 any appeal to topology.
 That is, they are handled with what is essentially an algebraic approach,
 where all sums are essentially finite and well defined because all sums
 involve only a finite number of non-zero terms.
 This was possible in part by construction, and in part by luck: the Bernoulli
 operator was a solvable, upper-triangular matrix in the infinite vector
 space whose basis elements are the monomials.
 A sum over monomials, where only a finite number of terms are non-zero,
 is a polynomial.
 To go beyond this, to get to more general functions, such as, for example,
 a sum over monomials with an infinite number of non-zero elements, requires
 the introduction of a topology on the infinite vector space, so that limits
 of Cauchy sequences can be defined and discussed.
 There are several ways to provide a topology; the straightforward way is
 to provide the space with a metric topology.
 A metric topology endows the infinite vector space with a norm, so that
 the length of a vector can be given, and the distance between vectors defined
 as the length of the vector difference.
\layout Standard

With this in mind, the question then turns to 
\begin_inset Quotes eld
\end_inset 

what are the interesting topologies?
\begin_inset Quotes erd
\end_inset 

.
 Before this question is asked in earnest, it is worth illustrating why,
 exactly, it is an important question, and why the role of topologies needs
 to be addressed.
 Some of the difficulties of sticking to a purely algebraic approach are
 illustrated in this section.
 
\layout Standard

The operator 
\begin_inset Formula $\mathbb{I}_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|$
\end_inset 

 was shown to be complete on the space of polynomials.
 By this, it is meant that there is no polynomial that lies in the kernel
 of 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

, other than the trivial polynomial 
\begin_inset Formula $p(x)=0$
\end_inset 

.
 Equivalently, there does not exist any polynomial for which the identity
 
\begin_inset Formula $p(x)=-p(x+1/2)$
\end_inset 

 holds: more broadly, there is no such thing as a periodic polynomial.
 A function which obeys 
\begin_inset Formula $f(x)=-f(x+1/2)$
\end_inset 

 is of necessity periodic, of which 
\begin_inset Formula $f(x)=\sin(2\pi x)$
\end_inset 

 is a canonical example.
 More generally, sine and cosine waves which have an odd number of periods
 in the unit interval are all in the kernel of the Bernoulli operator, when
 that operator is taken in the coordinate-space.
 This may be seen very easily simply by direct substitution into equation
 
\begin_inset LatexCommand \ref{eq:Bernoulli operator}

\end_inset 

, which promptly yields 
\begin_inset Formula \begin{equation}
\mathcal{L}_{B}^{\mbox{Coordinate}}\sin2\pi(2k+1)x=\frac{1}{2}\left[\sin\pi(2k+1)x+\sin\pi(2k+1)(x+1)\right]=0\label{eq:}\end{equation}

\end_inset 

 for integers 
\begin_inset Formula $k$
\end_inset 

; likewise for the cosine.
 Not so for waves with an even number of periods: 
\begin_inset Formula \begin{equation}
\mathcal{L}_{B}^{\mbox{Coordinate}}\sin4\pi kx=\frac{1}{2}\left[\sin2\pi kx+\sin2\pi k(x+1)\right]=\sin2\pi kx\label{eq:}\end{equation}

\end_inset 

Here, the superscript 
\begin_inset Quotes eld
\end_inset 

Coordinate
\begin_inset Quotes erd
\end_inset 

 is introduced to distinguish the operator in the coordinate basis, as given
 in equation 
\begin_inset LatexCommand \ref{eq:Bernoulli operator}

\end_inset 

, from the same operator in the monomial basis.
 
\layout Standard

In the previous sections, it was established (XXX but perhaps not very clearly?
 XXX) that 
\begin_inset Formula $\mathcal{L}_{B}^{\mbox{Bernoulli}}=\mathcal{L}_{B}^{\mbox{Monomial}}$
\end_inset 

 when considered as operators acting on the space of polynomials.
 However, these are not at all equivalent if one considers them as operators
 acting on sines and cosines.
 In particular, consider 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 acting on 
\begin_inset Formula $f(x)=\exp2\pi ikx$
\end_inset 

:
\begin_inset Formula \begin{eqnarray}
\left[\mathbb{I}_{B}f\right](x) & = & \left\langle x\left|\mathbb{I}_{B}\right|f\right\rangle \nonumber \\
 &  & \sum_{n=0}^{\infty}\left\langle x\left|B_{n}\right.\right\rangle \left\langle \left.\tilde{B}_{n}\right|f\right\rangle \\
 & = & \sum_{n=0}^{\infty}\left\langle x\left|B_{n}\right.\right\rangle \frac{1}{n!}\left[f^{(n-1)}(1)-f^{(n-1)}(0)\right]\nonumber \\
 & = & \sum_{n=0}^{\infty}\left\langle x\left|B_{n}\right.\right\rangle \frac{1}{n!}\left[(2\pi ik)^{n-1}e^{2\pi ik}-(2\pi ik)^{n-1}\right]\nonumber \\
 & = & 0\label{eq:}\end{eqnarray}

\end_inset 

 where the second step makes use of equation 
\begin_inset LatexCommand \ref{eq:B-tilde acting on f}

\end_inset 

.
 This is remarkable, as any periodic wave constructed from sines and cosines
 seems to be in the kernel.
 By contrast, 
\begin_inset Formula $\mathbb{I}_{M}$
\end_inset 

 does not behave this way: 
\begin_inset Formula \begin{eqnarray}
\left[\mathbb{I}_{M}f\right](x) & = & \left\langle x\left|\mathbb{I}_{M}\right|f\right\rangle \nonumber \\
 &  & \sum_{n=0}^{\infty}\left\langle x\left|n\right.\right\rangle \left\langle \left.n\right|f\right\rangle \\
 & = & \sum_{n=0}^{\infty}\left\langle x\left|n\right.\right\rangle \frac{1}{n!}f^{(n)}(0)\nonumber \\
 & = & \sum_{n=0}^{\infty}\left\langle x\left|n\right.\right\rangle \frac{1}{n!}(2\pi ik)^{n}\nonumber \\
 & = & \sum_{n=0}^{\infty}x^{n}\frac{1}{n!}(2\pi ik)^{n}\label{eq:}\\
 & = & \exp2\pi ikx\end{eqnarray}

\end_inset 

 which is just a re-derivation of equation 
\begin_inset LatexCommand \ref{eq:Taylors bra-kets}

\end_inset 

.
 Thus, 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 and 
\begin_inset Formula $\mathbb{I}_{M}$
\end_inset 

 are inequivalent when acting on sine functions; so 
\begin_inset Formula $\mathcal{L}_{B}^{\mbox{Monomial}}$
\end_inset 

 and 
\begin_inset Formula $\mathcal{L}_{B}^{\mbox{Bernoulli}}$
\end_inset 

 are inequivalent as well.
\layout Standard

Since the sine function is the limit of a polynomial sequence, it seems
 strange or somehow contradictory that 
\begin_inset Formula $\mathcal{L}_{B}^{\mbox{Bernoulli}}$
\end_inset 

 has only a trivial kernel on the space of polynomials, while utterly and
 completely killing all sine functions.
 In order to define limits, or more precisely, in order to define 
\begin_inset Formula $\sin2\pi x$
\end_inset 

 as the limit of a sequence of polynomials, one must define the manner in
 which a polynomial sequence can converge to a function, and, for that,
 one must have a topology.
\layout Standard

Can this conundrum be escaped without appealing to topology? Since 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 seems to be somehow incomplete when considering sine functions, perhaps,
 one might think, this lack of completeness is due to the form of the left
 eigenstates given in equation 
\begin_inset LatexCommand \ref{eq:left bernoulli}

\end_inset 

.
 One might make a guess that perhaps a more truly complete set of states
 can be found by considering 
\begin_inset Formula \begin{equation}
\tilde{S}_{n}(x)=\frac{(-)^{n+1}}{n!}\left[\delta^{(n-1)}(1-x)+\delta^{(n-1)}(x)\right]\label{eq:}\end{equation}

\end_inset 

 so that sums and differences of the duals 
\begin_inset Formula $\tilde{B}_{m}(x)$
\end_inset 

 and 
\begin_inset Formula $\tilde{S}_{n}(x)$
\end_inset 

 can be used to regain the duals to the monomials 
\begin_inset Formula $\left\langle n|y\right\rangle =(-)^{n}\delta^{(n)}(y)/n!$
\end_inset 

.
 
\layout Theorem

The duals to 
\begin_inset Formula $\tilde{S}_{n}(x)$
\end_inset 

 are given by 
\begin_inset Formula $S_{n}(x)=nE_{n}(x)/2$
\end_inset 

 where the 
\begin_inset Formula $E_{n}(x)$
\end_inset 

 are the Euler polynomials.
 
\layout Proof

Consider the generating function for the Euler polynomials 
\begin_inset Formula \begin{equation}
G_{E}(x,t)=\frac{2e^{xt}}{1+e^{t}}=\sum_{n=0}^{\infty}E_{n}(x)\frac{t^{n}}{n!}\label{eq:}\end{equation}

\end_inset 

 Then one has, by taking the left hand side, 
\begin_inset Formula \begin{equation}
\int_{0}^{1}\tilde{S}_{n}(x)\,\frac{2e^{xt}}{1+e^{t}}\, dx=\frac{2}{n}\frac{t^{n-1}}{(n-1)!}\label{eq:}\end{equation}

\end_inset 

 and, performing the same operation on the right hand side, 
\begin_inset Formula \begin{equation}
\int_{0}^{1}\tilde{S}_{n}(x)\sum_{k=0}^{\infty}E_{k}(x)\frac{t^{k}}{k!}\; dx=\sum_{k=0}^{\infty}\frac{t^{k}}{k!}\int_{0}^{1}\tilde{S}_{n}(x)\, E_{k}(x)\, dx\label{eq:}\end{equation}

\end_inset 

 Then, equating the two sides, one has demonstrated duality of these states:
 
\begin_inset Formula \begin{equation}
\int_{0}^{1}\tilde{S}_{n}(x)\, E_{k}(x)\, dx=\frac{2\delta_{k,n-1}}{n}\label{eq:}\end{equation}

\end_inset 

 which completes the proof.
\layout Standard

As with the Bernoulli polynomials, one can, to a limit extent, make a restricted
 completeness statement in coordinate space.
 That is, if one decomposes a function 
\begin_inset Formula $f(y)=\sum_{k=1}^{\infty}a_{k}S_{k}(y)$
\end_inset 

 then one easily finds 
\begin_inset Formula \begin{equation}
\int_{0}^{1}\sum_{n=1}^{\infty}S_{n}(x)\tilde{S}_{n}(y)\, f(y)\, dy=f(x)\label{eq:}\end{equation}

\end_inset 

 from which one wants to conclude, once again incorrectly, or at least misleadin
gly, that 
\begin_inset Formula \begin{equation}
\sum_{n=1}^{\infty}S_{n}(x)\tilde{S}_{n}(y)=\delta(x-y)\label{eq:}\end{equation}

\end_inset 

 by repeating the same concerns and issues that lead to equation 
\begin_inset LatexCommand \ref{eq: Bernoulli-faulty}

\end_inset 

.
 The fault is the assumption that arbitrary, non-polynomial 
\begin_inset Formula $f(y)$
\end_inset 

 can be decomposed in the fashion given.
 In fact, the operator 
\begin_inset Formula $\mathbb{I}_{S}=\sum_{n=0}^{\infty}\left|S_{n}\right\rangle \left\langle \tilde{S}_{n}\right|$
\end_inset 

 has a large kernel: this time, all functions that are evenly periodic are
 in the kernel.
 That is, any function for which one has 
\begin_inset Formula $f(y)=f(y+1/2)$
\end_inset 

 lies in the kernel of 
\begin_inset Formula $\mathbb{I}_{S}$
\end_inset 

.
\layout Standard

One might hope that one can remedy the above situation by taking the sum
 
\begin_inset Formula $\mathbb{I}_{C}=\mathbb{I}_{B}+\mathbb{I}_{S}$
\end_inset 

 with one operator projecting out the even periodic functions, and the other
 the odd periodic functions, and that somehow, between the two of them,
 making a whole.
 However, one immediately runs into a problem with the basis functions.
 The 
\begin_inset Formula $\tilde{S}_{n}(x)$
\end_inset 

 are not orthogonal to the 
\begin_inset Formula $B_{n}(x)$
\end_inset 

, and vice-versa.
 This is easily seen by considering the the generating function for the
 Bernoulli polynomials: 
\begin_inset Formula \begin{equation}
G_{B}(x,t)=\frac{te^{xt}}{e^{t}-1}=\sum_{n=0}^{\infty}B_{n}(x)\frac{t^{n}}{n!}\label{eq:}\end{equation}

\end_inset 

Integrating, one gets 
\begin_inset Formula \begin{equation}
\int_{0}^{1}\tilde{S}_{n}(x)G_{B}(x,t)\, dx=\frac{t^{n}}{n!}\frac{e^{t}+1}{e^{t}-1}=\sum_{k=0}^{\infty}\frac{t^{k}}{k!}\int_{0}^{1}\tilde{S}_{n}(x)\, B_{k}(x)\, dx\label{eq:}\end{equation}

\end_inset 

 from which one deduces that 
\begin_inset Formula $\int_{0}^{1}\tilde{S}_{n}(x)\, B_{k}(x)\, dx=0$
\end_inset 

 only for 
\begin_inset Formula $k<n-1$
\end_inset 

, and similarly for 
\begin_inset Formula $\int_{0}^{1}\tilde{B}_{n}(x)\, S_{k}(x)\, dx$
\end_inset 

.
 
\layout Standard

More generally, any such attempt to patch up the situation is doomed to
 fail.
 This is a well-known theorem of functional analysis, which states that
 the space 
\begin_inset Formula $\mathbb{R}^{\omega}$
\end_inset 

does not have a countable algebraic basis.
 That is, while one may be able to write down a countable number of linearly
 independent vectors 
\begin_inset Formula $e_{k}$
\end_inset 

 with 
\begin_inset Formula $k\in\mathbb{N}_{0}$
\end_inset 

, the linear combinations 
\begin_inset Formula $\sum_{k}a_{k}e_{k}$
\end_inset 

 with only a finite number of 
\begin_inset Formula $a_{k}\in\mathbb{R}$
\end_inset 

 being non-zero fail to span all of 
\begin_inset Formula $\mathbb{R}^{\omega}$
\end_inset 

.
 In particular, the vector 
\begin_inset Formula $v=\sum_{k}e_{k}$
\end_inset 

 cannot be expressed as the sum over only a finite number of 
\begin_inset Formula $e_{k}$
\end_inset 

.
 XXX Does this theorem have a name? Need to reference a ref for this.
 XXXX 
\layout Section

The Fourier Representation 
\layout Standard

The Koopman operator of the Bernoulli Map has the property of taking a function
 and making two copies of it.
 That is, 
\begin_inset Formula \begin{eqnarray}
\left[\mathcal{K}_{B}f\right](y) & = & \int_{0}^{1}\delta\left(x-b(y)\right)f(x)\, dx\nonumber \\
 & = & f(b(y))\nonumber \\
 & = & f(2y)\theta(1-2y)+f(2y-1)\theta(2y-1)\label{eq:}\end{eqnarray}

\end_inset 

 where 
\begin_inset Formula $\theta(x)$
\end_inset 

 is the step function, identically zero for 
\begin_inset Formula $x<0$
\end_inset 

 and identically one for 
\begin_inset Formula $x>0$
\end_inset 

.
 The Koopman operator for the Bernoulli map is not faithfully representable
 in the polynomial basis; this can be seen in two ways.
 First, it introduces a discontinuity at 
\begin_inset Formula $x=1/2$
\end_inset 

 which the polynomials cannot move beyond; the radius of the circle of converge
 is limited by this singularity.
 Secondly, it takes a function and more-or-less makes it periodic; again,
 the polynomials cannot cope directly with this.
 Thus, one is motivated to explore the Fourier representation, if only to
 express the Koopman operator.
 
\layout Standard

It is easy to find an explicit form for this operator in the Fourier basis.
 Writing 
\begin_inset Formula \begin{equation}
f(x)=\sum_{n}a_{n}\cos2\pi nx\;+b_{n}\sin2\pi nx\label{eq:}\end{equation}

\end_inset 

 then 
\begin_inset Formula \begin{equation}
\left[\mathcal{K}_{B}f\right](x)=\sum_{n}a_{n}\cos4\pi nx\;+b_{n}\sin4\pi nx\label{eq:}\end{equation}

\end_inset 

 or, in Dirac notation, 
\begin_inset Formula $\left\langle em\left|\mathcal{K}_{B}\right|en\right\rangle =\delta_{2m,n}$
\end_inset 

.
 This is a very singular operator in this basis.
 Visually, it has the distinctive appearance of 
\begin_inset Formula \begin{equation}
\mathcal{K}_{B}=\left[\begin{array}{cccccc}
1 & 0 & 0 & 0 & 0 & ...\\
0 & 0 & 0 & 0 & ...\\
0 & 1 & 0 & 0\\
0 & 0 & 0 & 0\\
0 & 0 & 1 & 0 & ...\\
...\end{array}\right]\label{eq:}\end{equation}

\end_inset 

 where every other row consists of zeros.
 In this same basis, 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

is equally remarkable: it is literally the transpose: that is 
\begin_inset Formula $\mathcal{K}_{B}=\mathcal{L}_{B}^{T}$
\end_inset 

 in this basis, and so 
\begin_inset Formula \begin{equation}
\mathcal{L}_{B}=\left[\begin{array}{cccccc}
1 & 0 & 0 & 0 & 0 & ...\\
0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & ...\\
...\end{array}\right]\label{eq:}\end{equation}

\end_inset 

 In this representation, it is easily seen that 
\begin_inset Formula $\mathcal{L}_{B}\mathcal{K}_{B}=1$
\end_inset 

 but 
\begin_inset Formula $\mathcal{K}_{B}\mathcal{L}_{B}\neq1$
\end_inset 

, just as in the coordinate-space representation.
 It is very instructive to verify that the Bernoulli polynomials are still
 eigenfunctions in this representation.
 For 
\begin_inset Formula $n\neq0$
\end_inset 

, one has 
\begin_inset Formula \begin{equation}
\int_{0}^{1}B_{1}(x)\,\sin(2\pi nx)\, dx=\frac{-1}{\pi n}\label{eq:}\end{equation}

\end_inset 

 and it is straightforward to visually verify that 
\begin_inset Formula $U_{B}B_{1}=\frac{1}{2}B_{1}$
\end_inset 

.
 By working with the generator for the Bernoulli polynomials, 
\begin_inset Formula \begin{equation}
\frac{te^{xt}}{e^{t}-1}=\sum_{n=0}^{\infty}B_{n}(x)\,\frac{t^{n}}{n!}\label{eq:}\end{equation}

\end_inset 

 one can immediately find, for 
\begin_inset Formula $m\neq0$
\end_inset 

, the Fourier components 
\begin_inset Formula \begin{equation}
\int_{0}^{1}B_{n}(x)\,\cos(2\pi mx)\, dx=\left\{ \begin{array}{cc}
0 & \;\textrm{ for n odd }\\
\left(-\right)^{1+n/2}n!/\left(2\pi m\right)^{n} & \;\textrm{ for n even }\end{array}\right.\label{eq:}\end{equation}

\end_inset 

 and 
\begin_inset Formula \begin{equation}
\int_{0}^{1}B_{n}(x)\,\sin(2\pi mx)\, dx=\left\{ \begin{array}{cc}
0 & \;\textrm{ for n even }\\
\left(-\right)^{(n+1)/2}n!/\left(2\pi m\right)^{n} & \;\textrm{ for n odd }\end{array}\right.\label{eq:}\end{equation}

\end_inset 

 Applying the Fourier-representation 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 to these to these vector components makes it immediately clear how the
 eigenvalue of 
\begin_inset Formula $1/2^{n}$
\end_inset 

 is associated with the eigenvector 
\begin_inset Formula $B_{n}$
\end_inset 

.
 
\layout Section

The Hurwitz zeta eigenfunctions
\layout Standard

The Fourier representation also makes it clear that any vector with vector
 components 
\begin_inset Formula $a_{n}=1/n^{s}$
\end_inset 

 will be an eigenvector of 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 associated with the eigenvalue 
\begin_inset Formula $\lambda=1/2^{s}$
\end_inset 

.
 In coordinate space, one may write these eigenfunctions as 
\begin_inset Formula \begin{equation}
\beta(x;s)=2\Gamma(s+1)\sum_{n=1}^{\infty}\frac{\exp(2\pi inx)}{\left(2\pi n\right)^{s}}\label{eq:}\end{equation}

\end_inset 

 which transform as 
\begin_inset Formula $\mathcal{L}_{B}\beta(x;s)=2^{-s}\beta(x;s)$
\end_inset 

.
 Given the nature of summation, this series is strictly convergent for any
 complex-valued 
\begin_inset Formula $s$
\end_inset 

 with 
\begin_inset Formula $\Re s>1$
\end_inset 

.
 This series recreates the Bernoulli polynomials for integer values of 
\begin_inset Formula $n$
\end_inset 

, so for example, 
\begin_inset Formula $\Re\beta(x;2)=B_{2}(x)$
\end_inset 

 and 
\begin_inset Formula $\Im\beta(x;3)=B_{3}(x)$
\end_inset 

 and generally 
\begin_inset Formula $\Re\left[\left(-i\right)^{n}\beta(x;n)\right]=-B_{n}(x)$
\end_inset 

.
 Equivalently, the Fourier series for the Bernoulli polynomials can be written
 as 
\begin_inset Formula \begin{eqnarray}
B_{n}(x) & = & -\Gamma(n+1)\sum_{k=1}^{\infty}\frac{\exp(2\pi ikx)+\exp(2\pi ik(1-x))}{\left(2\pi ik\right)^{n}}\label{eq:}\\
 & = & \frac{-(-i)^{n}}{2}\left(\beta(x;n)+\beta(1-x;n)\right)\nonumber \end{eqnarray}

\end_inset 

See, for example 
\begin_inset LatexCommand \cite[Thm. 12.19]{Apo76}

\end_inset 

.
 
\layout Standard

The periodic zeta function 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 is also an eigenfunction of the general 
\begin_inset Formula $p$
\end_inset 

-adic operator, given in equation 
\begin_inset LatexCommand \ref{eq:p-adic operator}

\end_inset 

.
 That is, one has 
\begin_inset Formula \begin{equation}
\mathcal{L}_{p}\beta(x;s)=\frac{1}{p^{s}}\beta(x;s)\label{eq:p-adic beta eigeneqn}\end{equation}

\end_inset 

 which may be deomnstrated easily enough.
\layout Standard

These eigenfunctions are essentially a form of the Hurwitz zeta function
 
\begin_inset Formula \begin{equation}
\zeta(s,x)=\sum_{n=0}^{\infty}\frac{1}{\left(n+x\right)^{s}}\label{eq:}\end{equation}

\end_inset 

 and that, in fact, the Hurwitz zeta itself is an eigenfunction, with eigenvalue
 
\begin_inset Formula $2^{s-1}$
\end_inset 

.
 One may confirm this by following a very old-fashioned recipe for obtaining
 the functional relation for a zeta-like sum.
 Start by expressing the gamma function as 
\begin_inset Formula \begin{equation}
\int_{0}^{\infty}dy\, e^{-2\pi ny}y^{s-1}=\frac{\Gamma(s)}{(2\pi n)^{s}}\label{eq:}\end{equation}

\end_inset 

 Substituting into the expression for 
\begin_inset Formula $\beta$
\end_inset 

 and performing the sum, one may write 
\begin_inset Formula \begin{equation}
\beta(x;s)=2s\int_{0}^{\infty}dy\,\frac{y^{s-1}}{\exp\left(-2\pi i(x+iy)\right)-1}\label{eq:}\end{equation}

\end_inset 

 Then, following a traditional trick 
\begin_inset LatexCommand \cite[pp 13 ff]{Edw74}

\end_inset 

, re-write this as a contour integral 
\begin_inset Formula \begin{equation}
\beta(x;s)=\frac{-is}{\sin\pi s}\oint\frac{(-y)^{s}}{\exp\left(-2\pi i(x+iy)\right)-1}\;\frac{dy}{y}\label{eq:}\end{equation}

\end_inset 

 where the contour is taken to extend from 
\begin_inset Formula $+\infty+i\epsilon$
\end_inset 

, running just above the positive real axis, to the origin, circling the
 origin in a clockwise fashion, and returning to 
\begin_inset Formula $+\infty-i\epsilon$
\end_inset 

 just under the real axis.
 The contour essentially encloses the cut of the logarithm in the expression
 
\begin_inset Formula $(-y)^{s}=\exp s\,\log(-y)$
\end_inset 

.
 The old fashioned recipe calls for closing the contour at infinity (in
 a counter-clockwise direction) and then taking the dubious step of asserting
 Cauchy's Theorem to equate the integral around the cut to the sum of the
 poles, where we note that we have a pole whenever 
\begin_inset Formula $x+iy=n$
\end_inset 

 for some integer 
\begin_inset Formula $n$
\end_inset 

.
 By doing this we get the formal summation 
\begin_inset Formula \begin{equation}
\frac{i\sin\pi s}{s}\beta(x;s)=\exp\left(\frac{i\pi s}{2}\right)\sum_{n=-\infty}^{\infty}(n-x)^{s-1}\label{eq:}\end{equation}

\end_inset 

 This is a 
\begin_inset Quotes eld
\end_inset 

formal sum
\begin_inset Quotes erd
\end_inset 

, since the preceding steps required taking 
\begin_inset Formula $\Re s>1$
\end_inset 

 whereas now one needs to take 
\begin_inset Formula $\Re s<0$
\end_inset 

.
 This is a bit of jiggery-pokery that is common for this type of presentation;
 a different set of tools is required to do better.
 So we proceed, ignoring these difficulties.
 Re-write this sum as 
\begin_inset Formula \begin{equation}
\frac{i\sin\pi s}{s}\beta(x;s)=\exp\left(\frac{i\pi s}{2}\right)\left[\sum_{n=0}^{\infty}(n+(1-x))^{s-1}+e^{-i\pi(s-1)}\sum_{n=0}^{\infty}(n+x)^{s-1}\right]\label{eq:}\end{equation}

\end_inset 

 where we were mindful to rotate counter-clockwise for 
\begin_inset Formula $n<0$
\end_inset 

 when replacing 
\begin_inset Formula $(-)^{n}$
\end_inset 

 by 
\begin_inset Formula $e^{-i\pi n}$
\end_inset 

 instead of the sloppy and incorrect 
\begin_inset Formula $e^{i\pi n}$
\end_inset 

.
 Recognizing the sums as the Hurwitz Zeta, this then gives the desired result:
 
\begin_inset Formula \begin{equation}
\beta(x;s)=\frac{is}{\sin\pi s}\left[e^{-i\pi s/2}\zeta(1-s,x)-e^{i\pi s/2}\zeta(1-s,1-x)\right]\label{eq:}\end{equation}

\end_inset 

 It is straightforward to invert this and solve for 
\begin_inset Formula $\zeta$
\end_inset 

; one gets 
\begin_inset Formula \begin{equation}
\zeta(1-s,x)=\frac{1}{2s}\left[e^{-i\pi s/2}\beta(x;s)+e^{i\pi s/2}\beta(1-x;s)\right]\label{eq:}\end{equation}

\end_inset 

 thus proving the assertion that the Hurwitz zeta is an eigenfunction of
 the Bernoulli operator, with eigenvalue 
\begin_inset Formula $2^{s-1}$
\end_inset 

.
 To verify the correctness of the above steps, expand the exponentials in
 terms of their real and imaginary parts, to find that 
\layout Standard


\begin_inset Formula \begin{equation}
\zeta(z,x)=\frac{2\Gamma(1-z)}{\left(2\pi\right)^{1-z}}\left[\sin\left(\frac{\pi z}{2}\right)\sum_{n=1}^{\infty}\frac{\cos(2\pi nx)}{n^{1-z}}+\cos\left(\frac{\pi z}{2}\right)\sum_{n=1}^{\infty}\frac{\sin(2\pi nx)}{n^{1-z}}\right]\label{eq:}\end{equation}

\end_inset 

 which agrees with standard textbook presentations of the Hurwitz zeta;
 see for example 
\begin_inset LatexCommand \cite[Thm 12.6, Ex 12.2]{Apo76}

\end_inset 

.
\layout Subsection

Visualizing the Hurwitz zeta eigenfunctions
\layout Standard

Perhaps one surprising aspect of this result is that the Hurwitz zeta eigenfunct
ions appear to be smooth, since one is conditioned to expect that the only
 continuous-spectrum eigenfunctions of a Frobenius-Perron operator are fractal.
 Thus, it is worthwhile to take a few minutes to get acquainted with the
 shape and nature of the zeta.
 This section shows a number of graphs, and discusses the analytic structure
 of the eigenvectors.
 We'll see that the eigenfunctions are 
\begin_inset Formula $C^{\infty}$
\end_inset 

 in 
\begin_inset Formula $x$
\end_inset 

 for almost all 
\begin_inset Formula $x$
\end_inset 

: everywhere except at the endpoints 
\begin_inset Formula $x=0,1$
\end_inset 

.
 Thus, these are not 
\begin_inset Quotes eld
\end_inset 

physical
\begin_inset Quotes erd
\end_inset 

 eigenstates, if 
\begin_inset Formula $C^{\infty}$
\end_inset 

 for all 
\begin_inset Formula $x$
\end_inset 

 is placed as a demand for being 
\begin_inset Quotes eld
\end_inset 

physical
\begin_inset Quotes erd
\end_inset 

.
 We also find that there are eigenfunctions that have eigenvalues greater
 than one; these, while quite smooth and differentiable, are not square-integrab
le: they are divergent at 
\begin_inset Formula $x=0,1$
\end_inset 

.
 However, in all other respects, the eigenfunctions are analytically well-behave
d, even if a bit 
\begin_inset Quotes eld
\end_inset 

lumpy
\begin_inset Quotes erd
\end_inset 

 and uneven.
 
\layout Standard

There is a countably infinite degeneracy of eigenfunctions for a give eigenvalue.
 We can see this by writing 
\begin_inset Formula $s=\sigma+i\tau$
\end_inset 

 in terms of its real and imaginary components.
 Then the eigenvalue is 
\begin_inset Formula $\lambda=2^{-s}=2^{-\sigma}\exp(-i\tau\ln2)$
\end_inset 

 and it belongs to a family of eigenvectors with 
\begin_inset Formula $\tau'=\tau+2\pi n/\ln2$
\end_inset 

 for 
\begin_inset Formula $n\in\mathbb{Z}$
\end_inset 

.
 The next five figures show some of these, graphed in various ways.
\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

Real Part of Symmetric Beta
\layout Standard


\begin_inset Graphics
	filename zeta-2.2345-04.png
	width 100text%

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\Re\left[\beta(x;s)+\beta(-x;s)\right]/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that 
\begin_inset Formula $\left|\Gamma(1+s)\right|$
\end_inset 

gets very small as n gets large, and so the normalization brings them to
 visually comparable values.
 Other real values of 
\begin_inset Formula $\sigma$
\end_inset 

 can be understood by recalling that 
\begin_inset Formula $\beta$
\end_inset 

 essentially interpolates between Bernoulli polynomials at integer values
 of 
\begin_inset Formula $\sigma$
\end_inset 

.
 In short, they'll all look more or less like this.
 
\layout Standard

XXX redo this graph to show 
\begin_inset Formula $\Re\left[\beta(x;s)+\beta(1-x;s)\right]/2\left|\Gamma(1+s)\right|$
\end_inset 

 instead XXX
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

Magnitude of Symmetric Beta
\layout Standard


\begin_inset Graphics
	filename zeta-abs-2.2345-04.png
	width 100text%

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\left|\beta(x;s)+\beta(-x;s)\right|/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that 
\begin_inset Formula $\left|\Gamma(1+s)\right|$
\end_inset 

gets very small as n gets large, and so the normalization brings them to
 visually comparable values.
 
\layout Standard

XXX redo this graph to show 
\begin_inset Formula $\left|\beta(x;s)+\beta(1-x;s)\right|/2\left|\Gamma(1+s)\right|$
\end_inset 

 instead XXX
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

Real part of Beta
\layout Standard


\begin_inset Graphics
	filename zeta-exp-2.2345-04.png
	width 100text%

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\Re\beta(x;s)/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Although these curves clearly look very lumpy, they are 
\begin_inset Formula $C^{\infty}$
\end_inset 

 for all 
\begin_inset Formula $x\in(0,1)$
\end_inset 

 but not at the endpoints 
\begin_inset Formula $x=0,1$
\end_inset 

.
 At the endpoints, the derivative becomes divergent after just a few derivatives
, where the curves are behaving essentially as 
\begin_inset Formula $x^{s-1}$
\end_inset 

 and 
\begin_inset Formula $(1-x)^{s-1}$
\end_inset 

.
 It is impossible to see this pending divergence in the graphs above, because,
 to the naked eye, a graph of, for example, 
\begin_inset Formula $x^{1.5}$
\end_inset 

 is nearly indistinguishable from a graph of 
\begin_inset Formula $x^{2}$
\end_inset 

.
 
\layout Standard

Although these curves appear to be sine-wave-like, it is perhaps more correct
 to think of them as being Bernoulli-polynomial-like.
 That is, to better understand what eigenvectors near some arbitrary value
 of 
\begin_inset Formula $s$
\end_inset 

 look like, its useful to think of what the polynomial 
\begin_inset Formula $B_{\left\lfloor \Re s\right\rfloor }(x)$
\end_inset 

 looks like.
 Recall, however, that, of course, 
\begin_inset Formula $B_{k}(x)$
\end_inset 

 for 
\begin_inset Formula $k\geq3$
\end_inset 

 is very sine-wave like! Note also that the first curve shown above, for
 
\begin_inset Formula $n=0$
\end_inset 

, generally resembles 
\begin_inset Formula $B_{2}(x)$
\end_inset 

 which is a parabola.
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

Magnitude of Beta 
\layout Standard


\begin_inset Graphics
	filename zeta-emag-2.2345-04.png
	width 100text%

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\left|\beta(x;s)\right|/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that curiously, these functions seem to be smoother for larger x and
 seem to have vanishing ripples as x approaches zero.
 Curiously, the ripples seem to have a period of oscillation of approximately
 
\begin_inset Formula $nx$
\end_inset 

 in the interval 
\begin_inset Formula $x\in\left[1/2,1\right]$
\end_inset 

, and then repeating again between 1, 1/2, 1/4, 1/8, ...
 We'll gain some insight into these ripples in a later section, where we
 will analyze a sawtooth map having the same oscillatory behavior, for which
 the Hurwitz Zeta also plays a role as an eigenvector.
 That is, there is a certain sense in which the above curves are self-similar,
 with the curve in the interval 
\begin_inset Formula $x\in\left[2^{-k-1},2^{-k}\right]$
\end_inset 

 reprises the curve in the interval 
\begin_inset Formula $x\in\left[1/2,1\right]$
\end_inset 


\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

Argument of Beta
\layout Standard


\begin_inset Graphics
	filename zeta-arg-2.2345-04.png
	width 100text%

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\arg\beta(x;s)/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 
\end_inset 

 
\layout Standard

There are eigenfunctions with eigenvalues greater than one, essentially
 because the Hurwitz zeta can be analytically continued to everywhere on
 the complex plane except for a simple pole at 
\begin_inset Formula $z=1$
\end_inset 

.
 Examining these eigenfunctions, one quickly discovers that these are not
 square-integrable: they have singularities located at 
\begin_inset Formula $x=0,1$
\end_inset 

.
 That is, for for 
\begin_inset Formula $\Re z>0$
\end_inset 

, the Hurwitz zeta 
\begin_inset Formula $\zeta(z,x)$
\end_inset 

 has a clear singularity 
\begin_inset Formula $x^{-z}$
\end_inset 

 at 
\begin_inset Formula $x=0$
\end_inset 

.
 We remove this explicitly, and write 
\begin_inset Formula \begin{eqnarray}
\frac{\sin\pi s}{is}\beta(x;s) & = & \frac{e^{-i\pi s/2}}{x^{1-s}}-\frac{e^{i\pi s/2}}{(1-x)^{1-s}}+\nonumber \\
 &  & e^{-i\pi s/2}\left(\zeta(1-s,x)-x^{s-1}\right)-e^{i\pi s/2}\left(\zeta(1-s,1-x)-(1-x)^{s-1}\right)\label{eq:}\end{eqnarray}

\end_inset 

 The first part of the equation above encapsulates the singularities at
 
\begin_inset Formula $x=0,1$
\end_inset 

 that occur when working with eigenvalues 
\begin_inset Formula $\left|\lambda\right|=\left|2^{-s}\right|>1$
\end_inset 

, that is, with 
\begin_inset Formula $\Re s<0$
\end_inset 

.
 The remaining term is well-behaved and is shown in figure 
\begin_inset LatexCommand \ref{cap:The-non-singular-part}

\end_inset 

.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption


\begin_inset LatexCommand \label{cap:The-non-singular-part}

\end_inset 

The Non-Singular Part of the Divergent Eigenfunctions
\layout Standard


\begin_inset Graphics
	filename zeta-diverge.png
	width 100text%

\end_inset 


\layout Standard

This figure shows 
\begin_inset Formula \[
\eta_{even}(x;\sigma)=\frac{\cos\pi\sigma/2}{\sigma}\left[\beta(x;\sigma)+\beta(1-x;\sigma)\right]-x^{\sigma-1}-(1-x)^{\sigma-1}\]

\end_inset 

 and 
\begin_inset Formula \[
\eta_{odd}(x;\sigma)=\frac{\sin\pi\sigma/2}{\sigma}\left[\beta(x;\sigma)-\beta(1-x;\sigma)\right]-x^{\sigma-1}+(1-x)^{\sigma-1}\]

\end_inset 

 for a value of 
\begin_inset Formula $\sigma=-3.3$
\end_inset 

, corresponding to an eigenvalue of 
\begin_inset Formula $9.85=2^{3.3}$
\end_inset 

.
 Except for the singularity, we see that the finite part of these eigenfunctions
 is very well behaved.
 
\end_inset 

 
\layout Standard

Note that when 
\begin_inset Formula $\left|\lambda\right|=\left|2^{-s}\right|<1/2$
\end_inset 

, that is, when 
\begin_inset Formula $\Re s>1$
\end_inset 

, there is no singularity, and 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 is finite on the entire interval 
\begin_inset Formula $x\in[0,1]$
\end_inset 

 including the endpoints.
 For 
\begin_inset Formula $1/2<\Re s\leq1$
\end_inset 

 there is a bit of funny-business at the endpoints, that is, there is a
 weak divergence there, but the function overall remains square-integrable.
 Things break loose after that, with the exception of 
\begin_inset Formula $s=0$
\end_inset 

, where we have 
\begin_inset Formula $\beta(x;0)=-1$
\end_inset 

, a constant independent of 
\begin_inset Formula $x$
\end_inset 

.
 This essentially follows from the nature of differentiation on the Bernoulli
 polynomials, which we'll see below.
 Note, however, that for 
\begin_inset Formula $s$
\end_inset 

 near zero, the function 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 has severe ringing artifacts in 
\begin_inset Formula $x$
\end_inset 

, suffering from a variation of Gibbs Phenomenon.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

Ringing
\layout Standard


\begin_inset Graphics
	filename zeta-gibbs.png
	width 100text%

\end_inset 


\layout Standard

This figure shows ringing/Gibbs phenomenon as 
\begin_inset Formula $s$
\end_inset 

 approaches zero.
 In the limit of 
\begin_inset Formula $s=0$
\end_inset 

, we expect the real part of 
\begin_inset Formula $\beta$
\end_inset 

 to approach the trivial eigenfunction 
\begin_inset Formula $\lim_{s\rightarrow0^{+}}\Re\beta(x;s)=-B_{0}(x)=-1$
\end_inset 

.
 As this graph shows, the function is indeed trying very desperately to
 get flat, with not much success.
 The ringing occurs only at 
\begin_inset Formula $s=0$
\end_inset 

; there is no problem with convergence near larger integers, where 
\begin_inset Formula $\lim_{s\rightarrow n}\Re(-i)^{s}\beta(x;s)=-B_{n}(x)$
\end_inset 

 converges very smoothly and cleanly.
\end_inset 


\layout Standard

We conclude by noting that 
\begin_inset Formula $\beta$
\end_inset 

 is 
\begin_inset Formula $C^{\infty}$
\end_inset 

 for 
\begin_inset Formula $x\in(0,1)$
\end_inset 

 but not at the endpoints 
\begin_inset Formula $x=0,1$
\end_inset 

.
 This can be easily seen by writing the derivative 
\begin_inset Formula \begin{equation}
\frac{d}{dx}\beta(x;s)=2\pi i\beta(x;s-1)\label{eq:}\end{equation}

\end_inset 

 and so even if we start with 
\begin_inset Formula $\Re s>1$
\end_inset 

, each derivative carries us one step closer into the danger zone.
 
\layout Subsection

The Kernel
\layout Standard

What is the kernel of 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

? It is the set of functions that have only odd Fourier terms.
 
\layout Standard

That is, for any integer 
\begin_inset Formula $k\in\mathbb{Z}$
\end_inset 

 we have 
\begin_inset Formula $\mathcal{L}_{B}\cos2\pi(2k+1)x=0$
\end_inset 

 and so we write 
\begin_inset Formula $\cos2\pi(2k+1)x\in K\left[\mathcal{L}_{B}\right]$
\end_inset 

 and likewise 
\begin_inset Formula $\sin2\pi(2k+1)x\in K\left[\mathcal{L}_{B}\right]$
\end_inset 

.
 
\layout Standard

This implies that 'half' of all square-integrable functions are in the kernel.
 This is a huge space.
 The quotient space of the implied isomorphism thus has the Bernoulli polynomial
s as the representative elements.
 This is I think the correct way to relate coordinate space to the Hilbert
 space, is by means of the quotient space generated by the kernel of the
 time-evolution operator.
 
\layout Subsection

Synthetic operators
\layout Standard

The equation 
\begin_inset LatexCommand \ref{eq:p-adic beta eigeneqn}

\end_inset 

 shows that there are a countable set of commuting operators all posessing
 the same eigenfunctions.
 Since they are commuting, one is free to take arbitrary sums and products.
 By applying series expansions and applying standard arguments from Fredholm
 operator theory, one may, for practical purposes consider analytic functions
 of these operators.
 These are 
\begin_inset Quotes eld
\end_inset 

synthetic
\begin_inset Quotes erd
\end_inset 

 opertators, in that they have been synthesized from the basic set in equation
 
\begin_inset LatexCommand \ref{eq:p-adic beta eigeneqn}

\end_inset 

.
 A few examples follow below.
\layout Standard

Any Dirichlet series is traightforward: an operator with polylogarithm eigenvalu
es: 
\begin_inset Formula \begin{equation}
\left[\mathcal{LI}_{z}\right]\beta(x;s)=\left[\sum_{p=1}^{\infty}z^{p}\mathcal{L}_{p}\right]\beta(x;s)=\sum_{p=1}^{\infty}\frac{z^{p}}{p^{s}}\beta(x;s)=\mbox{Li}_{s}(z)\beta(x;s)\label{eq:}\end{equation}

\end_inset 

 An operator built from the Mobius function 
\begin_inset Formula $\mu$
\end_inset 

: 
\begin_inset Formula \begin{equation}
\left[\sum_{p=1}^{\infty}\mu(p)\mathcal{L}_{p}\right]\beta(x;s)=\sum_{p=1}^{\infty}\frac{\mu(p)}{p^{s}}\beta(x;s)=\frac{1}{\zeta(s)}\,\beta(x;s)\label{eq:}\end{equation}

\end_inset 

 A curious squaring:
\begin_inset Formula \begin{equation}
\left[\sum_{p=1}^{\infty}e^{2\pi iyp}\mathcal{L}_{p}\right]\beta(x;s)=\sum_{p=1}^{\infty}\frac{e^{2\pi iyp}}{p^{s}}\beta(x;s)=\frac{\left(2\pi\right)^{s}}{2\Gamma(s+1)}\,\beta(y;s)\beta(x;s)\label{eq:}\end{equation}

\end_inset 

 The Euler products of Fredholm kernels may be taken; for example: 
\begin_inset Formula \begin{equation}
\prod_{p}\frac{1}{1-\mathcal{L}_{p}}\beta(x;s)=\zeta(s)\beta(x;s)\label{eq:}\end{equation}

\end_inset 

 with the product now taken only over prime numbers 
\begin_inset Formula $p$
\end_inset 

.
 With considerable more difficulty, one might envision operators constructed
 after a sequence of differential and integral moves; for example, something
 involving the Mellin transform.
\layout Standard

In principle, any such operator may be constrcuted.
 Denote 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 by the vector space basis vector 
\begin_inset Formula $e_{s}$
\end_inset 

, and let 
\begin_inset Formula $e_{s}^{*}$
\end_inset 

 be its dual, so that 
\begin_inset Formula $e_{s}^{*}(e_{t})=\delta(s-t)$
\end_inset 

.
 Then given an arbitrary function 
\begin_inset Formula $f(s)$
\end_inset 

, one may consider the operator constructed with the topological tensor
 product: 
\begin_inset Formula \begin{equation}
\mathcal{O}=\int_{\mathbb{C}}ds\, f(s)\, e_{s}\otimes e_{s}^{*}\label{eq:}\end{equation}

\end_inset 

 then the operator 
\begin_inset Formula $\mathcal{O}$
\end_inset 

 has, by construction, eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 corresponding to eigenvalues 
\begin_inset Formula $f(s)$
\end_inset 

.
 What makes the above different is that there is a certain air of concreteness
 to the 
\begin_inset Formula $p$
\end_inset 

-adic transfer operators.
 
\layout Section

Lattice model topology
\layout Standard

It is well-known that one-dimensional lattice models, and more generally,
 subshifts of finite type, can provide useful tools and insights for the
 study of one-dimensional iterated maps
\begin_inset LatexCommand \cite{May91}

\end_inset 

.
 This section recaps the use of a one-dimensional spin lattice for the construct
ion of a class of Bernoulli operator eigenfunctions.
\layout Standard

Consider a one-sided lattice of points, labelled by the positive integers,
 that is, by 
\begin_inset Formula $n\in\mathbb{N}$
\end_inset 

.
 At each lattice location, a variable 
\begin_inset Formula $\sigma_{n}$
\end_inset 

, sometimes called the 
\begin_inset Quotes eld
\end_inset 

spin
\begin_inset Quotes erd
\end_inset 

, can take one of 
\begin_inset Formula $p$
\end_inset 

 values, so that 
\begin_inset Formula $\sigma_{n}\in\left\{ 0,1,2,\cdots,p-1\right\} $
\end_inset 

.
 A given lattice configuration 
\begin_inset Formula $\sigma=(\sigma_{1},\sigma_{2},\cdots)\in\Omega$
\end_inset 

 can be taken to be either a 
\begin_inset Formula $p$
\end_inset 

-adic number, or as a real number 
\begin_inset Formula $x$
\end_inset 

, with the Cantor mapping 
\begin_inset Formula $x:\Omega\to[0.1]$
\end_inset 

 from the set of all lattice configurations 
\begin_inset Formula $\Omega$
\end_inset 

 to the unit interval 
\begin_inset Formula $[0,1]$
\end_inset 

 given by
\begin_inset Formula \begin{equation}
x(\sigma)=\sum_{n=1}^{\infty}\sigma_{n}p^{-n}\label{eq:}\end{equation}

\end_inset 

 The latter mapping allows every possible spin lattice configuration to
 be mapped into the unit interval 
\begin_inset Formula $[0,1]$
\end_inset 

, although not vice-versa: the usual topologies on the spin lattice is finer
 than that on the reals, in that 
\begin_inset Formula $\sigma=(0,1,1,\cdots)$
\end_inset 

 and 
\begin_inset Formula $(1,0,0,\cdots)$
\end_inset 

 are inequivalent lattice configurations, whereas the binary numbers 
\begin_inset Formula $0.0111\ldots$
\end_inset 

 and 
\begin_inset Formula $0.1000\ldots$
\end_inset 

 both represent the rational 1/2.
 Only certain rationals are double-pointed like this, all irrationals are
 not.
 This double-pointed topology can be understood to be one and the same as
 the Cantor set topology, in that the Cantor set topology makes exactly
 the same distinction between endpoints of intervals.
 XXX See my other ref on fat cantor sets for details, if this is not clear.
 XXX Note also that lattices have another natural topology as well, the
 
\begin_inset Quotes eld
\end_inset 

cylinder set topology
\begin_inset Quotes erd
\end_inset 

, which is just the product topology of the discrete set of values at each
 lattice point.
 
\layout Standard

This finer topology on the one-sided lattice allows a richer set of eigenfunctio
ns to be constructed for the Bernoulli operator.
 One begins by noting that the shift operator 
\begin_inset Formula $\tau$
\end_inset 

 on the lattice, defined by 
\begin_inset Formula \begin{equation}
\tau(\sigma)=\tau((\sigma_{1},\sigma_{2},\cdots))=(\sigma_{2},\sigma_{3},\cdots)\label{eq:}\end{equation}

\end_inset 

 corresponds exactly to the Bernoulli map: 
\begin_inset Formula \begin{equation}
x(\tau(\sigma))=2x(\sigma)-\left\lfloor 2x(\sigma)\right\rfloor \label{eq:}\end{equation}

\end_inset 

 where we've written 
\begin_inset Formula $x(\sigma)$
\end_inset 

 instead of 
\begin_inset Formula $x$
\end_inset 

 to help remind that 
\begin_inset Formula $x$
\end_inset 

 should be thought of as a map, not a real number.
 For the remainder of this section, this distinction will rarely be made
 again, although every occurrence of 
\begin_inset Formula $\textrm{x}$
\end_inset 

 should be implicitly understood to be the map 
\begin_inset Formula $x:\Omega\to[0,1]$
\end_inset 

.
\layout Standard

Consider now some arbitrary function 
\begin_inset Formula $V:\Omega\to F$
\end_inset 

, where 
\begin_inset Formula $F$
\end_inset 

 may be taken to be the field 
\begin_inset Formula $\mathbb{R}$
\end_inset 

, or 
\begin_inset Formula $\mathbb{C}$
\end_inset 

, or some arbitrary generally field.
 Then, given some 
\begin_inset Formula $\lambda\in F$
\end_inset 

, one may construct the sum 
\begin_inset Formula \begin{equation}
H(\sigma)=\sum_{n=1}^{\infty}\lambda^{n}V(\tau^{n}\sigma)\label{eq:Lattice Hamlitonian}\end{equation}

\end_inset 

 where 
\begin_inset Formula $\tau^{n}\sigma=(\tau\circ\tau\circ\cdots\circ\tau)(\sigma)$
\end_inset 

 is simply the 
\begin_inset Formula $n$
\end_inset 

-fold iteration of the shift operator.
 In physics, the function 
\begin_inset Formula $H$
\end_inset 

 is usually called the translation-invariant Hamiltonian for the system,
 while 
\begin_inset Formula $V$
\end_inset 

 is the interaction potential.
 For a one-sided lattice, 
\begin_inset Formula $H$
\end_inset 

 is not strictly translation invariant, as 
\begin_inset Formula \begin{equation}
H(\tau(\sigma))=\sum_{n=1}^{\infty}\lambda^{n}V(\tau^{n+1}\sigma)=\frac{H(\sigma)-V(\sigma)}{\lambda}\label{eq:}\end{equation}

\end_inset 

 so that 
\begin_inset Formula $H$
\end_inset 

 is 
\begin_inset Quotes eld
\end_inset 

almost
\begin_inset Quotes erd
\end_inset 

 an eigenvector of 
\begin_inset Formula $\tau$
\end_inset 

, with eigenvalue 
\begin_inset Formula $1/\lambda$
\end_inset 

.
 Almost, because the one-sided lattice introduces a correction 
\begin_inset Formula $V/\lambda$
\end_inset 

.
 For the bi-infinite, two-sided lattice, a truly translation-invariant Hamiltoni
an can be defined.
 The two-sided lattice model corresponds to the Bakers map, and is treated
 in greater detail in XXX.
 
\layout Standard

If 
\begin_inset Formula $\tau$
\end_inset 

 is the left-shift operator, then the analog of the transfer operator can
 be roughly taken to be the right-shift operator.
 Since the lattice is one-sided, there exist in fact 
\begin_inset Formula $p$
\end_inset 

 inequivalent right-shift operators 
\begin_inset Formula $S_{k}$
\end_inset 

:
\begin_inset Formula \begin{equation}
S_{k}(\sigma_{1},\sigma_{2},\cdots)=(k,\sigma_{1},\sigma_{2},\cdots)\label{eq:}\end{equation}

\end_inset 

These right-shift operators are inverses to the left shift operator 
\begin_inset Formula $\tau$
\end_inset 

 only on one side, in that 
\begin_inset Formula $\tau\circ S_{k}$
\end_inset 

 is the identity, but 
\begin_inset Formula $S_{k}\circ\tau$
\end_inset 

 is not.
 Clearly, 
\begin_inset Formula $\tau$
\end_inset 

 has no left-inverse, as 
\begin_inset Formula $\tau$
\end_inset 

 throws away data in its action.
 For the 
\begin_inset Formula $p=2$
\end_inset 

 case, the shift operators act on the Cantor mapping as 
\begin_inset Formula \begin{eqnarray}
x(S_{0}(\sigma)) & = & \frac{x(\sigma)}{2}\nonumber \\
x(S_{1}(\sigma)) & = & \frac{1+x(\sigma)}{2}\label{eq:}\end{eqnarray}

\end_inset 

 and so one may immediately recognize how to pose the Bernoulli operator
 on the lattice model.
 For some arbitrary 
\begin_inset Formula $f:\Omega\to F$
\end_inset 

 one defines 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}f\right](\sigma)=\frac{1}{2}\left[f(S_{0}(\sigma))+f(S_{1}(\sigma))\right]\label{eq:}\end{equation}

\end_inset 

For the general 
\begin_inset Formula $p$
\end_inset 

-adic case, this generalizes trivially:
\layout Definition

The 
\begin_inset Formula $p$
\end_inset 

-adic Bernoulli operator acting on the dual space of lattice configurations
 is given by 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}f\right](\sigma)=\frac{1}{p}\sum_{k=0}^{p-1}f\left(S_{k}(\sigma)\right)\label{eq:Lattice Bernoulli}\end{equation}

\end_inset 

 where 
\begin_inset Formula $S_{k}$
\end_inset 

 is the 
\begin_inset Formula $k$
\end_inset 

'th right-shift operator.
\layout Standard

The action of 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 on the Hamiltonian 
\begin_inset Formula $H$
\end_inset 

 is takes the form
\begin_inset Formula \begin{equation}
\mathcal{L}_{B}H=\mathcal{L}_{B}V+\lambda H\label{eq:}\end{equation}

\end_inset 

 and thus 
\begin_inset Formula $H$
\end_inset 

 is is an eigenvector provided that 
\begin_inset Formula $\mathcal{L}_{B}V=0$
\end_inset 

.
\layout Standard

Thus, curiously, functions in the kernel of 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 can be used to construct eigenfunctions of 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

.
 The above construction is not limited the the Bernoulli operator, but in
 fact generalizes to other transfer operators in general.
 In particular, it can be used to define general eigenfunctions of the Gauss-Kuz
min-Wirsing (GKW) operator XXX ref my other paper.
 XXX perhaps show how this is done in general.
 In the next section ???XX
\layout Standard

The above construction shows how to construct a large number of general
 eigenfunctions, provided that on can find non-trivial objects in the kernel,
 and provided that the sum of equation 
\begin_inset LatexCommand \ref{eq:Lattice Hamlitonian}

\end_inset 

 converges.
\layout Standard

Although the finer topology of the Cantor set promises a richer set of functions
, one does not need to employ it to find interesting functions in the kernel.
\layout Section

Number theoretic connections
\layout Standard

XXX The definition 
\begin_inset LatexCommand \ref{eq:Lattice Bernoulli}

\end_inset 

 is suggestive of the kinds of sums occurring in the definition of the Hecke
 operator.
 One may also consider a Gauss-sum-like extension 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}^{(m)}f\right](\sigma)=\frac{1}{p}\sum_{k=0}^{p-1}e^{2\pi ikm/p}f\left(S_{k}(\sigma)\right)\label{eq:Lattice Bernoulli}\end{equation}

\end_inset 

 regaining 
\begin_inset Formula $\mathcal{L}_{B}=\mathcal{L}_{B}^{(0)}$
\end_inset 

.
\layout Section

The Continuous Fractal Spectrum
\layout Standard

An alternate set of eigenvectors with a continuous spectrum are given by
 
\begin_inset Formula \begin{equation}
\phi_{z,k}(x)=\sum_{n=0}^{\infty}z^{n}\exp\left(2\pi i\;2^{n}\left(2k+1\right)x\right)\label{eq:}\end{equation}

\end_inset 

 and have eigenvalue 
\begin_inset Formula $z$
\end_inset 

: that is 
\begin_inset Formula $[U_{B}\phi_{z,k}](x)=z\phi_{z,k}(x)$
\end_inset 

.
 Again, for a given fixed eigenvalue, they have a countably infinite degeneracy,
 labelled by the parameter 
\begin_inset Formula $k\in\mathbb{Z}$
\end_inset 

.
 These eigenfunctions are fractal, as can be readily seen from the graph[xxx
 need figure].
 Since they are a generalization of the Takagi-Landsberg curve, they have
 an 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

 symmetry, as discussed in an earlier chapter.
 As is typical for Takagi-type curves, these eigenfunctions are differentiable
 a finite number of times before they become differentiable nowhere.
 For example, for 
\begin_inset Formula $1/2<\left|z\right|<1$
\end_inset 

, these are continuous with respect to 
\begin_inset Formula $x$
\end_inset 

 but nowhere differentiable.
 For 
\begin_inset Formula $1/2^{m+1}<\left|z\right|<1/2^{m}$
\end_inset 

, these are everywhere 
\begin_inset Formula $m$
\end_inset 

 times differentiable with respect to 
\begin_inset Formula $x$
\end_inset 

, but nowhere 
\begin_inset Formula $m+1$
\end_inset 

 times differentiable.
 
\layout Standard

We can express these in terms of the Hurwitz Zeta eigenfunctions by considering
 the sum 
\begin_inset Formula \begin{eqnarray}
\sum_{k=0}^{\infty}z^{\ln_{2}(2k+1)}\phi_{z,k}(x) & = & \sum_{n=1}^{\infty}z^{\ln_{2}n}\exp\left(2\pi inx\right)\nonumber \\
 & = & \sum_{n=1}^{\infty}n^{\ln_{2}z}\exp\left(2\pi inx\right)\label{eq:}\end{eqnarray}

\end_inset 

 Thus, we see that we should equate 
\begin_inset Formula $s=-\ln_{2}z$
\end_inset 

 so that the eigenvalues are 
\begin_inset Formula $z=2^{-s}$
\end_inset 

.
 Multiplying by the appropriate factors, we get the desired relationship
 
\begin_inset Formula \begin{equation}
\beta(x;s)=2\Gamma(s+1)\left(2\pi\right)^{-s}\sum_{k=0}^{\infty}\left(2k+1\right)^{-s}\phi_{z,k}(x)\label{eq:}\end{equation}

\end_inset 

 That is, the Hurwitz zeta eigenfunctions are expressible as a linear combinatio
n of the fractal eigenfunctions.
 Essentially, either set of eigenfunctions can be used to form a set of
 basis states for the Bernoulli map transfer operator.
 The Hurwitz zeta eigenfunctions span a larger space than the fractal eigenfunct
ions, as the Hurwitz zeta is well-defined for eigenvalues with 
\begin_inset Formula $\left|z\right|>1$
\end_inset 

, whereas the fractal eigenfunctions are not.
 Of course, as we saw above, the Hurwitz zeta eigenfunctions are not square-inte
grable when 
\begin_inset Formula $\left|z\right|>1$
\end_inset 

, which invalidates their consideration for most 
\begin_inset Quotes eld
\end_inset 

physical
\begin_inset Quotes erd
\end_inset 

 uses.
 Note also that through careful work, the fractal eigenfunctions can probably
 be extended to 
\begin_inset Formula $\left|z\right|>1$
\end_inset 

 continuous-nowhere functions by considering their transformation properties
 under 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 This would be in analogy to the exploration of the derivative of the Takagi
 curve, which, as we saw in an earlier chapter, can be defined as the Cantor
 polynomial, built out of the digits of the binary expansion of 
\begin_inset Formula $x$
\end_inset 

.
 
\layout Standard

We can explicitly demonstrate the change of basis by defining 
\begin_inset Formula \begin{equation}
\beta_{n}(x;s)\equiv\beta(x;s+2\pi ni/\ln2)\label{eq:}\end{equation}

\end_inset 

 which all share the same eigenvalue: 
\begin_inset Formula $U_{B}\beta_{n}=2^{-s}\beta_{n}$
\end_inset 

.
 We can then restrict 
\begin_inset Formula $s$
\end_inset 

 to a principle domain 
\begin_inset Formula $-\pi<\Im s\,\ln2=\arg\, z<\pi$
\end_inset 

 .
 The change of basis can now be written explicitly as 
\begin_inset Formula \begin{equation}
\beta_{n}(x;s)=\sum_{k=0}^{\infty}F_{nk}\phi_{z,k}(x)\label{eq:}\end{equation}

\end_inset 

 where the matrix elements are 
\begin_inset Formula \begin{equation}
F_{nk}=2\Gamma\left(s+1+\frac{2\pi ni}{\ln2}\right)\left(2\pi(2k+1)\right)^{-s}\exp\left[-2n\pi i\frac{\ln\pi(2k+1)}{\ln2}\right]\label{eq:}\end{equation}

\end_inset 

 Presumably 
\begin_inset Formula $F$
\end_inset 

 is invertible; either set of eigenstates span the space.
 Given that one set of basis functions are clearly fractal, while the other
 is clearly analytic, it would be interesting to describe the space of functions
 spanned by these basis states.
 That is, given an arbitrary sequence 
\begin_inset Formula $\{ b_{n}|b_{n}\in\mathbb{C}\}$
\end_inset 

, describe the nature of the functions 
\begin_inset Formula \begin{equation}
\sum_{n=0}^{\infty}b_{n}\beta_{n}(x;s)\label{eq:}\end{equation}

\end_inset 

 considered as functions of 
\begin_inset Formula $x$
\end_inset 

 or alternately of 
\begin_inset Formula $s$
\end_inset 

.
 
\layout Standard

The modular group symmetries of the fractal eigenfunctions do not seem to
 provide any interesting insight into the zeta, since they do not mix or
 permute eigenstates.
 For example, applying the generator 
\begin_inset Formula $g$
\end_inset 

 on the fractal eigenstates gives
\begin_inset Formula \begin{equation}
g\phi_{zk}(x)=\phi_{zk}\left(\frac{x}{2}\right)=\exp((2k+1)\pi ix)+z\phi_{zk}(x)\label{eq:}\end{equation}

\end_inset 

 and so one might hope that since the zetas are a linear combination of
 the fractal eigenfunctions, one might get some new insight.
 However, doing this gives the sum 
\layout Standard


\begin_inset Formula \begin{equation}
g\beta(x;s)=\beta\left(\frac{x}{2};s\right)=\frac{2\Gamma(s+1)}{(2\pi)^{s}}\sum_{k=0}^{\infty}\frac{\exp2\pi ix(2k+1)}{(2k+1)^{s}}+2^{-s}\beta(x;s)\label{eq:}\end{equation}

\end_inset 

 as a symmetry, but the evaluation of the sum in the middle yields 
\begin_inset Formula $\beta(x/2;s)-2^{-s}\beta(x;s)$
\end_inset 

 and so one gets a trivial relationship and no insight in particular.
\layout Section

Modular Group Symmetry and the Takagi Representation 
\layout Standard

Yet another way to understand the solution of the Bernoulli Map is to note
 that it can be written as 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}f\right](x)=\frac{1}{2}\left(f(g_{D}(x))+f(r_{D}g_{D}r_{D}(x)\right)\label{eq: bern modular}\end{equation}

\end_inset 

 where 
\begin_inset Formula $g_{D}(x)=x/2$
\end_inset 

 and 
\begin_inset Formula $r_{D}(x)=1-x$
\end_inset 

 are the generators of the dyadic representation of the Modular group 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 Thus, we expect that we should be able to build eigenfunctions out of any
 functions 
\begin_inset Formula $f(x)$
\end_inset 

 that posses a Modular group symmetry.
\layout Standard

As we saw in a previous chapter, the Takagi curve fits this bill.
 Start with the triangle wave/tent map: 
\begin_inset Formula \begin{equation}
\tau(x)=\left\{ \begin{array}{ccc}
2(x-\left\lfloor x\right\rfloor ) & \;\textrm{ when }\; & 0\leq x-\left\lfloor x\right\rfloor \leq1/2\\
2(1-x+\left\lfloor x\right\rfloor ) & \;\textrm{ when }\; & 1/2\leq x-\left\lfloor x\right\rfloor \leq1\end{array}\right.\label{eq:}\end{equation}

\end_inset 

 which has the property that it doubles under iteration: 
\begin_inset Formula $\tau^{k}(x)=\tau(2^{k-1}x)$
\end_inset 

.
 The iterated tent map behaves sort-of like a shift state, in that 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}\tau^{k}\right](x)=\tau^{k-1}(x)\label{eq:}\end{equation}

\end_inset 

 although it does not terminate properly for a shift state: 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}\tau\right](x)=\frac{1}{2}\label{eq:}\end{equation}

\end_inset 

 (a true shift state would vanish on the final iteration).
 Thus we see that the Takagi curve transforms as 
\begin_inset Formula \begin{equation}
\left[\mathcal{L}_{B}t_{w}\right](x)=\frac{1}{2}+wt_{w}(x)\label{eq:}\end{equation}

\end_inset 

 under the Bernoulli operator.
 We can use this to build an eigenfunction 
\begin_inset Formula \begin{equation}
b_{w}(x)=\frac{-1}{2(1-w)}+t_{w}(x)\label{eq:}\end{equation}

\end_inset 

 so that 
\begin_inset Formula $\mathcal{L}_{B}b_{w}=wb_{w}$
\end_inset 

.
 On closer examination, we can see that this eigenvalue has the same countable
 degeneracy we've seen previously.
 That is, we can replace 
\begin_inset Formula $x$
\end_inset 

 on the right-hand-side of the equations above by 
\begin_inset Formula $(2j+1)x$
\end_inset 

 for 
\begin_inset Formula $j\in\mathbb{N}$
\end_inset 

 to obtain the set of eigenfunctions
\begin_inset Formula \begin{equation}
b_{w,j}(x)=\frac{-1}{2(1-w)}+t_{w}((2j+1)x)\label{eq:}\end{equation}

\end_inset 

 all sharing the eigenvalue 
\begin_inset Formula $w.$
\end_inset 

 It follows immediately that, just as above, we should be able to express
 the Hurwitz Zeta eigenfunctions 
\begin_inset Formula $\beta_{n}(x;s)$
\end_inset 

 for fixed 
\begin_inset Formula $s=-\ln_{2}w$
\end_inset 

 as a linear combination of the 
\begin_inset Formula $b_{w,j}$
\end_inset 

 if the 
\begin_inset Formula $b_{w,j}$
\end_inset 

 are a complete set of eigenstates for the eigenvalue 
\begin_inset Formula $w$
\end_inset 

.
 One special case is immediately apparent: the Takagi Curve 
\begin_inset Formula $t_{1/4}(x)$
\end_inset 

 is a parabola, corresponding to the Bernoulli polynomial 
\begin_inset Formula $B_{2}(x)$
\end_inset 

.
\layout Standard

XXX finish me; give the explicit expressions between 
\begin_inset Formula $b_{w,j}$
\end_inset 

 and 
\begin_inset Formula $\beta_{n}$
\end_inset 

.
\layout Standard

We can also obtain other eigenvectors by starting with the Takagi curves
 that transform under the higher-dimensional representations of 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 The equation 
\begin_inset LatexCommand \ref{eq: bern modular}

\end_inset 

 implies that any curve that transforms under a linear representation of
 the Modular Group can be used to build an eigenfunction of the Bernoulli
 Map.
 We exclude the non-linear representations, since we don't know how to build
 a vector space out of a non-linear operator.
 Thus, if 
\begin_inset Formula $t_{w}^{(n)}((2j+1)x)$
\end_inset 

 is a Takagi curve that transforms under an 
\begin_inset Formula $n$
\end_inset 

-dimensional representation, then 
\begin_inset Formula $\mathcal{L}_{B}$
\end_inset 

 is represented by 
\begin_inset Formula $(g_{n}+r_{n}g_{n}r_{n})/2$
\end_inset 

 where 
\begin_inset Formula $r_{n},g_{n}\in GL(n,\mathbb{R})$
\end_inset 

 are the generators of that 
\begin_inset Formula $n$
\end_inset 

-dimensional representation of 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 Solving the eigenvalue equation then amounts to diagonalizing the (finite-dimen
sional) matrix 
\begin_inset Formula $(g_{n}+r_{n}g_{n}r_{n})/2$
\end_inset 

.
\layout Standard

For a fixed eigenvalue 
\begin_inset Formula $w$
\end_inset 

, we expect a countably infinite degeneracy built out of the curves 
\begin_inset Formula $t_{w}^{(n)}((2j+1)x)$
\end_inset 

.
 Again, if these form a complete set of eigenstates, then we expect to be
 able to write out 
\begin_inset Formula $\beta_{n}(x;s)$
\end_inset 

 as a linear combination of these, and v.v.
\layout Standard

XXX finish me ..
 Give explicit expression for the higher-dim reps and in particular,the
 matrix from 
\begin_inset Formula $b_{w,j}$
\end_inset 

 and 
\begin_inset Formula $\beta_{n}$
\end_inset 

 in explicit detail.
 Also develop the lower-dim reps (move in opposite direction).
 This material should probably go into the chapter on the Takagi Curves,
 instead of here,right ...
 ???
\layout Standard

Note this is a ladder of isomorphisms between the different dimensional
 reps.
 Note also the ability to choose different set of basis funcs for the higher-dim
 Takagi Curves, viz, any polynomial of degree 
\begin_inset Formula $n-2$
\end_inset 

.
\layout Section

The Topological Zeta
\layout Standard

XXX ToDo: explain topo zeta gets this has this name, and why this concept
 is important.
 XXX
\layout Standard

The topological zeta of the Bernoulli operator can be computed very easily
 in the polynomial basis because we know the eigenvalues and these form
 a simple series.
 We'll define the Bernoulli topological zeta as
\begin_inset Formula \begin{equation}
\zeta_{B}(t)\equiv\frac{1}{\det\left[\mathbb{I}-t\mathcal{L}_{B}\right]}\label{eq:}\end{equation}

\end_inset 

 We start by noting its inverse: 
\begin_inset Formula \begin{eqnarray}
\det\left[\mathbb{I}-t\mathcal{L}_{B}\right] & = & \prod_{n=0}^{\infty}\left(1-t\;2^{-n}\right)\nonumber \\
 & = & 1-t\sum_{j=0}^{\infty}2^{-j}+t^{2}\sum_{j=0}^{\infty}2^{-j}\sum_{\begin{array}{c}
k=0\\
k\neq j\end{array}}^{\infty}2^{-k}-t^{3}...\nonumber \\
 & = & 1-2t+\frac{8}{3}t^{2}-\frac{16}{7}t^{3}+\frac{128}{105}t^{4}-...\label{eq:}\end{eqnarray}

\end_inset 

 Successive terms of this series are hard to compute, and it would be interestin
g to know what the generating function for this series is.
 The series appears to have a circle of convergence of radius one.
 The zeta can be computed directly by working with its logarithm: 
\begin_inset Formula \begin{eqnarray}
\log\zeta_{B}(t) & = & \log\prod_{n=0}^{\infty}\left(1-t\;2^{-n}\right)^{-1}\nonumber \\
 & = & -\sum_{n=0}^{\infty}\log\left(1-t\;2^{-n}\right)\nonumber \\
 & = & \sum_{k=1}^{\infty}\frac{t^{k}}{k}\;\frac{2^{k}}{2^{k}-1}\nonumber \\
 & = & -\log(1-t)+\sum_{k=1}^{\infty}\frac{t^{k}}{k}\;\frac{1}{2^{k}-1}\label{eq:}\end{eqnarray}

\end_inset 

 Thus we have 
\begin_inset Formula $\textrm{Tr}\mathcal{L}_{B}^{k}=2^{k}/(2^{k}-1)$
\end_inset 

.
 Of some curiosity is the proximity of the Erdos-Borwein constant: 
\begin_inset Formula \begin{eqnarray}
1.6066... & = & \sum_{n=1}^{\infty}\frac{1}{2^{n}-1}\nonumber \\
 & = & \sum_{n=1}^{\infty}\frac{d(n)}{2^{n}}\label{eq:}\end{eqnarray}

\end_inset 

 which marks the first appearance of a classical number-theoretic function
 in the proceedings so far: 
\begin_inset Formula $d(n)$
\end_inset 

 is the number of divisors of 
\begin_inset Formula $n$
\end_inset 

.
 This arises from the Lambert series
\begin_inset Formula \begin{equation}
\sum_{n=1}^{\infty}d(n)x^{n}=\sum_{n=1}^{\infty}\frac{x^{n}}{1-x^{n}}\label{eq:}\end{equation}

\end_inset 

The sum 
\begin_inset Formula \begin{equation}
E(t)=\sum_{k=1}^{\infty}\frac{t^{k}}{1-2^{-k}}\label{eq:}\end{equation}

\end_inset 

 can be re-summed as a Lambert series, namely, 
\begin_inset Formula \begin{equation}
E(t)=\sum_{k=1}^{\infty}b_{k}2^{-k}\label{eq:}\end{equation}

\end_inset 

 where 
\begin_inset Formula \begin{equation}
b_{k}=\sum_{n|k}(2t)^{n}\label{eq:}\end{equation}

\end_inset 

 The analytic/meromorphic structure of this zeta is not clear; its dull
 within the unit disk, and its not quite obvious what the continuation is
 outside of the disk.
 XXX ToDo: get the full analytic structure.
\layout Section

Curiosities
\layout Standard

We list here some intriguing forms that suggest further relationships.
\layout Standard

The Pochhammer symbol 
\begin_inset Formula $(a)_{n}=\Gamma(a+n)/\Gamma(n)$
\end_inset 

 obeys a 
\emph on 
dimidiation formula
\emph default 
 that is reminiscent of the Bernoulli map:
\layout Standard


\begin_inset Formula \begin{eqnarray*}
(a)_{2n} & = & 2^{2n}\left(\frac{a}{2}\right)_{n}\left(\frac{a+1}{2}\right)_{n}\\
(a)_{2n+1} & = & 2^{2n+1}\left(\frac{a}{2}\right)_{n}\left(\frac{a+1}{2}\right)_{n}\end{eqnarray*}

\end_inset 


\layout Section

Conclusions
\layout Standard

Apologies for the format of this paper.
 
\layout Section

Appendix
\layout Standard

This section needs to be re-written, merged, abolished.
 I think what its saying its mostly correct, but its misleading; there's
 a more enlightening, better treatment possible, by focusing on topologies.
\layout Subsection

Fourier Representation
\layout Standard

Review of standard Fourier series techniques.
 In traditional notation, for some (periodic) function 
\begin_inset Formula $f(x)$
\end_inset 

 one writes the Fourier Series as 
\begin_inset Formula \begin{equation}
f(x)=\sum_{n=-\infty}^{\infty}a_{n}\cos2\pi nx\;+b_{n}\sin2\pi nx\label{eq:}\end{equation}

\end_inset 

 where the conjugates of 
\begin_inset Formula $f$
\end_inset 

 are given by 
\begin_inset Formula \begin{equation}
a_{n}=\int_{0}^{1}f(x)\,\cos(2\pi nx)\, dx\label{eq:}\end{equation}

\end_inset 

 and 
\begin_inset Formula \begin{equation}
b_{n}=\int_{0}^{1}f(x)\,\sin(2\pi nx)\, dx\label{eq:}\end{equation}

\end_inset 

 Moving over to bra-ket notation, we can define the Fourier-space basis
 vectors 
\begin_inset Formula $\left|em\right\rangle $
\end_inset 

 in terms of their components in coordinate space.
 These components are 
\begin_inset Formula $\left\langle x|em\right\rangle =\exp(i2\pi mx)$
\end_inset 

.
 The conjugate vectors 
\begin_inset Formula $\left\langle en\right|$
\end_inset 

 have an equally simple representation: 
\begin_inset Formula $\left\langle en|x\right\rangle =\exp(-i2\pi nx)$
\end_inset 

.
 One has the usual sense of orthogonality over coordinate space in that
 
\begin_inset Formula \begin{equation}
\left\langle em|en\right\rangle =\int_{0}^{1}dx\,\left\langle em|x\right\rangle \left\langle x|en\right\rangle =\int_{0}^{1}dx\,\exp(2\pi i(n-m)x)=\delta_{nm}\label{eq:}\end{equation}

\end_inset 

 and the traditional presentation of the Fourier Series is a statement of
 completeness over coordinate space, in that for an arbitrary square-integrable
 coordinate-space function 
\begin_inset Formula $f(x)=\left\langle x|f\right\rangle $
\end_inset 

 one has 
\begin_inset Formula \begin{eqnarray}
f(x)=\left\langle x|f\right\rangle  & = & \sum_{n=-\infty}^{\infty}\left\langle x|en\right\rangle \left\langle en|f\right\rangle \nonumber \\
 & = & \sum_{n=-\infty}^{\infty}\exp(i2\pi nx)\int_{0}^{1}dy\,\left\langle en|y\right\rangle \left\langle y|f\right\rangle \nonumber \\
 & = & \sum_{n=-\infty}^{\infty}\exp(i2\pi nx)\int_{0}^{1}dy\,\exp(-i2\pi ny)f(y)\nonumber \\
 & = & \int_{0}^{1}dy\,\delta(x-y)\, f(y)\label{eq:}\end{eqnarray}

\end_inset 

 Thus, one is accustomed to the notion of having an identity operator of
 the form 
\begin_inset Formula $1_{F}=\sum_{m=-\infty}^{\infty}\left|em\right\rangle \left\langle em\right|$
\end_inset 

 because it has the matrix elements that one expects in both the Fourier
 space and in coordinate space: that is, 
\begin_inset Formula $\left\langle em\right|1_{F}\left|en\right\rangle =\delta_{nm}$
\end_inset 

 and 
\begin_inset Formula $\left\langle x\right|1_{F}\left|y\right\rangle =\delta(x-y)$
\end_inset 

 .
 
\layout Standard

Thus, in light of this perfectly ordinary standard textbook behavior, the
 following shall be surprising.
 The matrix elements of this operator, expressed in the polynomial basis,
 are not only non-trivial, but are divergent.
 That is, one can be lulled into believing that 
\begin_inset Formula $\left\langle m\right|1_{F}\left|n\right\rangle =\delta_{nm}$
\end_inset 

 for the polynomial basis, and indeed, by performing the operations in a
 certain order, one can certainly show this.
 However, reversing the order of operations shows that what might seem like
 simple operations can in fact be quite treacherous.
 
\layout Standard

We begin by writing the components of the vector 
\begin_inset Formula $\left|em\right\rangle $
\end_inset 

 in the polynomial-space representation:
\layout Standard


\begin_inset Formula \begin{eqnarray}
\left\langle n|em\right\rangle  & = & \int_{0}^{1}dx\left\langle n|x\right\rangle \left\langle x|em\right\rangle \nonumber \\
 & = & \int_{0}^{1}dx\,\frac{(-)^{n}}{n!}\delta^{(n)}(x)\, e^{i2\pi mx}\nonumber \\
 & = & \int_{0}^{1}dx\,\frac{\delta(x)}{n!}\,\frac{d^{n}}{dx^{n}}\, e^{i2\pi mx}\nonumber \\
 & = & \frac{(i2\pi m)^{n}}{n!}\label{eq:}\end{eqnarray}

\end_inset 

 Essentially, this is nothing more than a plain-old Taylor's Series expansion
 of the exponential function.
 The conjugate vectors have a slightly trickier form.
 They are the Fourier components of monomials.
 For 
\begin_inset Formula $m\neq0$
\end_inset 

 
\begin_inset Formula \begin{eqnarray}
\left\langle em|n\right\rangle  & = & \int_{0}^{1}dy\left\langle em|y\right\rangle \left\langle y|n\right\rangle \nonumber \\
 & = & \int_{0}^{1}\exp(-2\pi imy)\, y^{n}\, dy\nonumber \\
 & = & \frac{-1}{2\pi im}+\frac{n}{2\pi im}\int_{0}^{1}\exp(-2\pi imy)\, y^{n-1}\, dy\nonumber \\
 & = & -\frac{1}{2\pi im}\sum_{k=0}^{n-1}\frac{n!}{(n-k)!}\left(\frac{1}{2\pi im}\right)^{k}\label{eq:}\end{eqnarray}

\end_inset 

 and, for 
\begin_inset Formula $m=0$
\end_inset 

, 
\begin_inset Formula $\left\langle e0|n\right\rangle =1/(n+1)$
\end_inset 

.
 Let us now try to explicitly evaluate the matrix elements of the Fourier
 identity operator in the polynomial representation.
 That is, we attempt to write the matrix elements of 
\begin_inset Formula $1_{F}=\sum_{m=-\infty}^{\infty}\left|em\right\rangle \left\langle em\right|$
\end_inset 

 
\begin_inset Formula \begin{eqnarray}
\left\langle p\right|1_{F}\left|n\right\rangle  & = & \sum_{m=-\infty}^{\infty}\left\langle p|em\right\rangle \left\langle em|n\right\rangle \nonumber \\
 & = & \sum_{m=-\infty}^{\infty}\left[\delta_{p0}+\left(1-\delta_{p0}\right)\frac{\left(2\pi im\right)^{p}}{p!}\right]\left[\frac{\delta_{m0}}{n+1}-\frac{\left(1-\delta_{m0}\right)}{2\pi im}\sum_{k=0}^{n-1}\frac{n!}{(n-k)!}\left(\frac{1}{2\pi im}\right)^{k}\right]\label{eq:}\end{eqnarray}

\end_inset 

 We need only to look at the relatively simple matrix element 
\begin_inset Formula $n=1$
\end_inset 

, 
\begin_inset Formula $p\neq0$
\end_inset 

 to see the misery of this expression: 
\begin_inset Formula \begin{equation}
\left\langle p\neq0\right|1_{F}\left|n=1\right\rangle =\frac{\left(2\pi i\right)^{p}}{p!}\sum_{m=1}^{\infty}\frac{m^{p}}{2\pi im}\label{eq:}\end{equation}

\end_inset 

 One can try to rescue the situation by making the Ansatz that the summation
 should have been replaced by 
\begin_inset Formula $\zeta(1-p)$
\end_inset 

 which is regular, but already this is dangerous.
 What is perhaps the more surprising is that one might have expected this
 kind of trouble from the polynomial completeness relationship 
\begin_inset Formula $\mathbb{I}_{A}=\sum_{n=0}^{\infty}\left|n\right\rangle \left\langle n\right|$
\end_inset 

 because it ranges only over analytic functions: its essentially a statement
 of the idea that analytic functions are expressible through a series expansion
 in a variable.
 Functions that are not infinitely differentiable more-or-less lie in the
 kernel of 
\begin_inset Formula $\mathbb{I}_{A}$
\end_inset 

.
 However, we'd expect 
\begin_inset Formula $1_{F}$
\end_inset 

 to be more faithful, as it would seem to venture over square-integrable
 functions.
 Thus, such a simple failing is surprising.
 
\layout Standard

The goal here is to simply present a signpost warning, as we make heavy
 use of these techniques in the sections that follow, where we work with
 functions that are differentiable-nowhere or worse.
 
\layout Subsection

The Koopman Operator
\layout Standard

The Koopman operator is in a certain sense conjugate to the Frobenius-Perron
 operator, and defines how observables evolve.
 Given a density 
\begin_inset Formula $\rho(x)$
\end_inset 

 we say that the observation of a function 
\begin_inset Formula $f(x)$
\end_inset 

 by 
\begin_inset Formula $\rho$
\end_inset 

 is 
\begin_inset Formula \begin{equation}
\left\langle f\,\right\rangle _{\rho}=\int_{0}^{1}f(x)\rho(x)\, dx\label{eq:}\end{equation}

\end_inset 

 The term 
\begin_inset Quotes eld
\end_inset 

observable
\begin_inset Quotes erd
\end_inset 

 comes from usage in Quantum Mechanics, where 
\begin_inset Formula $f(x)$
\end_inset 

 is associated with the eigenvalues of an operator.
 We do not need to appeal to these operator equations for the following
 development.
 The Koopman operator 
\begin_inset Formula $K$
\end_inset 

 gives the change in 
\begin_inset Formula $f$
\end_inset 

 when 
\begin_inset Formula $U$
\end_inset 

 acts on 
\begin_inset Formula $\rho$
\end_inset 

, thus: 
\begin_inset Formula \begin{equation}
K_{g}:\left\langle f\,\right\rangle _{\rho}\rightarrow\left\langle K_{g}f\,\right\rangle _{\rho}=\int_{0}^{1}[K_{g}f](x)\rho(x)\, dx=\int_{0}^{1}f(x)[U_{g}\rho](x)\, dx\label{eq:}\end{equation}

\end_inset 

 In Dirac bra-ket notation, we have 
\begin_inset Formula \begin{eqnarray}
\int_{0}^{1}f(x)[U_{g}\rho](x)\, dx & = & \int_{0}^{1}\left\langle x|U_{g}|\rho\right\rangle \left\langle x|f\right\rangle \, dx\nonumber \\
 & = & \int_{0}^{1}dx\int_{0}^{1}dy\left\langle x|U_{g}|y\right\rangle \left\langle y|\rho\right\rangle \left\langle x|f\right\rangle \, dx\label{eq:}\end{eqnarray}

\end_inset 

 and so we have 
\begin_inset Formula \begin{equation}
\left[K_{g}f\right](y)=\int_{0}^{1}\left\langle x|U_{g}|y\right\rangle \left\langle x|f\right\rangle \, dx=\int_{0}^{1}U_{g}(x,y)f(x)\, dx=\int_{0}^{1}\delta\left(x-g(y)\right)f(x)\, dx\label{eq:}\end{equation}

\end_inset 

 This gives the action of the Koopman operator in a coordinate-space representat
ion.
 As is the recurring theme, different representations can lead to different
 results.
 In the coordinate-space representation, the Koopman operator appears to
 be the transpose of the Frobenius-Perron operator, in that 
\begin_inset Formula $K(x,y)=U(y,x)$
\end_inset 

.
 However, in a general representation, whether the Koopman operator is the
 transpose or the complex conjugate or something else needs to be determined
 on a case-by-case basis, with an appeal to the particular operator 
\begin_inset Formula $g(x)$
\end_inset 

 and the representations on which it works.
 
\layout Subsection

Topologically Conjugate Maps
\layout Standard

Conjugation of the function that generates the map will provide, in general,
 another map that behaves exactly the same as the first, as long as the
 conjugating function is a 1-1 and onto diffeomorphism.
 That is, if 
\begin_inset Formula $\phi$
\end_inset 

 is invertible, so that 
\begin_inset Formula \begin{equation}
\gamma=\phi\circ g\circ\phi^{-1}\label{eq:}\end{equation}

\end_inset 

 then 
\begin_inset Formula $\gamma$
\end_inset 

 will iterate the same way that 
\begin_inset Formula $g$
\end_inset 

 does: 
\begin_inset Formula $\gamma^{n}=\phi\circ g^{n}\circ\phi^{-1}$
\end_inset 

.
 The orbit of any point 
\begin_inset Formula $x$
\end_inset 

 under the map 
\begin_inset Formula $g$
\end_inset 

 is completely isomorphic to the orbit of a point 
\begin_inset Formula $y=\phi(x)$
\end_inset 

 under the map 
\begin_inset Formula $\gamma$
\end_inset 

.
 Because the (chaotic) point dynamics of these two maps are isomorphic,
 we expect just about any related construction and analysis to show evidence
 of this isomorphism.
 
\layout Standard

In particular, we expect that the Koopman and Frobenius-Perron operators
 for 
\begin_inset Formula $\gamma$
\end_inset 

 are conjugate to those for 
\begin_inset Formula $g$
\end_inset 

: 
\begin_inset Formula \begin{equation}
U_{\gamma}=U_{\phi}^{-1}U_{g}U_{\phi}\label{eq:}\end{equation}

\end_inset 


\layout Standard

XXX ToDo derive the above.
 Show that eigenvalues are preserved.
 The most trivial way to see that the eigenvalues are unchanged is through
 the formal definition of the characteristic polynomial for this operator,
 which is 
\begin_inset Formula \begin{equation}
p_{U}(\lambda)=\det\left[U_{g}-\lambda\mathbb{I}\right]\label{eq:}\end{equation}

\end_inset 

 Just as in the finite-dimensional case, a similarity transform commutes
 inside the determinant, leaving the characteristic polynomial unchanged.
 XXX ToDo a more correct, non-formal proof that the eigenvalues are preserved.
\layout Standard

Note that in the construction of this proof, we invoke the Jacobian 
\begin_inset Formula $\left|d\phi(y)/dy\right|_{y=\phi^{-1}(x)}$
\end_inset 

 and thus, in order to preserve the polynomial-rep eigenvalues, the conjugating
 function must be a diffeomorphism; a homeomorphism does not suffice.
 We will show an example below of a conjugating function that is highly
 singular, and thus the Jacobian does not exist (in the ordinary sense).
 When the conjugating function is sufficiently singular, then 
\begin_inset Formula $U_{\phi}$
\end_inset 

 cannot be coherently defined.
 As a result, one can have conjugate maps with completely isomorphic point
 dynamics, but the eigenvalue spectra associated with these maps will 
\emph on 
not
\emph default 
 be identical.
 
\layout Subsection

The Topological Zeta
\layout Standard

Another interesting quantity is the topological zeta function associated
 with the transfer operator.
 It is formally defined by 
\begin_inset Formula \begin{equation}
\zeta_{U_{g}}(t)=\frac{1}{\det\left[\mathbb{I}-tU_{g}\right]}\label{eq:}\end{equation}

\end_inset 

 and embeds number-theoretic information about the map.
 Using standard formal manipulations on operators, one can re-write the
 above as the operator equation 
\begin_inset Formula \begin{equation}
\zeta_{U_{g}}(t)=\exp\sum_{k=1}^{\infty}\frac{t^{k}}{k}\;\textrm{Tr}U_{g}^{k}\label{eq:}\end{equation}

\end_inset 

 Of associated interest is the Maclaurin Series 
\begin_inset Formula \begin{equation}
t\frac{d}{dt}\log\zeta_{U_{g}}(t)=\sum_{k=1}^{\infty}n_{k}t^{k}\label{eq:}\end{equation}

\end_inset 

 where we can read off 
\begin_inset Formula $n_{k}=\textrm{Tr}U_{g}^{k}$
\end_inset 

.
 From graph theory and the theory of dynamical systems, it is known that
 the 
\begin_inset Formula $n_{k}$
\end_inset 

 correspond to the number of periodic orbits of length 
\begin_inset Formula $k$
\end_inset 

.
 In the context of dynamical systems, this zeta is often referred to as
 the Artin-Mazur Zeta function.
 In the context of graph theory, it is referred to as the Ihara Zeta.
 Both are connected to the Selberg Zeta.
\layout Standard

The standard definition of the Ihara Zeta applies only to the adjacency
 matrix of finite-sized graphs.
 Adjacency matrices only have (non-negative) integer entries as matrix elements.
 Thus, we ask: given an appropriate basis, can an inifinite-dimensional
 transfer operator be written so as to have integer entries as matrix elements?
\layout Standard

The standard definition of the Artin-Mazur Zeta function requires that the
 number of fixed points (periodic orbits) be a finite number.
 For the operators that we are studying, there will in general be (countably)
 infinite number of periodic orbits.
 Yet the zeta will still be well defined, although the coefficients of the
 Maclaurin expansion will not be integers.
 Can these be reinterpreted as a density or measure? 
\layout Section

Appendix: To-Do List
\layout Standard

In order to give a proper and complete treatment of the subject, the topics
 listed below should be presented/reviewed/understood.
 
\layout Itemize

The Bernoulli process in probability theory is one of the simplest Markov
 processes.
 Understood as a Markov process, it has a number of generalizations.
 
\layout Itemize

Discuss entropy.
\layout Itemize

Discuss symbolic dynamics in two letters.
 Mention one-dimensional tiling, mention Fibonacci tiling.
 Mention Lindenmeyer systems.
 Mention subshifts of finite type.
 Mention how subshifts are solved.
 
\layout Itemize

Discuss connection to the Cantor set.
 viz, all strings in two letters.
\layout Itemize

Discuss free groups, discuss Cayley tree, discuss group presentation, and
 connect it up to this.
\layout Itemize

Discuss ergodicity, the ergodic theorem, and how its related to this.
 Discuss how the Bernoulli map is a 
\begin_inset Quotes eld
\end_inset 

bad
\begin_inset Quotes erd
\end_inset 

 example of ergodicity.
 Hypothesis: are all transfer operators that are triangular (have a polynomial
 basis) equivalent to 
\begin_inset Quotes eld
\end_inset 

bad
\begin_inset Quotes erd
\end_inset 

 ergodic sequences? Or are there good (uniformly converging) ergodic sequences
 that can result from triangular transfer operators?
\layout Itemize

Discuss wavelet transforms, point out their dyadic nature, point out their
 relationship to this mess; point out how wavelet transforms are a good
 tool for working with this kind of dyadic data.
\layout Itemize

While this paper focuses primarily on the polynomial and square-integrable
 eigenfunctions of the Bernoulli operator, there is also a class of non-differen
tiable, non-integrable eigenfunctions that can be precisely defined in terms
 of the shift operator on a one-dimensional lattice model, the Ising model
 of statistical mechanics.
 The Ising model has a natural topology that is distinctly different from
 the topology of the real number line; this alternate topology allows for
 a much, much larger set of eigenfunctions.
 This is discussed in greater detail in 
\begin_inset LatexCommand \cite{Ve-I04}

\end_inset 

.
\layout Section

Bibliography
\layout Standard


\begin_inset LatexCommand \BibTeX[plain]{/home/linas/linas/fractal/paper/fractal}

\end_inset 


\the_end
